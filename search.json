[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Manual Basico da Linguagem R",
    "section": "",
    "text": "{.unnumbered}"
  },
  {
    "objectID": "00-prefacio.html",
    "href": "00-prefacio.html",
    "title": "Prefácio da Segunda Edição",
    "section": "",
    "text": "Desde a publicação da primeira edição do “Manual Básico da Linguagem R” em 2019, a recepção positiva e o feedback construtivo dos leitores nos motivaram a aprimorar e expandir esta obra. Com 407 avaliações na Amazon e uma média de 4.7 pontos de um total de 5, ficamos profundamente agradecidos pelo reconhecimento e suporte de nossos leitores.\nA crescente importância da análise de dados na área da saúde e a popularização da linguagem R como uma ferramenta essencial para estatísticas médicas reforçam a relevância de um guia acessível e prático para estudantes e profissionais da saúde.\nNesta segunda edição, mantivemos o compromisso de oferecer um material didático que facilita o aprendizado da linguagem R, mesmo para aqueles sem formação prévia em ciência da computação ou estatística avançada. Revisamos cuidadosamente a estrutura do livro para incluir novos tópicos e atualizações importantes, garantindo que os leitores tenham acesso às ferramentas e técnicas mais atuais.\nDesde 2019, a linguagem R e seu ecossistema evoluíram significativamente. A empresa RStudio, que desenvolve o ambiente de desenvolvimento integrado amplamente utilizado por nossos leitores, mudou seu nome para POSIT, refletindo uma expansão de suas ferramentas e serviços. Entre as grandes novidades no mundo R, destacam-se o avanço dos pacotes do tidyverse, a introdução de novos pacotes para análise de dados e visualização, e a melhoria contínua das interfaces de usuário e de desenvolvimento.\nAo longo do livro, procuramos manter a abordagem prática e didática que caracterizou a primeira edição. Exemplos claros, exercícios práticos e explicações detalhadas continuam sendo a base do nosso método de ensino, com o objetivo de tornar a análise de dados acessível e útil para todos os profissionais da saúde.\nA importância da estatística na medicina não pode ser subestimada. Ela é fundamental para a prática baseada em evidências, permitindo uma avaliação crítica da literatura científica e uma melhor tomada de decisão clínica. Com a evolução constante das técnicas estatísticas e das ferramentas computacionais, esperamos que esta edição continue a ser um recurso valioso para a formação de profissionais de saúde capacitados e informados.\nAgradecemos a todos os leitores e colaboradores que contribuíram com sugestões e críticas construtivas. Este livro é um trabalho em constante evolução, e sua participação é essencial para que possamos continuar melhorando e adaptando o conteúdo às necessidades dos estudantes e profissionais da área da saúde.\nHenrique Alvarenga da Silva"
  },
  {
    "objectID": "01-intro.html#r---uma-linguagem-para-análise-de-dados-e-gráficos",
    "href": "01-intro.html#r---uma-linguagem-para-análise-de-dados-e-gráficos",
    "title": "2  Introdução",
    "section": "2.1 R - Uma linguagem para análise de dados e gráficos",
    "text": "2.1 R - Uma linguagem para análise de dados e gráficos\nR é um sistema para computação estatística e gráficos. Consiste em uma linguagem mais um ambiente de execução com gráficos, um depurador, acesso a determinadas funções do sistema e a capacidade de executar programas armazenados em arquivos de script (Hornik 2017).\nAprender uma linguagem computacional de estatística pode parecer inicialmente assustador para alunos de graduação da área da saúde. Entretanto, estamos aprendendo novas línguas a todo momento e uma linguagem computacional nada mais é do que uma nova língua.\nTodo ramo da ciência tem sua língua própria, muitas vezes incompreensível para quem não foi iniciado naquela disciplina. A medicina tem seu próprio vocabulário, com inúmeros termos obscuros até mesmo para médicos de especialidades diferentes. Todos os ramos do conhecimento têm seu próprio vocabulário e seu modo próprio de fazer a comunicação da informação. A linguagem de sinais tem em seus gestos a forma de expressar a linguagem, a música tem uma notação gráfica para expressar toda suas notas, melodias, ritmos. Até mesmo jogos tem uma linguagem própria. O xadrez tem vários sistemas de notação para expressar os movimentos do jogo.\nNão apenas os ramos da ciência têm sua língua, mas também cada equipamento, cada máquina, seja um carro, um microondas, um computador ou um smartphone, tem também sua própria linguagem. Cada aparelho só compreende aquilo que foi projetado para compreender. Uma torradeira só sabe esquentar e a forma de comunicarmos a ela o momento de fazer isso é apertando um botão. Um microondas é capaz de se aquecer de várias formas, dependendo da informação que é inserida em seu painel. Um smartphone consegue fazer uma infinidade de procedimentos, todos dependentes das informação que é inserida na tela pelo seu proprietário. Quanto mais sofisticado um equipamento, mais funções ele pode realizar, maior vocabulário necessário para essa interação.\nMas, então, como pode alguém sem nenhuma formação em engenharia ou computação, conseguir fazer um equipamento tão sofisticado como um smartphone encontrar a localização de uma cidade, mostrar na tela a imagem de uma rua da cidade, traçar uma rota de sua posição até esse local? Conseguimos isso porque a forma como os seres humanos se comunicam com os equipamentos evoluiu de forma impressionante no último século. Há alguns poucos anos era preciso aprender um código morse para transmitir uma informação pelo telégrafo, hoje com um conhecimento muito mais simples podemos nos comunicar com todo o planeta através da internet num smartphone. Da mesma forma, as linguagem computacionais evoluíram substancialmente desde sua criação. As primeiras linguagens de programação eram tão obscuras que só apenas umas poucos iniciados eram capazes de usar um computador. Mas cada ano surgem novas linguagens, cada vez mais simples de serem usadas. Atualmente, até mesmo crianças se tornam exímias programadoras. As linguagens computacionais modernas permitem a comunicação entre um ser humano e um computador de uma forma que cada vez mais simples. E a linguagem R é justamente a ponte entre a linguagem da estatística e a linguagem humana. O R foi criado para ser justamente uma uma linguagem para análise de dados e produção de gráficos (R. Ihaka and Gentleman 1996). A linguagem R tornou possível executarmos complexos cálculos matemáticos de forma fácil e rápida e criarmos gráficos complexos com simples comandos."
  },
  {
    "objectID": "01-intro.html#r-para-análise-exploratória-de-dados",
    "href": "01-intro.html#r-para-análise-exploratória-de-dados",
    "title": "2  Introdução",
    "section": "2.2 R para Análise Exploratória de dados",
    "text": "2.2 R para Análise Exploratória de dados\nA Análise Exploratória de Dados (EDA - Exploratory Data Analysis) é uma etapa inicial crítica no processo de análise de dados que ajuda a descobrir padrões, tendências e anomalias nos conjuntos de dados, através do uso sistemático de várias técnicas de visualização e estatísticas descritivas. John W. Tukey, o pioneiro da Análise Exploratória de Dados (EDA), desempenhou um papel significativo ao enfatizar a importância da EDA no campo da estatística e análise de dados. Tukey defendia uma exploração mais intuitiva e flexível, em vez de simplesmente confiar em um conjunto predeterminado de suposições e modelos. Em seu livro “Exploratory Data Analysis”, Tukey enfatizou a importância de “aprender com os dados” e considerar vários aspectos dos dados para formar um entendimento abrangente(Tukey et al. 1977).\nTukey também destacou a importância da visualização e das técnicas gráficas em EDA, mostrando o valor de usar representações visuais para descobrir padrões, tendências e relacionamentos que podem não ser facilmente discerníveis por meio de métodos estatísticos tradicionais. Nesse sentido, a EDA permite que os pesquisadores interajam com os dados de forma mais direta, fomentando a curiosidade e promovendo uma investigação mais aprofundada. Uma exploração mais flexível e aberta, pode levar a novos insights e descobertas inesperadas e gerar novas questões e hipóteses a serem analisadas.\nA linguagem R emergiu como uma escolha popular para EDA devido à sua versatilidade, biblioteca abrangente de pacotes e forte suporte da comunidade. Aproveitando os recursos do R e os pacotes do tidyverse, é possível realizar um EDA eficaz e estabelecer uma base sólida para análises subsequentes, levando a uma melhor tomada de decisão e insights.\nDe acordo com Hadley Wickham,\n\nNão há regra sobre quais perguntas você deve fazer para orientar sua pesquisa. No entanto, dois tipos de perguntas sempre serão úteis para fazer descobertas em seus dados. Que tipo de variação ocorre dentro de minhas variáveis? Que tipo de covariação ocorre entre minhas variáveis?\nHadley Wickham, R for Data Science."
  },
  {
    "objectID": "01-intro.html#a-importância-da-estatística-na-medicina",
    "href": "01-intro.html#a-importância-da-estatística-na-medicina",
    "title": "2  Introdução",
    "section": "2.3 A importância da Estatística na Medicina",
    "text": "2.3 A importância da Estatística na Medicina\nA estatística é uma das áreas fundamentais das ciências da saúde. Em um dos primeiros artigos sobre o ensino da estatística para estudantes de medicina, num editorial do British Medical Journal de 1937, Bradford Hill já salientava que para poder ler de forma crítica a literatura científica o médico precisava dominar os conceitos estatísticos (Hill 1937). Entretanto, o ensino da estatística só se tornou compulsório nas escolas médicas de Londres a partir de 1975 e em muitos países europeus apenas dez anos mais tarde (Altman and Bland 1991). Nas últimas duas décadas a Organização Mundial de Saúde tem buscado estratégias para melhorar o ensino da estatística para os profissionais de saúde, tendo em vista que essas habilidades são úteis não apenas para aqueles que desejam se tornar pesquisadores, mas para todos que trabalham com a saúde, pois favorecem o pensamento crítico, lógico e científico, facilitando os processos de tomada de decisão, de análise de riscos e de avaliação das evidências científicas (Lwanga, Tye, and Ayeni 1999). A falta do conhecimento estatístico coloca em risco todo o projeto de uma prática baseada em evidências, cujo ponto fundamental é justamente a capacidade de uma leitura crítica da literatura científica (Sackett and Rosenberg 1995).\nA importância desse conhecimento se torna ainda mais relevante quando levamos em conta a imensa quantidade de erros estatísticos básicos na literatura médica (Altman and Bland 1991) e baixa qualidade da literatura científica que, infelizmente, é muito menos confiável do que nossa intuição imagina. Em um dos artigos mais citados de 2005, Ioannidis alerta que cerca de metade dos resultados da literatura científica médica não são verdadeiros (Ioannidis 2005) e, mais recentemente, que a maioria dos estudos clínicos não são úteis (Ioannidis 2016). Ou seja, não apenas a maioria dos resultados são falsos, como a maioria dos resultados verdadeiros não são úteis (Ioannidis 2016). O médico, consumidor principal dessa literatura, precisa mais do que nunca saber analisar de forma crítica esses artigos e, para tanto, a formação sólida em métodos estatísticos é de suma importância.\nEntretanto, existem barreiras reais ao ensino da estatística para estudantes das áreas da saúde. A mera menção da palavra “estatística” é suficiente para evocar fortes reações emocionais de rejeição na maioria das pessoas (Hill 1947). Estudantes de medicina muitas vezes preferem evitar disciplinas com conteúdo matemático e, via de regra, os cursos de estatística ou bioestatística não são muito populares entre esses alunos (Altman and Bland 1991). Além disso, alunos das áreas de saúde usualmente tem dificuldade em perceber a importância dessa disciplina, não veem razão para estudar metodologia da pesquisa científica e não se sentem motivados para aprender os difíceis conceitos matemáticos fundamentais (Altman and Bland 1991; Clarke, Clayton, and Donaldson 1980). Essas barreiras podem comprometer seriamente o aprendizado da estatística pelos estudantes de medicina e, como resultado disso, fazer com que muitos médicos sejam incapazes de uma leitura crítica da literatura científica.\nA performance do aprendizado de um estudante está diretamente relacionada a diversos fatores, tais como o seu grau de engajamento, ao prazer em estudar o conteúdo, ao seu sentimento de confiança na capacidade de aprender, a sua determinação para aprender. Assim, devem ser buscados mecanismos que possibilitem aumentar esses fatores. Um desses fatores é o uso de softwares estatísticos adequados. O uso de um software em cursos introdutórios de estatística deve levar em consideração uma série de fatores: disponibilidade, custo, facilidade de uso, possibilidade de geração de gráficos e imagens, facilidade de acesso a literatura sobre o software, documentação do software, disponibilidades de pacotes auxiliares, utilidade futura do software na vida acadêmica.\nA linguagem estatística R associada à interface do RStudio preenchem da melhor forma possível os requisitos necessários para essa função."
  },
  {
    "objectID": "01-intro.html#breve-história-do-r",
    "href": "01-intro.html#breve-história-do-r",
    "title": "2  Introdução",
    "section": "2.4 Breve História do R",
    "text": "2.4 Breve História do R\nA origem do R remonta à Linguagem S, desenvolvida por John Chambers em 1976 nos laboratórios da AT&T Bell Labs. No início da década de 1990, a linguagem S foi aprimorada com uma notação para modelos estatísticos, o que resultou em uma significativa economia de esforço de programação para a análise estatística de dados. No final da década de 1990, o S foi revisado e transformado em uma linguagem de alto padrão, totalmente baseada em programação orientada a objetos. Esta versão revisada da linguagem S foi o ponto de partida para o desenvolvimento do R.\nA linguagem R foi criada em 1993 por Robert Gentleman e Ross Ihaka, na Universidade de Auckland, na Nova Zelândia. Inicialmente, o R foi desenvolvido como uma ferramenta para o ensino em cursos introdutórios de estatística ministrados por esses professores(Ross Ihaka 1998).\nO R é o resultado de uma colaboração entre estatísticos, visando criar um ambiente computacional poderoso, programável, portátil e aberto. Este ambiente é adequado para resolver problemas complexos e sofisticados, bem como para realizar análises rotineiras, sem restrições de acesso ou uso. O R é executável em diversos sistemas operacionais, incluindo macOS, Windows e Linux.\nO R é uma linguagem de código aberto e livre, publicada sob a licença pública GNU e mantida pela R Foundation. Sua estrutura de código aberto e software gratuito atraiu um grande número de desenvolvedores ao longo dos anos. Este modelo colaborativo de desenvolvimento permitiu que o R crescesse rapidamente em termos de funcionalidades e popularidade, tornando-se uma das principais ferramentas para análise de dados e estatísticas em todo o mundo.\nAlém disso, o R é altamente extensível, com milhares de pacotes disponíveis que expandem suas capacidades para praticamente qualquer tipo de análise de dados. Esses pacotes são armazenados e distribuídos através do Comprehensive R Archive Network (CRAN), o repositório oficial de pacotes do R.\nO sucesso do R também se deve à sua capacidade de criar visualizações de dados de alta qualidade. Com pacotes como o ggplot2, os usuários podem gerar visualizações complexas e esteticamente agradáveis com apenas algumas linhas de código.\nA popularidade do R continua a crescer, especialmente entre cientistas de dados e estatísticos. Sua capacidade de lidar com grandes conjuntos de dados, a comunidade ativa e os abundantes recursos de aprendizado são alguns dos motivos pelos quais o R é uma escolha popular para análise de dados estatísticos."
  },
  {
    "objectID": "01-intro.html#cran-comprehensive-r-archive-network",
    "href": "01-intro.html#cran-comprehensive-r-archive-network",
    "title": "2  Introdução",
    "section": "2.5 CRAN (Comprehensive R Archive Network)",
    "text": "2.5 CRAN (Comprehensive R Archive Network)\nO CRAN (Comprehensive R Archive Network) é um repositório central onde qualquer pessoa pode contribuir com extensões para o R, conhecidas como “pacotes” (packages), desde que atendam aos requisitos de qualidade e licenciamento estabelecidos pelos mantenedores do CRAN (Hornik 2012). Em janeiro de 2017, graças à comunidade extremamente ativa de desenvolvedores que contribuem para o R diariamente, o CRAN já tinha atingido a marca de 10.000 pacotes disponíveis para download (Smith 2008). Em maio de 2024, esse número já ultrapassava 20.000 pacotes.\nO CRAN não apenas armazena pacotes, mas também fornece documentação extensa e exemplos de uso, facilitando a aprendizagem e implementação das ferramentas. Os pacotes no CRAN são frequentemente atualizados para incluir novas funcionalidades, corrigir bugs e melhorar a eficiência, refletindo o rápido progresso na comunidade de desenvolvedores do R. A comunidade de desenvolvedores e usuários do R é vibrante e colaborativa, com inúmeros fóruns, blogs e conferências dedicados à troca de conhecimentos e melhores práticas.\nEsses pacotes são fundamentais para a força e a versatilidade do R. Entre os milhares de pacotes disponíveis, alguns dos mais famosos foram desenvolvidos por Hadley Wickham. Eles desempenharam um papel crucial no aumento da popularidade do R nos últimos anos. O conjunto de pacotes desenvolvidos por Wickham se tornou tão importante e abrangente que foram reunidos em um grande pacote chamado tidyverse, uma analogia ao termo universo, que sugere um universo organizado de ferramentas para análise de dados.\nO tidyverse inclui pacotes essenciais como ggplot2 para visualização de dados, dplyr para manipulação de dados, tidyr para arrumação de dados, entre outros. Estes pacotes foram desenvolvidos com a filosofia de tornar a programação e a análise de dados no R mais simples, intuitiva e eficiente.\nEste livro se baseia principalmente nos pacotes do tidyverse, que facilitam a programação e as análises no R. Ao utilizar o tidyverse, os usuários podem realizar tarefas complexas com menos esforço e maior clareza, aproveitando a consistência e integração entre os pacotes.\nO crescimento exponencial do CRAN e a influência de pacotes como o tidyverse ilustram como a comunidade do R continua a expandir e inovar, consolidando o R como uma das principais linguagens para análise de dados e estatísticas."
  },
  {
    "objectID": "01-intro.html#bioconductor",
    "href": "01-intro.html#bioconductor",
    "title": "2  Introdução",
    "section": "2.6 Bioconductor",
    "text": "2.6 Bioconductor\nAlém do CRAN, diversos pacotes específicos para análise de gens e biologia molecular, são mantidos e distribuidos por um projeto chamado Bioconductor, totalmente desenvolvido com base na liguagem R (Tippmann 2015). Bioconductor é um projeto de software de código aberto para a análise genômica e biologia molecular, feito com a contrição de uma comunidade grande e diversificada de cientistas (Huber et al. 2015).Em junho de 2024 o Bioconductor já tinha cerca de 2300 pacotes.\nPopularidade do R\nO R tem se tornado cada vez mais popular na pesquisa científica. Em 2009, o jornal New York Times publicou uma reportagem destacando a crescente popularidade do R entre os cientistas. Segundo o New York Times, o R tem se tornado a segunda língua dos pesquisadores. Em uma pesquisa realizada em 2015 pela Rexer Analytics Survey, o R foi o software mais utilizado entre os 1.220 cientistas avaliados (Rexer, Gearan, and Allen 2015).\nA popularidade do R tem crescido ininterruptamente, especialmente nos últimos anos (Robinson 2017). Atualmente, o R é um dos principais softwares estatísticos utilizados em pesquisas acadêmicas, particularmente na área médica, onde é “a ferramenta de escolha para muitos métodos estatísticos necessários nos estudos clínicos” (Robinson 2017). No Canadá, cerca de metade das universidades tem pelo menos um curso que utiliza a linguagem R (Carson and Basiliko 2016). O R também é reconhecido como o principal repositório de funções estatísticas validadas (Smith 2008).\nConforme destacado por um especialista: “R has really become the second language for people coming out of grad school now, and there’s an amazing amount of code being written for it” (Vance 2009).\nNos últimos anos, o uso do R como ferramenta em aulas de estatística cresceu substancialmente. Diversos pacotes específicos foram desenvolvidos para uso educacional, como o mosaic, TeachingDemos, simpleR e uwIntroStats. Além disso, foram lançados diversos livros didáticos introdutórios baseados no uso do R, incluindo “Introductory Statistics with R”, “Discovering Statistics Using R”, “Learn Statistics Using R”, “An R Introduction to Statistics”, “Introduction to Probability and Statistics Using R”, “OpenIntro Statistics” e muitos outros manuais disponíveis gratuitamente na internet. Em 2014, durante o New England Statistics Symposium, foi lançado o site StatsTeachR, um repositório de módulos de ensino de estatística usando o R, acessível gratuitamente.\nO R possui uma rica documentação e uma vasta quantidade de tutoriais gratuitos disponíveis online (Piboonrungroj 2012). A comunidade de usuários e desenvolvedores do R é grande e está em constante crescimento, proporcionando um suporte valioso para novos usuários. Estudos recentes têm mostrado que o uso do R tem crescido exponencialmente nas últimas décadas, sendo atualmente o software estatístico com a maior projeção de crescimento no futuro.\nAlém disso, a linguagem R continua a se adaptar e inovar, incorporando novos pacotes e funcionalidades que atendem às demandas emergentes em diversas áreas de pesquisa e indústria. Muitas instituições acadêmicas e organizações de pesquisa têm adotado o R como sua ferramenta principal para análise de dados, contribuindo para sua disseminação e evolução contínua.\nCom todas essas vantagens, o R solidifica sua posição como uma ferramenta indispensável para cientistas de dados, estatísticos e pesquisadores em todo o mundo."
  },
  {
    "objectID": "01-intro.html#rstudio",
    "href": "01-intro.html#rstudio",
    "title": "2  Introdução",
    "section": "2.7 RStudio",
    "text": "2.7 RStudio\nRStudio é um Ambiente de Desenvolvimento Integrado (IDE - Integrated Development Environment) projetado especificamente para a linguagem estatística R, mas que atualmente suporta também python e outras linguagens. Um IDE é um software que oferece um conjunto de ferramentas que facilitam e aprimoram o processo de desenvolvimento, tornando o trabalho com R muito mais eficiente e produtivo.\nLançado ao público em 2011, o RStudio rapidamente se tornou uma das ferramentas preferidas para programação em R, devido à sua interface amigável e rica em funcionalidades. O RStudio oferece um ambiente unificado para escrita de código, execução de scripts, visualização de gráficos e gerenciamento de pacotes, entre outras funcionalidades.\n\n2.7.1 Funcionalidades do RStudio:\n\nEditor de Código Avançado: Com destaque de sintaxe, autocompletar e suporte a múltiplas linguagens.\nConsole Interativo: Permite a execução de comandos R em tempo real.\nVisualização de Gráficos: Ferramentas integradas para visualização e exportação de gráficos.\nGerenciamento de Pacotes: Instalação, atualização e carregamento de pacotes diretamente do IDE.\nPainéis de Ajuda e Documentação: Acesso rápido à documentação e ajuda sobre funções e pacotes.\nIntegração com Versionamento: Suporte integrado para Git e outros sistemas de controle de versão.\n\nO RStudio é amplamente utilizado por organizações de renome mundial, incluindo NASA, Eli Lilly, AstraZeneca, Samsung, Honda, Hyundai, Walmart, Nestlé, General Electric, Santander, Universidade de Oxford, Universidade de Toronto e muitas outras instituições. Essas organizações confiam no RStudio para suas análises estatísticas e visualizações de dados devido à sua robustez e facilidade de uso.\nA versão gratuita do RStudio é perfeitamente adequada para uso acadêmico e pessoal, eliminando a necessidade de softwares pagos caros. Para usuários que necessitam de funcionalidades adicionais, como suporte avançado para servidores e integração com plataformas empresariais, a RStudio PBC oferece versões comerciais com recursos ampliados.\n\n\n2.7.2 Por que escolher o RStudio?\n\nInterface Intuitiva: Design simplificado que facilita a navegação e uso eficiente do R.\nFerramentas Integradas: Todas as ferramentas necessárias para desenvolvimento, análise e visualização em um único lugar.\nComunidade Ativa: Grande comunidade de usuários e desenvolvedores que compartilham recursos, tutoriais e suporte.\nAtualizações Constantes: Lançamentos regulares com novas funcionalidades e melhorias de desempenho.\n\nO RStudio é, sem dúvida, uma ferramenta essencial para qualquer pessoa que trabalhe com a linguagem R, seja em ambientes acadêmicos, de pesquisa ou industriais. Seu impacto no campo da análise de dados é significativo, proporcionando uma plataforma robusta e acessível para todos os níveis de usuários."
  },
  {
    "objectID": "01-intro.html#leituras-complementares-sobre-a-linguagem-r",
    "href": "01-intro.html#leituras-complementares-sobre-a-linguagem-r",
    "title": "2  Introdução",
    "section": "2.8 Leituras complementares sobre a linguagem R",
    "text": "2.8 Leituras complementares sobre a linguagem R\nPara quem desejar aprofundar o aprendizado do R, segue abaixo uma lista de livros, sites e cursos sobre a linguagem R:\n\n2.8.1 Livros sobre progamação em R\n\nThe R Book, de Michael J. Crawley. Publicado pela Editora Willey (2º ed, 2013.)\nR for Everyone. Advanced Analytics and Graphics, de Jared P. Lander. Publicado pela Editora Pearson (2014).\nBiostatistics with R. An Introduction to Statistics Through Biological Data, de Babak Shahbaba. Publicado pela editora Springer (2012).\nIntroduction to Probability and Statistics Using R, de G. Jay Kerns. Disponível no site do CRAN no link: https://cran.r-project.org/web/packages/IPSUR/vignettes/IPSUR.pdf\nAn Introduction to Statistical and Data Sciences via R, de Chester Ismay e Albert Y. Kim. Online book. (2018). https://moderndive.com.\nA Beginner’s Guide to R, de Alain F. Zuur, Elena N. Ieno e Erik H. W. G. Meesters. Publicado pela Editora Springer (2009).\nThe Art of R Programming. A tour of Statistical Software Design, de Norman Matloff. Publicado pela Editora no Starch Press (2011).\nR for Data Science. Import, tidy, transform, visualize and model data, de Hadley Wickham e Garret Grolemund. Publicado pela Editora O’Reilly (2016). Disponível online em: https://r4ds.had.co.nz.\nData Analysis for the Life Sciences with R, de Rafael A Irizarry and Michael I Love. Ebook gratuito no site leanpub: https://leanpub.com/dataanalysisforthelifesciences\nHands-On Programming with R, de Garrett Grolemund, publicado pela editora O’Reilly (2014).\nIntroductory Statistics with R, de Peter Dalgaard. Publicado pela Editora Springer (2º ed, 2008).\nAdvanced R, de Hadley Wickham. Publicado pela Editora Chapman and Hall/CRC (2ª ed, 2019). Disponível online em: adv-r.hadley.nz\nEfficient R Programming, de Colin Gillespie e Robin Lovelace. Publicado pela Editora O’Reilly (2016). Disponível online em: efficientr.programming\n\n\n\n2.8.2 livros sobre a gráficos no R\n\n“ggplot2: Elegant Graphics for Data Analysis” de Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen. https://ggplot2-book.org.\nR Graphics Cookbook, de Winston Chang. https://r-graphics.org/index.html\n\nggplot2 Essentials. Explore the full range of ggplot plotting capabilities to create meaningful and spectacular graphs, de Donato Teutonico. Publicado pela editora Packt Publishing (2015).\nFundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures, de Claus O. Wilke. Publicado pela Editora O’Reilly (2019). Disponível online em: <clauswilke.com/dataviz>\n\n\n\n2.8.3 Sites\n\nRStudio. https://www.rstudio.com/online-learning\nThe R Project for Statistical Computing. https://www.r-project.org\nr-bloggers. https://www.r-bloggers.com\nStackoverflow. https://stackoverflow.com/questions/tagged/r\n\nO site the Big Book of R tem uma lista com mais de 300 livros sobre o R nas mais áreas da ciência. https://www.bigbookofr.com\n\n\n2.8.4 Cursos\n\nCoursera. https://www.coursera.org (inúmeros cursos sobre a linguagem R)\nedX. https://www.edx.org (inúmeros cursos sobre a linguagem R)\nDatacamp. https://www.datacamp.com\n\nEssa é só uma lista resumida sobre onde encontrar informações sobre o R. Buscando na internet você poderá encontrar uma infinidade de outros livros, manuais, cursos e sites sobre o R.\n\n\n\n\nAltman, Douglas G, and J Martin Bland. 1991. “Improving Doctors’ Understanding of Statistics.” Journal Article. Journal of the Royal Statistical Society: Series A (Statistics in Society) 154 (2): 223–48.\n\n\nCarson, M. A., and N. Basiliko. 2016. “Approaches to r Education in Canadian Universities.” Journal Article. F1000Res 5: 2802. https://doi.org/10.12688/f1000research.10232.1.\n\n\nClarke, M, DG Clayton, and LJ Donaldson. 1980. “Teaching Epidemiology and Statistics to Medical Students the Leicester Experience.” Journal Article. International Journal of Epidemiology 9 (2): 179–85.\n\n\nHill, A Bradford. 1937. “I.—the Aim of the Statistical Method.” Journal Article. The Lancet 229 (5914): 41–43.\n\n\n———. 1947. “Statistics in the Medical Curriculum?” Journal Article. British Medical Journal 2 (4522): 366.\n\n\nHornik, Kurt. 2012. “The Comprehensive r Archive Network.” Journal Article. Wiley Interdisciplinary Reviews: Computational Statistics 4 (4): 394–98. https://doi.org/doi:10.1002/wics.1212.\n\n\n———. 2017. “The r FAQ.” Web Page. https://CRAN.R-project.org/doc/FAQ/R-FAQ.html.\n\n\nHuber, Wolfgang, Vincent J. Carey, Robert Gentleman, Simon Anders, Marc Carlson, Benilton S. Carvalho, Hector Corrada Bravo, et al. 2015. “Orchestrating High-Throughput Genomic Analysis with Bioconductor.” Journal Article. Nature Methods 12 (2): 115–21. https://doi.org/10.1038/nmeth.3252.\n\n\nIhaka, R, and R Gentleman. 1996. “R: A Language for Data Analysis and Graphics. Journal of Computational and Graphical Statistics 5: 299.” Journal Article. Doi: 10.2307/1390807.\n\n\nIhaka, Ross. 1998. “R: Past and Future History.” Journal Article. Computing Science and Statistics 392396.\n\n\nIoannidis, John PA. 2005. “Why Most Published Research Findings Are False.” Journal Article. PLoS Medicine 2 (8): e124.\n\n\n———. 2016. “Why Most Clinical Research Is Not Useful.” Journal Article. PLoS Medicine 13 (6): e1002049.\n\n\nLwanga, S Kaggwa, Cho-Yook Tye, and O Ayeni. 1999. Teaching Health Statistics: Lesson and Seminar Outlines. Book. World Health Organization.\n\n\nPiboonrungroj, Pairach. 2012. “R-Uni (a List of 100 Free r Tutorials and Resources in University Webpages).” Web Page. https://pairach.com/2012/02/26/r-tutorials-from-universities-around-the-world/.\n\n\nRexer, Karl, Paul Gearan, and Heather Allen. 2015. “Rexer Analytics’ 2015 Data Science Survey.” Data Science Survey Report. Rexer Analytics.\n\n\nRobinson, David. 2017. “The Impressive Growth of r.” https://stackoverflow.blog/2017/10/10/impressive-growth-r/.\n\n\nSackett, D. L., and W. M. Rosenberg. 1995. “The Need for Evidence-Based Medicine.” Journal Article. JR Soc Med 88: 620–24.\n\n\nSmith, D. 2008. “CRAN Now Has 10,000 r Packages. Here’s How to Find the Ones You Need.” Journal Article. Revolutions. Daily News about Using Open Source R for Big Data Analysis, Predictive Modeling, Data Science, and Visualization Since 2017.\n\n\nTippmann, S. 2015. “Programming Tools: Adventures with r.” Journal Article. Nature 517 (7532): 109–10. https://doi.org/10.1038/517109a.\n\n\nTukey, John Wilder et al. 1977. Exploratory Data Analysis. Vol. 2. Springer.\n\n\nVance, Ashlee. 2009. “Data Analysts Captivated by r’s Power.” Journal Article. New York Times 6 (5.4)."
  },
  {
    "objectID": "02-Instalation.html#instalando-o-r",
    "href": "02-Instalation.html#instalando-o-r",
    "title": "3  Instalação do R e do RStudio",
    "section": "3.1 Instalando o R",
    "text": "3.1 Instalando o R\nO R pode ser baixado para instalação no site do CRAN: https://cran.r-project.org/index.html"
  },
  {
    "objectID": "02-Instalation.html#instalando-o-rstudio",
    "href": "02-Instalation.html#instalando-o-rstudio",
    "title": "3  Instalação do R e do RStudio",
    "section": "3.2 Instalando o RStudio",
    "text": "3.2 Instalando o RStudio\nO RStudio pode ser instalado a partir do site do RStudio: https://www.rstudio.com"
  },
  {
    "objectID": "02-Instalation.html#video-da-instalação-no-youtube",
    "href": "02-Instalation.html#video-da-instalação-no-youtube",
    "title": "3  Instalação do R e do RStudio",
    "section": "3.3 Video da instalação no Youtube",
    "text": "3.3 Video da instalação no Youtube\nHá um pequeno video de instalação do R e do RStudio no Mac no link a seguir: https://youtu.be/zhhxPbGhI8Q"
  },
  {
    "objectID": "03-RStudio.html#rstudio---primeiros-passos",
    "href": "03-RStudio.html#rstudio---primeiros-passos",
    "title": "4  RStudio",
    "section": "4.1 RStudio - Primeiros passos",
    "text": "4.1 RStudio - Primeiros passos\nO R é uma linguagem, uma linguagem escrita. Da mesma forma que precisamos de um papel ou um processador de texto para escrevermos uma carta, também precisamos de um meio onde escrever nossos comandos na linguagem R. Qualquer editor de textos simples poderia servir para escrevermos na linguagem R, o TextEdit no Mac. Entretanto, usar um software específico para escrevermos comandos na linguagem R facilita muito o trabalho. O RStudio é justamente isso e muito mais. E um ambiente completo para escrever todo um projeto de análises estatísticas com a linguagem R."
  },
  {
    "objectID": "03-RStudio.html#video-aula",
    "href": "03-RStudio.html#video-aula",
    "title": "4  RStudio",
    "section": "4.2 Video Aula",
    "text": "4.2 Video Aula\nLink para video aula de primeiros passos com o RStudio: https://youtu.be/P8lIjQmRiuU"
  },
  {
    "objectID": "03-RStudio.html#os-painéis-do-rstudio",
    "href": "03-RStudio.html#os-painéis-do-rstudio",
    "title": "4  RStudio",
    "section": "4.3 Os Painéis do RStudio",
    "text": "4.3 Os Painéis do RStudio\nO RStudio possui 4 painéis principais: Editor, Console, Ambiente (Enviroment) e Arquivos (Files). Cada um desses painéis pode conter diversas abas para visualização de outras informações. Cada um desses painéis pode ser redimensionado conforme o desejo do usuário. Veremos sucintamente para que servem cada um deles.\n\n\n\n\n\nOs 4 Paineis do RStudio.\n\n\n\n\n\n4.3.1 Console\nO console é o local no qual podemos digitar e executar comandos de forma direta. Os códigos digitados no console são imediatamente executados ao clicar ENTER e o resultado é mostrado logo a seguir. Operações mais simples podem ser executadas diretamente no console, mas códigos mais complexos devem ser criados num script, necessitando do painel Editor.\n\n\n4.3.2 Editor\nO Editor é o painel no qual serão exibidos os editores de texto do RStudio. No Editor podemos criar documentos de diversos tipos, tais como Scripts, Notebooks etc.. O importante é que esses documentos podem ser salvos para uso posterior. Veremos adiante que os documentos do tipo RNotebook e Quarto são bastante poderosos e versáteis para análises estatísticas.\n\n\n4.3.3 Ambiente (Enviroment)\nO painel Ambiente possui várias abas: Environment, History, Connections. A primeira, chamada de Enviroment (ambiente), exibe as variáveis e objetos que estão na memória durante uma sessão do RStudio. Nessa aba podemos visualizar as variáveis à medida que são criadas, modificadas e deletadas. A segunda aba, chamada de History, contém a lista de todos os comandos que foram executados pelo R nas últimas sessões. A terceira aba, Connections, é usada em projetos mais avançados, para mostrar as conexões do RStudio com bancos de dados. Não usaremos essa aba nesse curso.\n\n\n4.3.4 Arquivos e Gráficos (Files e Plots)\nO painel Files também possui várias abas: Files, Plots, Packages, Help e Viewer. A aba Files mostra a pasta atual do R e os arquivos dessa pasta. É sempre indicado que todo projeto estatístico tenha sua própria pasta, o que organiza melhor o trabalho. Portanto é recomendado sempre criar um projeto no RStudio, vinculado a uma pasta em seu computador onde serão salvos os dados e arquivos desse projeto. Veremos mais adiante como criar um projeto no RStudio. A aba Plots mostra os gráficos criados na sessão do R. Essa aba permite tanto a visualização como a exportação dos gráficos no formato de imagem ou pdf. A aba Packages mostra os pacotes do R que foram instalados e permite a atualização desses pacotes. A aba Help mostra o arquivo help do R. A aba Viewer serve para visualização de arquivos da web. Não usaremos essa aba nesse curso."
  },
  {
    "objectID": "03-RStudio.html#os-tipos-de-documentos-do-rstudio",
    "href": "03-RStudio.html#os-tipos-de-documentos-do-rstudio",
    "title": "4  RStudio",
    "section": "4.4 Os tipos de documentos do RStudio",
    "text": "4.4 Os tipos de documentos do RStudio\n\n4.4.1 R Script\nNo cinema ou no teatro um script é o texto escrito do diálogos dos personagens. Na ciência da computação um script é um texto escrito em alguma linguagem de programação. No nosso caso, R Script é um texto com comandos da linguagem R. Ou seja, em última análise, um script é nada mais que um documento de texto, que pode ser salvo, assim como podemos salvar documentos que escrevemos com o uso de processadores de texto. Tal como salvamos documentos do Word, também podemos salvar os Scripts escritos no RStudio.\nUm script contém a sequencia de comandos que desejamos que sejam executados pelo R, escrito na linguagem R. Podemos também escrever os comandos diretamente no console, entretanto os comando assim escritos não podem ser salvos. A vantagem de escrever os comandos num documento de texto é justamente poder salvar esse documento para uso posterior. Em computação é usual denominarmos os comandos num documento de texto como nosso código. Em especial, quando esse código está escrito na linguagem R, é usual denominar esses comando de código em R ou simplesmente de R code. Um Script contém principalmente códigos, mas deve conter também comentários, que explicam o código.\n\n4.4.1.1 Comentários no R - #\nUm símbolo importante no R é o hashtag #.\nDentro de um Script ou num campo de código esse símbolo indica que o texto a seguir é um comentário, ou seja, é um texto para ser lido por humanos e que o computador ignora.\n\n\n\n\n\nMeu Primeiro Script no R\n\n\n\n\nNo RStudio podemos criar outros tipos de documentos. Um RNotebook é um documento do tipo Markdown. Como veremos adiante, num RNotebook o hashtag # tem outra função, serve para indicar uma seção do documento.\n\n\n\n4.4.2 RNotebook\nO R Notebook é um documento de texto mais sofisticado que um R Script. Um documento do tipo R Notebook é um misto de texto e códigos. O texto de um R Notebook é escrito no formato mais usado em ciência chamado de Markdown, intercalado com trechos de código (chamados de code chunks). Essa mistura de texto com código proporciona criar documentos com toda nossa análise estatística de forma muito mais simples. Além disso, um R Notebook pode ser gravado em diferentes formatos (word, pdf ou html) o que simplifica os processos de transferência de arquivos entre colaboradores.\nVeja na imagem abaixo que um trecho de código vem dentro de um campo (code chunk) delimitado por\n’’’{r}\n’’’’\n\n\n\n\n\nMeu Primeiro RNotebook no R\n\n\n\n\n\n\n4.4.3 Documento Quarto\nO documento tipo Quarto no RStudio é um formato de arquivo muito versátil, que permite a criação de um ambiente de trabalho personalizado, contendo diversos elementos, como códigos, gráficos, tabelas e textos explicativos.\nO nome Quarto é derivado do nome dado ao formato de um livro ou panfleto produzido a partir de folhas inteiras impressas com oito páginas de texto, quatro de cada lado, e depois dobradas duas vezes para produzir quatro folhas. O primeiro livro impresso europeu conhecido é um Quarto, o Sibyllenbuch, que se acredita ter sido impresso por Johannes Gutenberg em 1452-53.\nO documento Quarto se parece muito com o RNotebook, mas combina as funcionalidades de muitos pacotes do R, inclusive o pacote bookdown para autoria de livros. Esse livro, não por acaso, foi escrito totalmente em documentos tipo Quarto.\nEsse é um tipo de documento mais moderno, criado há poucos anos e especialmente útil para análises de dados, que envolvem diversos passos e resultados intermediários, pois permite a organização e a documentação dos procedimentos utilizados.\nOs documentos tipo Quarto também são criados no RStudio por meio da extensão .qmd. Combina o uso da linguagem R com o formato Markdown, utilizado para a criação de textos com formatação simples. Assim, também é possível incluir no documento tanto trechos de código em R quanto texto formatado com títulos, parágrafos, listas, entre outros elementos.\nAlém disso, os documentos tipo Quarto no RStudio permitem a utilização de recursos avançados, como a inclusão de gráficos interativos, tabelas dinâmicas e widgets, que possibilitam a interação do usuário com os resultados obtidos. Também é possível personalizar o tema visual do documento, alterando cores, fontes e outros aspectos de design.\nUma vez criado o documento tipo Quarto, é possível exportá-lo em diversos formatos, como PDF, HTML e Word, mantendo a formatação e a interatividade dos elementos. Isso permite a compartilhamento dos resultados e da metodologia utilizada com outros usuários e colaboradores.\nEm resumo, o documento tipo Quarto no RStudio é uma ferramenta poderosa para análises de dados, que combina a linguagem R com o formato Markdown e permite a organização, a documentação e a interação com os resultados obtidos.\nO documento tipo Quarto no RStudio e o RNotebook são formatos de arquivo similares e ambos oferecem algumas vantagens para os usuários. No entanto, há diferenças entre eles que podem tornar um mais adequado para determinadas situações do que o outro.\nUma das principais vantagens do documento tipo Quarto é que ele permite criar um ambiente de trabalho personalizado que combina códigos, gráficos, tabelas e textos explicativos, além de oferecer recursos avançados como gráficos interativos e tabelas dinâmicas. Isso faz com que seja uma ferramenta muito útil para análises de dados complexas, em que é necessário organizar e documentar os procedimentos utilizados e também compartilhar os resultados com outras pessoas.\nUma desvantagem do RNotebook em relação ao documento tipo quarto é que ele pode ser mais limitado em termos de personalização do ambiente de trabalho, uma vez que segue um modelo de formato fixo. Além disso, os R Notebooks podem ser mais complexos de editar e compartilhar com outras pessoas que não estão familiarizadas com o R.\nEm resumo, ambos os formatos de arquivo oferecem recursos úteis para análises de dados, mas o documento tipo quarto é um formato mais moderno, com mais opções de formatação e mais interativo.\n\n\n\n\n\nMeu Primeiro Documento Quarto no R"
  },
  {
    "objectID": "04-R-Projects.html#conceitos-e-vantagens",
    "href": "04-R-Projects.html#conceitos-e-vantagens",
    "title": "5  Projetos do R",
    "section": "5.1 Conceitos e Vantagens",
    "text": "5.1 Conceitos e Vantagens\nProjetos no R são uma maneira organizada e eficiente de gerenciar seu trabalho de análise de dados. Um projeto no R cria um ambiente isolado onde todos os arquivos relacionados ao seu trabalho específico são armazenados juntos, facilitando o gerenciamento e a reprodução de análises. Isso é especialmente útil quando se trabalha em múltiplos projetos ou quando se colabora com outras pessoas."
  },
  {
    "objectID": "04-R-Projects.html#diretórios-de-trabalho-working-directories",
    "href": "04-R-Projects.html#diretórios-de-trabalho-working-directories",
    "title": "5  Projetos do R",
    "section": "5.2 Diretórios de Trabalho (Working Directories)",
    "text": "5.2 Diretórios de Trabalho (Working Directories)\nPara entender melhor o que é um projeto no R, é essencial compreender o conceito de diretório de trabalho ou working directories.\nO diretório de trabalho é a pasta no seu computador onde o R lê e grava arquivos por padrão. Quando você inicia uma sessão do R, ele define um diretório de trabalho inicial. Se você não especificar um caminho completo para um arquivo, o R procurará esse arquivo no diretório de trabalho atual.\nOs diretórios de trabalho são importantes porque:\n\nOrganização: Eles ajudam a manter seus arquivos organizados.\nFacilidade de Acesso: Simplificam o acesso a arquivos, sem a necessidade de especificar caminhos completos.\nReprodutibilidade: Facilita a reprodução do trabalho, garantindo que todos os arquivos necessários estejam no mesmo lugar.\n\nO Working Directory (diretório de trabalho) é o local padrão onde o R procurará os arquivos que você deseja carregar e onde colocará todos os arquivos salvos. Toda sessão de trabalho com R tem uma diretório de trabalho associado. Para que o R possa ler um arquivo, é necessário que esse arquivo esteja na pasta do diretório de trabalho da sessão do R.\nSe o arquivo a ser lido estiver em outra pasta, será invisível para o RStudio.\nEntão uma das coisas mais importantes quando trabalhamos no RStudio é sabermos exatamente qual o diretório de trabalho estamos usando.\nO R tem duas funções básicas para lidar com o working directory:\n\ngetwd()\nsetwd(dir)\n\nA função getwd() indica qual o working directory atual, ou seja, indica qual folder o R está usando no momento.\nA função setwd() muda o working directory para o folder indicado como argumento.\nAlém dessas funções, você pode mudar o diretório de trabalho diretamente no menu do RStudio.\nPodemos indicar ao R que diretório da sessão de trabalho seja o diretório aberto naa aba Files. Para isso:\n\nclique em Session (no menu do RStudio)\nEm seguida em Set Working Directory\nEscolha a opção To Files Pane Location.\n\n\n\n\n\n\nCriando um Projeto\n\n\n\n\nEntretanto, esse é um método muito desajeitado e trabalhoso para fazer toda vez que se usar o RStudio. A melhor forma de resolver esse problema é usar sempre um Project do RStudio."
  },
  {
    "objectID": "04-R-Projects.html#projetos-no-r",
    "href": "04-R-Projects.html#projetos-no-r",
    "title": "5  Projetos do R",
    "section": "5.3 Projetos no R",
    "text": "5.3 Projetos no R\nUm projeto no R é essencialmente um diretório de trabalho bem organizado. Quando você cria um projeto no RStudio (um ambiente de desenvolvimento integrado para R), ele cria uma pasta específica para o projeto e define essa pasta como o diretório de trabalho sempre que você abre o projeto. Isso significa que todos os arquivos e scripts que você criar ou usar no projeto serão armazenados nessa pasta.\n\n5.3.1 Vantagens dos Projetos no R\n\nIsolamento: Cada projeto tem seu próprio diretório de trabalho, isolando os arquivos e pacotes específicos para esse projeto. Isso evita conflitos entre diferentes projetos.\nOrganização: Facilita a organização dos seus arquivos, scripts, dados e resultados em um único lugar.\nFacilidade de Compartilhamento: Você pode facilmente compartilhar o diretório do projeto com outras pessoas, garantindo que elas tenham acesso a todos os arquivos necessários para reproduzir sua análise.\nGerenciamento de Pacotes: Projetos no R podem ter seu próprio conjunto de pacotes, o que garante que todas as dependências necessárias estão disponíveis e na versão correta.\nReprodutibilidade: Mantém um ambiente consistente, o que é crucial para a reprodutibilidade das análises.\n\nA grande importância de criar um Projeto no RStudio é que um projeto define automaticamente seu diretório de trabalho.\nO nome do seu projeto aparece na barra na parte superior RStudio, e o caminho completo do diretório de trabalho aparece na barra superior do painel Console, como mostra a figura abaixo.\n\n\n\n\n\nCriando um Projeto\n\n\n\n\n\n\n5.3.2 Criando um Projeto no RStudio\nAntes de criar um projeto, é necessário criar primeiro a pasta que servirá de diretório de trabalho em seu computador e salvar nessa pasta os arquivos com os dados a serem analisados.\nPara criar um projeto (project) clique em Project (na parte superior à direta do RStudio) e em seguida em New Project.\nA seguir, escolha a opção Existing Directory - Associate a project with an existing directory.\nEm seguida, clique em Browse para encontrar a pasta existente e associá-la ao seu projeto.\nVideo de Criação de Projetos no RStudio https://youtu.be/YYRb_7yJSlQ\n\n\n5.3.3 Estrutura de pastas de um projeto\nEm geral uma pesquisa possui um monte de arquivos. Temos arquivos com os dados brutos, arquivos com dados modificados, arquivos em formatos específicos tal como Excel, Word, PDFs, artigos de referências, imagens, gráficos etc. Colocar tudo isso numa única pasta do projeto não é uma boa prática. A pasta do projeto fica caótica.\nA técnica ideal é criar um conjunto de subpastas dentro da pasta principal do projeto. Uma dessas pastas, talvez a mais importante, é a pasta de dados. Escolha um nome adequado, tal como dados, dataset, etc. E use essa pasta para armazenar o banco de dados de sua pesquisa.\nUm projeto no R geralmente inclui:\n\nScripts: arquivos .R contendo seu código, no formato Scripts, Notebooks, Quarto etc.\nDados: arquivos de dados que você está analisando (por exemplo, arquivos .csv, .xlsx).\nResultados: resultados das análise, gráficos e tabelas, criadas pelo seus scripts.\nDocumentação: arquivos de texto ou markdown documentando seu trabalho.\nConfigurações do Projeto: arquivos específicos do RStudio, como .Rproj, que armazena as configurações do projeto.\n\nVeja abaixo um exemplo de como organizar sua pasta do projeto:\n\n\n\n\n\nEstrutura de Diretórios de um Projeto"
  },
  {
    "objectID": "05-R-Objects-Variables-Vectors.html#tipos-de-dados-e-estruturas-de-dados",
    "href": "05-R-Objects-Variables-Vectors.html#tipos-de-dados-e-estruturas-de-dados",
    "title": "6  Objetos do R",
    "section": "6.1 Tipos de Dados e Estruturas de Dados",
    "text": "6.1 Tipos de Dados e Estruturas de Dados\nEm R, os tipos de dados e as estruturas de dados são conceitos fundamentais, mas distintos, que se complementam na manipulação de informações.\nOs tipos de dados referem-se às categorias de valores que R pode manipular. Cada tipo de dado determina o tipo de operação que pode ser realizada e a forma como os dados são armazenados. Por exemplo, o tipo numeric abrange números de ponto flutuante, enquanto integer inclui apenas valores inteiros. Character se refere a dados textuais ou strings, logical trata de valores booleanos (TRUE ou FALSE), e complex abrange números complexos. Existe também o tipo raw, que representa bytes brutos. Esses tipos de dados são fundamentais para definir as características básicas dos valores individuais em R.\nAs estruturas de dados, por outro lado, referem-se às maneiras como esses valores individuais podem ser organizados e armazenados em coleções. Enquanto os tipos de dados tratam de valores individuais, as estruturas de dados lidam com conjuntos de valores.\nVetores (Vectors) são estruturas unidimensionais homogêneas, onde todos os elementos são do mesmo tipo. Fatores (Factors) são usados para representar dados categóricos e são uma forma especializada de vetor. Listas (Lists) são estruturas heterogêneas, onde os elementos podem ser de diferentes tipos, oferecendo uma flexibilidade significativa na manipulação de dados complexos.\nMatrizes (Matrices) são bidimensionais e homogêneas, adequadas para dados tabulares. Arrays são uma extensão das matrizes para múltiplas dimensões, mantendo a homogeneidade dos dados. Data Frames são estruturas bidimensionais heterogêneas, onde cada coluna pode conter diferentes tipos de dados, sendo amplamente usados para manipulação de dados tabulares em análises estatísticas. Veremos adiantes que as Tibbles são data frames modernos.\nAlém disso, existem tipos especializados para trabalhar com datas e tempos, como Date para datas e POSIXct/POSIXlt para datetimes, permitindo a manipulação eficiente de informações temporais.\nA principal diferença entre tipos de dados e estruturas de dados reside na granularidade e na finalidade. Os tipos de dados definem as propriedades básicas e os comportamentos dos valores individuais. Já as estruturas de dados organizam esses valores em conjuntos, permitindo a manipulação de dados em níveis mais complexos e estruturados. Enquanto tipos de dados são o alicerce para os valores básicos, as estruturas de dados são a construção que permite a organização e a manipulação de coleções desses valores em R.\n\n\n\n\n\n\n\n\n\nCategory\nData Type\nR Name\nDescription\n\n\n\n\nTipos Básicos de dados\nNumeric\nnumeric\nDados numéricos gerais (dupla precisão)\n\n\n\nInteger\ninteger\nNúmeros inteiros\n\n\n\nCharacter\ncharacter\nTexto or string\n\n\n\nLogical\nlogical\nValores lógicos (TRUE or FALSE)\n\n\n\nComplex\ncomplex\nNúmeros Complexos\n\n\n\nRaw\nraw\nRaw bytes\n\n\nTipo Especial de dados\nFactor\nfactor\nDados categóricos\n\n\nEstructuras de Dados\nVector\nvector\nColeções homogêneas de tipos de dados básicos\n\n\n\nList\nlist\nColeções heterogêneas de tipos de dados\n\n\n\nMatrix\nmatrix\nEstruturas de dados bidimensionais e homogêneas\n\n\n\nArray\narray\nEstruturas de dados multidimensionais e homogêneas\n\n\n\nData Frame\ndata.frame\nEstruturas de dados bidimensionais e heterogêneas\n\n\nTipos especiais\nDate\nDate\nDatas\n\n\n\nPOSIXct\nPOSIXct\nDate-time\n\n\n\nPOSIXlt\nPOSIXlt\nDate-time\n\n\nOutros tipos\nNULL\nNULL\nRepresenta a ausência de um valor\n\n\n\nNA\nNA\nRepresenta um valor faltante\n\n\n\nNaN\nNaN\nRepresenta algo que Não é um Número\n\n\n\nInf\nInf\nRepresenta infinito positivo\n\n\n\n-Inf\n-Inf\nRepresenta infinito negativo\n\n\n\nEntretanto, antes de estudarmos os objetos do R, será útil rever os tipos de dados existentes numa pesquisa, lembrando que cada tipo de dado será armazenado numa variável de tipo diferente."
  },
  {
    "objectID": "05-R-Objects-Variables-Vectors.html#variáveis-no-r",
    "href": "05-R-Objects-Variables-Vectors.html#variáveis-no-r",
    "title": "6  Objetos do R",
    "section": "6.2 Variáveis no R",
    "text": "6.2 Variáveis no R\nA ciência depende de dados, que são gerados a partir de alguma forma de coleta ou transformação de outros dados. Tudo que poder ser contado ou quantificado será armazenado numa variável. Uma variável deve ser entendida como um objeto que contém os resultados dessa coleta ou transformação de dados.\nMas dados podem ser coletados de diferentes modos: algumas dados são provenientes de algo que foi contado, outros dados provém de algo que foi medido. Contar e medir fornecem diferentes tipos de dados. Podemos por exemplo, contar o número de pessoas com AIDS, o número de eleitores de um determinado político, o número de óbitos, de nascimentos etc. Por outro lado, podemos medir o perímetro cefálico de crianças recém-nascidas, o nível pressórico ou de glicemia de um grupo de pacientes, etc."
  },
  {
    "objectID": "05-R-Objects-Variables-Vectors.html#tipos-de-variáveis",
    "href": "05-R-Objects-Variables-Vectors.html#tipos-de-variáveis",
    "title": "6  Objetos do R",
    "section": "6.3 Tipos de Variáveis",
    "text": "6.3 Tipos de Variáveis\nVariáveis com dados provenientes de contagem são denominadas variáveis categóricas, também chamadas de variáveis qualitativas, pois podem expressar uma qualidade.\nVariáveis com dados provenientes de medidas são denominadas variáveis numéricas, também chamadas de variáveis quantitativas.\n\nAs variáveis categóricas (ou qualitativas) se dividem em nominais e ordinais.\nAs variáveis numéricas (ou quantitativas) por sua vez são tradicionalmente divididas em variáveis numéricas inteiras e numéricas contínuas.\n\nA necessidade de classificarmos as variáveis em diferentes tipos é devido ao fato de que o tipo de variável determina os tipos de operações matemáticas que podem ser realizadas e, consequentemente, as medidas estatísticas e os testes estatísticos que podem ser realizados.\nVeremos também que na computação existem outros tipos de variáveis, tais como variáveis lógicas, strings, caracteres etc.\n\n6.3.0.1 Variáveis Categóricas ou Qualitativas\nAlgumas variáveis são nomes que expressão uma qualidade (que podem ter ou não uma ordenação). Em estatística essas variáveis são chamadas categóricas e podem se dividir em nominais ou ordinais. Os dados que não possuem nenhuma ordenação, são armazenados em variáveis categóricas nominais.\nVariáveis categóricas nominais expressam qualidades, mas sem uma ordenação, tal como sexo, raça, local de nascimento etc.\nVariáveis categóricas ordinais também expressão qualidades, mas tem uma ordenação, tais como grau de obesidade (leve, moderado, grave), estancamento do câncer (estágio I, estágio II, estágio III) etc.\nNo R as variáveis categóricas são chamados de factor, independente de serem nominais ou ordinais. Caso sejam variáveis categóricas ordinais, ou seja, caso exista uma ordem certa entre os elementos, existem meios de indicar isso para o R.\nFrequentente precisamos indicar ao R que uma determinada variável é categórica. Em algumas situações o R pode interpretar uma variável como numérica quando na verdade é categórica. É usual em pesquisas em os sexos sejam codificados com números, por exemplo 0 = Masculino, 1 = Feminino. Nesse caso, a variável sexo iria ser interpretada no R como um vetor numérico. Entretanto, os elementos desse vetor não representam números de verdade, mas são apenas símbolos para indicar os sexo masculino ou feminino.\nVejamos um exemplo num conjunto fictício de dados de uma pesquisa com nomes, sexo e idade de alguns participantes. Esse conjunto de dados será armazenado num objeto do tipo data frame. Esse tipo de objeto será discutido mais adiante, por enquanto basta entender que um data frame é como uma planilha, com linhas e colunas. Nesse exemplo nosso data frame será denominado de df. Poderíamos escolher qualquer outro nome. Iremos discutir mais sobre esses objetos no capítulo adiante sobre Dataframes e Tibbles (Chapter 7).\nNo código abaixo você irá ver também um operador do R, o operador de atribuição: <- que indica que o que está à direita do operador será atribuido ao objeto à esquerda. Iremos detalhar mais sobre isso no capítulo adiante sobre operadores do R (?sec-operadores).\n\n# criando os vetores com os dados\nnome  <- c(\"Eduardo\",\"José\",\"Antônio\",\"Pedro\",\"Maria\",\"Gustavo\")\nsexo  <- c(0,  0,  0,  0,  1,  0)\nidade <- c(50, 45, 49, 60, 32, 39)\n\n# criando o data frame:\ndf <- data.frame(nome, sexo, idade)\n\n# mostrando  o data frame\ndf\n\n     nome sexo idade\n1 Eduardo    0    50\n2    José    0    45\n3 Antônio    0    49\n4   Pedro    0    60\n5   Maria    1    32\n6 Gustavo    0    39\n\n\nVeja que para o R, a variável tando a sexo como a idade são numéricas (dbl).\nPara contornar esse problema precisamos informar ao R que sexo é uma variável categórica. Isso pode ser feito com a função as.factor().\nPodemos fazer isso com o vetor sexo antes de criar o banco de dados:\n\n# criando os vetores com os dados\nnome  <- c(\"Eduardo\",\"José\",\"Antônio\",\"Pedro\",\"Maria\",\"Gustavo\")\nsexo  <- c(0,  0,  0,  0,  1,  0)\nidade <- c(50, 45, 49, 60, 32, 39)\n\n# transformando sexo em factor\nsexo <- as.factor(sexo)\n\n# criando o o data frame\ndf <- data.frame(nome, sexo, idade)\n\n# mostrando  o data frame\ndf\n\n     nome sexo idade\n1 Eduardo    0    50\n2    José    0    45\n3 Antônio    0    49\n4   Pedro    0    60\n5   Maria    1    32\n6 Gustavo    0    39\n\n\nPodemos fazer isso depois de criar o banco de dados:\n\nnome  <- c(\"Eduardo\",\"José\",\"Antônio\",\"Pedro\",\"Maria\",\"Gustavo\")\nsexo  <- c(0,  0,  0,  0,  1,  0)\nidade <- c(50, 45, 49, 60, 32, 39)\n\n# criando o banco de dados:\ndf <- data.frame(nome, sexo, idade)\n\n# transformando a variável sexo do data frame df em factor\ndf$sexo <- as.factor(df$sexo)\n\n# mostrando o data frame\ndf\n\n     nome sexo idade\n1 Eduardo    0    50\n2    José    0    45\n3 Antônio    0    49\n4   Pedro    0    60\n5   Maria    1    32\n6 Gustavo    0    39\n\n\nCaso seja interessante renomear os elementos, transformando 0 em “Masc” e 1 em “Fem” podemos usar a função recode_factor do pacote dplyr. Iremos discutir esse pacote mais adiante, portanto, não se preocupe em entender o código abaixo por enquanto, veja apenas que podemos fazer isso facilmente com essa função.\n\n# recodificando os elementos da variável sexo\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndf$sexo <- recode_factor(df$sexo, \"0\" = \"Masc\", \n                                  \"1\" = \"Fem\")\n\n# mostrando novamente o data frame\ndf\n\n     nome sexo idade\n1 Eduardo Masc    50\n2    José Masc    45\n3 Antônio Masc    49\n4   Pedro Masc    60\n5   Maria  Fem    32\n6 Gustavo Masc    39\n\n\nAs variáveis categóricas não podem ser usadas em operações aritméticas. Não podemos, por exemplo, calcular a média desse tipo de variável. O que podemos fazer com variáveis categóricas é construir tabelas de frequências de cada categoria.\nOu seja, podemos pedir ao R para contar o número absoluto ou a freqüência relativa dos resultados. A função para tabular os dados de variáveis categóricas é table().\n\ntable(df$sexo)\n\n\nMasc  Fem \n   5    1 \n\n\nPodemos calcular os percentuais facilmente com a função prop.table(), como mostrado abaixo:\n\nprop.table(table(df$sexo))\n\n\n     Masc       Fem \n0.8333333 0.1666667 \n\n\nMais adiante veremos como deixar esse código mais elegante usando um operador chamado pipe |>.\n\ndf$sexo |>         # busque a variável sexo no data frame df\n  table() |>       # calcule as quantidade de cada sexo\n  prop.table() |>  # calcule o percentual de cada sexo\n  round(2)         # arredondo para 2 casas decimais\n\n\nMasc  Fem \n0.83 0.17 \n\n\n\n\n6.3.0.2 Variáveis Numéricas ou Quantitativas\nAs variáveis quantitativas (numéricas) são resultado de alguma medida realizada. Podem ser números inteiros (discretas) ou reais (contínuas). A grande diferença dessas variáveis com as qualitativas é que com as variáveis numéricas podemos fazer todas operações matemáticas: somar, dividir, calcular a média, a variância, o desvio padrão etc.\n\n6.3.0.2.1 Cuidado: representando valores decimais no R\nUma questão importante:\nNo R o separador decimal é o ponto final e não a vírgula, portanto o valor de metade de 1 é 0.5. Cuidado para não usar a vírgula como separador dos decimais.\nNo R a vírgula separa elementos.\n\nidade <- c(45,10,12) \nclass(idade) \n\n[1] \"numeric\"\n\n\nNo exemplo acima criamos uma variável numérica chamada idade, e atribuímos a essa variável o conjunto de valores 45, 10 e 12.\nNa linha seguinte usamos a função class( ) para que o R nos informasse o tipo dessa variável, confirmando que foi criada uma variável numérica.\nO R já tem um enorme conjunto de funções pré definidas para fazer operações matemáticas e estatísticas. Veremos mais adiante o funcionamento dessas funções com mais detalhes.\nVeja nos códigos a seguir alguns exemplos de como usar essas funções do R em variáveis numéricas.\n\n# calcula a média de todos os valores da variável idade\nmean(idade)\n\n[1] 22.33333\n\n\n\n# calcula a mediana de todos os valores da variável idade\nmedian(idade)\n\n[1] 12\n\n\n\n# calcula a variância \nvar(idade)\n\n[1] 386.3333\n\n\n\n# calcula o desvio padrão\nsd(idade)\n\n[1] 19.65536\n\n\n\n# calcula a raiz quadrada de cada um dos valores da variável\nsqrt(idade)\n\n[1] 6.708204 3.162278 3.464102\n\n\n\n# soma todos os valores\nsum(idade)\n\n[1] 67\n\n\nA função summary() já foi demonstrada anteriormente.\n\n# soma todos os valores\nsummary(idade)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.00   11.00   12.00   22.33   28.50   45.00 \n\n\n\n\n\n6.3.0.3 Variáveis Lógicas\nVariáveis lógicas são aquelas que armazenam resultados de operações lógicas. Operações lógicas são aquelas realizadas através de relacionais: igual, maior, maior ou igual, menor, menor ou igual, etc. Como já vimos resultado dessas operação não é um número, mas sim FALSO ou VERDADEIRO, e esse resultado pode ser armazenada numa variável. No exemplo uma operação lógica é realizada e seu resultado é colocado numa variável chamada teste.\n\na <- 2\nb <- 3\nteste <- (b > a)\nteste\n\n[1] TRUE\n\n\nPodemos confirmar que a variável é do tipo lógica com a função class( ).\n\nclass(teste)\n\n[1] \"logical\"\n\n\nPara visualizarmos o conteúdo de uma variável basta digitar o nome da variável.\n\nteste\n\n[1] TRUE\n\n\nVeja que o valor da variável teste é TRUE, pois 3 é realmente maior que 2. Um ponto importante a ser memorizado é que em linguagens de programação é usual que TRUE tenha o valor de 1 e FALSE tenha o valor de 0."
  },
  {
    "objectID": "05-R-Objects-Variables-Vectors.html#vetores-no-r",
    "href": "05-R-Objects-Variables-Vectors.html#vetores-no-r",
    "title": "6  Objetos do R",
    "section": "6.4 Vetores no R",
    "text": "6.4 Vetores no R\nVetores são objetos fundamentais de todas linguagens computacionais. Um vetor é um conjunto de elementos da mesma natureza. Por exemplo, um conjunto de números, um conjunto de palavras, etc.\n\n6.4.0.1 A função c()\nA função c(), abreviação de “combine” ou “concatenate” (combinar ou concatenar), é uma das funções mais frequentemente usadas no R. Ela permite que você crie conjuntos combinando elementos individuais em uma única estrutura coesa. Esta função é incrivelmente versátil, permitindo a construção de vetores, que são o tipo mais simples de conjuntos em R. Vetores são coleções ordenadas de elementos e servem como blocos de construção para estruturas de dados mais complexas, como matrizes, data frames e listas.\nA forma mais comum de criar um vetor no R é através do uso do comando c() como mostrado a seguir.\n\n6.4.0.1.1 Criando um vetor numérico determinado conjunto de números\n\nidades <- c(45, 32, 24, 23, 55, 56) \n\n\n\n6.4.0.1.2 Criando um vetor com uma sequencia de números\n\nx <- c(1:10)\n\nNo exemplo acima vimos um novo operador : (dois pontos), que cria uma sequencia de números. No capítulo sobre operadores do R iremos discutir melhor o que são operadores e quais os operadores do R @ref(operadores).\nMais adiante veremos como podemos agrupar um conjunto de vetores num objeto chamado de data frame, formado por colunas e linhas tal como uma planilha.\n\n\n6.4.0.1.3 Criando um vetor com nomes dos pacientes:\n\nnomes <- c(\"Eduardo\",\"José\",\"Antônio\",\"Pedro\",\"Maria\",\"Gustavo\")\n\n\n\n\n6.4.0.2 Manipulando Vetores\n\n\n6.4.1 A Vantagem do R Ser uma Linguagem Vetorial\nUma das principais vantagens do R é ser uma linguagem vetorial. Isso significa que o R realiza operações em vetores de maneira eficiente e intuitiva.\nEm linguagens não vetoriais, operações em conjuntos de dados geralmente requerem loops explícitos, que podem ser lentos e complexos de escrever. No R, a maioria das operações aritméticas e lógicas pode ser aplicada diretamente a vetores, permitindo código mais conciso, legível e de melhor desempenho.\n\n6.4.1.1 Benefícios do R como Linguagem Vetorial:\n\nEficiência: Operações em vetores são implementadas de maneira otimizada em R, resultando em desempenho superior comparado a loops explícitos.\nConcisão: O código que usa vetores é geralmente mais curto e mais fácil de entender, o que reduz a probabilidade de erros.\nOperações em Conjunto: R permite aplicar operações aritméticas e lógicas diretamente a vetores inteiros, facilitando a manipulação de grandes conjuntos de dados.\nFacilidade de Uso: As operações vetoriais em R são intuitivas e facilitam o trabalho com dados tabulares e séries temporais, comuns em análises médicas e científicas.\n\n\n\n6.4.1.2 Exemplos de Operações Vetoriais no R\n\nAritmética Vetorial: Operações aritméticas podem ser aplicadas diretamente a vetores.\n\n\n# Criando vetores numéricos\na <- c(1,  2,  3, 4 ,  5)\nb <- c(10, 20, 30, 40, 50)\nc <- c(10, 20, 31, 41, 51)\n\n\n# Adição de vetores: soma os elementos nas posições equivalentes.\n a + b\n\n[1] 11 22 33 44 55\n\n\nVeja que a soma de a + b resultou num outro vetor: 11 22 33 44 55.\nNo exemplo abaixo e nos seguintes iremos armazenar esse novo vetor num outro objeto (outro vetor) para futuras análises.\n\n# criando um vetor y que será o resultado da soma dos vetores a e b\ny <- a + b \n# mostrando o vetor y\nprint(y) \n\n[1] 11 22 33 44 55\n\n\n\n# criando um vetor w que será o resultado da subtração dos vetores b e a\nw <- b - a\n# mostrando o vetor w\nprint(w)\n\n[1]  9 18 27 36 45\n\n\n\nOperações Lógicas: Comparações lógicas podem ser feitas diretamente entre elementos dos vetores.\n\n\n# Comparando elementos de um vetor numérico com um determinado valor\n# o resultado será armazenado num vetor chamado de z\nz <- a > 3\n# mostrando o vetor z\nprint(z)\n\n[1] FALSE FALSE FALSE  TRUE  TRUE\n\n\n\n# Comparando elementos de dois vetores: compara elementos em posições equivalentes\n# o resultado será armazenado num vetor chamado de comparacao\ncomparacao <- b == c\n# mostrando o vetor comparacao\nprint(comparacao) \n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\n\n\nFunções Aplicadas a Vetores: Muitas funções em R são vetorizadas, o que significa que elas podem ser aplicadas diretamente a vetores inteiros.\n\n\n# Calculando a média de um vetor numérico\nmean(a)\n\n[1] 3\n\n\n\n# Calculando a soma de um vetor\nsum(a)\n\n[1] 15\n\n\n\nOperações Elemento-a-Elemento: A aplicação de funções a cada elemento de um vetor é direta.\n\nVamos imaginar a situação na qual temos um vetor com os dados de peso em libras de um conjunto de pacientes e precisamos transformar esses dados em quilos. Para isso basta multiplicar o vetor pelo valor adequado.\nNo exemplo a seguir, o vetor peso_lib contém valores do peso em libras e o vetor altura_metros contém valores de altura em metros de 15 pacientes.\nA conversão para quilogramas é realizada multiplicando cada elemento pelo fator de conversão 0.45359237. Armazenaremos o resultado desses cálculos no vetor peso_kg.\n\n# Vetor de pesos em libras com 15 elementos\npeso_lib <- c(120, 135, 150, 165, 180, \n              195, 210, 225, 240, 255, \n              270, 285, 300, 315, 330)\n\naltura_metros <- c(1.50, 1.55, 1.60, 1.65, 1.70, \n                   1.75, 1.80, 1.85, 1.90, 1.95, \n                   2.00, 2.05, 2.10, 2.15, 2.20)\n\n\n# Convertendo para quilogramas todos os valores do vetor de uma só vez.\npeso_kg <- peso_lib * 0.45359237\n\n# mostrando os resultados armazenados no novo vetor pesos_kg\nprint(peso_kg)\n\n [1]  54.43108  61.23497  68.03886  74.84274  81.64663  88.45051  95.25440\n [8] 102.05828 108.86217 115.66605 122.46994 129.27383 136.07771 142.88160\n[15] 149.68548\n\n\nSe quisermos construir um novo vetor com o índice de massa corporal (imc) vamos precisar de um vetor com a altura elevada ao quadrado. Isso pode ser feito também de forma simples e rápida no R apenas elevando o vetor de alturas ao quadrado como mostrado abaixo.\n\naltura2 <- altura_metros^2\naltura2 \n\n [1] 2.2500 2.4025 2.5600 2.7225 2.8900 3.0625 3.2400 3.4225 3.6100 3.8025\n[11] 4.0000 4.2025 4.4100 4.6225 4.8400\n\n\nCriar um vetor com o imc agora ficou fácil:\n\nimc <- peso_kg/altura2\nimc\n\n [1] 24.19159 25.48802 26.57768 27.49045 28.25143 28.88180 29.39951 29.81981\n [9] 30.15573 30.41842 30.61748 30.76117 30.85662 30.91003 30.92675\n\n\nPoderiamos também ter feito tudo isso de forma mais simples numa única operação:\n\nimc <- (peso_lib * 0.45359237)/(altura_metros^2)\nimc\n\n [1] 24.19159 25.48802 26.57768 27.49045 28.25143 28.88180 29.39951 29.81981\n [9] 30.15573 30.41842 30.61748 30.76117 30.85662 30.91003 30.92675\n\n\n\nCombinação de Vetores: A combinação de vetores é simples e intuitiva.\n\n\n# Combinando vetores\nc <- c(a, b)\nprint(c) \n\n [1]  1  2  3  4  5 10 20 30 40 50\n\n\nEsses exemplos ilustram a eficácia e a simplicidade das operações vetoriais em R. Ao aproveitar essas capacidades, você pode escrever código mais eficiente e legível, facilitando a análise e manipulação de grandes conjuntos de dados comuns na prática médica e em pesquisas científicas."
  },
  {
    "objectID": "05-R-Objects-Variables-Vectors.html#matrizes-do-r",
    "href": "05-R-Objects-Variables-Vectors.html#matrizes-do-r",
    "title": "6  Objetos do R",
    "section": "6.5 Matrizes do R",
    "text": "6.5 Matrizes do R\nAs matrizes são uma das estruturas de dados fundamentais em R, amplamente utilizadas para armazenar e manipular dados numéricos. Uma matriz é uma coleção bidimensional de elementos, organizados em linhas e colunas. Cada elemento em uma matriz deve ser do mesmo tipo de dado, o que as torna ideais para operações matemáticas e estatísticas.\n\n6.5.1 Criando Matrizes\nPara criar uma matriz em R, utilizamos a função matrix(). Por exemplo, para criar uma matriz de 2 linhas e 3 colunas contendo os números de 1 a 6, podemos usar o seguinte código:\n\nminha_matriz <- matrix(1:6, nrow = 2, ncol = 3)\nprint(minha_matriz)\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n\n\n\n6.5.2 Acessando Elementos de uma Matriz\nOs elementos de uma matriz podem ser acessados utilizando a notação de índice [linha, coluna]. Por exemplo, para acessar o elemento na primeira linha e segunda coluna da matriz minha_matriz, usamos:\n\nminha_matriz[1, 2]\n\n[1] 3\n\n\n\n\n6.5.3 Operações com Matrizes\nUma das vantagens das matrizes é a facilidade de realizar operações matemáticas. Podemos realizar adição, subtração, multiplicação e divisão diretamente entre matrizes ou entre uma matriz e um escalar.\n\n6.5.3.1 Adição e Subtração\nPara adicionar duas matrizes de mesmas dimensões, utilizamos o operador +:\n\nmatriz_a <- matrix(1:4, nrow = 2)\nmatriz_b <- matrix(5:8, nrow = 2)\nmatriz_c <- matriz_a + matriz_b\nprint(matriz_c)\n\n     [,1] [,2]\n[1,]    6   10\n[2,]    8   12\n\n\n\n\n6.5.3.2 Multiplicação\nA multiplicação elementar (elemento a elemento) é feita com o operador *, enquanto a multiplicação de matrizes (produto matricial) é feita com a função %*%:\n\nproduto_elementar <- matriz_a * matriz_b\nproduto_matricial <- matriz_a %*% matriz_b\n\n\n\n\n6.5.4 Funções Úteis com matrizes\nR oferece uma série de funções úteis para trabalhar com matrizes, tais como:\n\nt(): Transposta de uma matriz.\nsolve(): Inversa de uma matriz quadrada.\ndet(): Determinante de uma matriz.\n\nAs matrizes são essenciais para muitos métodos estatísticos e análises de dados em R, servindo como a base para outras estruturas de dados mais complexas, como arrays e data frames. Entender e dominar o uso de matrizes é fundamental para qualquer pessoa que deseje utilizar R de forma eficaz em análises de dados na área da saúde."
  },
  {
    "objectID": "05-R-Objects-Variables-Vectors.html#arrays-do-r",
    "href": "05-R-Objects-Variables-Vectors.html#arrays-do-r",
    "title": "6  Objetos do R",
    "section": "6.6 Arrays do R",
    "text": "6.6 Arrays do R\nArrays são uma estrutura de dados em R que permitem armazenar dados multidimensionais. Enquanto matrizes são restritas a duas dimensões (linhas e colunas), arrays podem ter qualquer número de dimensões, tornando-os mais flexíveis para certas aplicações.\n\n6.6.1 Criando Arrays\nPara criar um array em R, utilizamos a função array(). A função requer um vetor de dados e um vetor de dimensões. Por exemplo, para criar um array tridimensional com dimensões 2x3x4, contendo os números de 1 a 24, podemos usar o seguinte código:\n\nmeu_array <- array(1:24, dim = c(2, 3, 4))\nprint(meu_array)\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    7    9   11\n[2,]    8   10   12\n\n, , 3\n\n     [,1] [,2] [,3]\n[1,]   13   15   17\n[2,]   14   16   18\n\n, , 4\n\n     [,1] [,2] [,3]\n[1,]   19   21   23\n[2,]   20   22   24\n\n\n\n\n6.6.2 Acessando Elementos de um Array\nOs elementos de um array podem ser acessados utilizando a notação de índice [dim1, dim2, dim3, ...]. Por exemplo, para acessar o elemento na primeira linha, segunda coluna e terceira camada do array meu_array, usamos:\n\nelemento <- meu_array[1, 2, 3]\nprint(elemento)\n\n[1] 15\n\n\n\n\n6.6.3 Operações com Arrays\nAssim como as matrizes, arrays suportam operações matemáticas. Podemos realizar operações entre arrays de mesmas dimensões ou entre um array e um escalar.\n\n6.6.3.1 Adição e Subtração\nPara adicionar dois arrays de mesmas dimensões, utilizamos o operador +:\n\narray_a <- array(1:12, dim = c(2, 3, 2))\narray_b <- array(13:24, dim = c(2, 3, 2))\narray_c <- array_a + array_b\nprint(array_c)\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]   14   18   22\n[2,]   16   20   24\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]   26   30   34\n[2,]   28   32   36\n\n\n\n\n6.6.3.2 Multiplicação\nA multiplicação elementar (elemento a elemento) é feita com o operador *:\n\nproduto_elementar <- array_a * array_b\nprint(produto_elementar)\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]   13   45   85\n[2,]   28   64  108\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]  133  189  253\n[2,]  160  220  288\n\n\n\n\n\n6.6.4 Funções Úteis\nR oferece uma série de funções úteis para trabalhar com arrays, tais como:\n\ndim(): Retorna as dimensões de um array.\napply(): Aplica uma função ao longo de uma margem (dimensão) de um array.\narrayInd(): Converte índices lineares para índices de array.\n\nOs arrays são particularmente úteis em análises de dados que envolvem múltiplas dimensões, como análise de imagens, séries temporais multivariadas e simulações complexas. Compreender como criar e manipular arrays é uma habilidade valiosa para utilizar o poder do R em análises de dados na área da saúde."
  },
  {
    "objectID": "05-R-Objects-Variables-Vectors.html#listas-do-r",
    "href": "05-R-Objects-Variables-Vectors.html#listas-do-r",
    "title": "6  Objetos do R",
    "section": "6.7 Listas do R",
    "text": "6.7 Listas do R\nAs listas são uma estrutura de dados poderosa e flexível em R, capazes de armazenar diferentes tipos de elementos, como vetores, matrizes, arrays, data frames e até outras listas. Essa flexibilidade torna as listas ideais para agrupar dados heterogêneos em uma única estrutura.\n\n6.7.1 Criando Listas\nPara criar uma lista em R, utilizamos a função list(). Podemos incluir qualquer tipo e quantidade de elementos dentro de uma lista. Alias, uma lista pode conter até mesmo outras listas. O exemplo abaixo é uma lista de pacientes, onde cada paciente é uma lista com diversos elementos.\n\n# Carregando a biblioteca necessária\nlibrary(tibble)\n\n# Criando a lista de pacientes\npacientes <- list(\n  paciente_1 = list(idade = 34,\n                    sexo = \"Feminino\",\n                    altura = 1.65,\n                    peso = 62,\n                    diagnostico = \"Transtorno de Ansiedade Generalizada\",\n                    data_nascimento = as.Date(\"1990-04-15\"),\n                    escolaridade = \"Ensino Superior Completo\",\n                    fumante = FALSE),\n  paciente_2 = list(idade = 45,\n                    sexo = \"Masculino\",\n                    altura = 1.75,\n                    peso = 85,\n                    diagnostico = \"Depressão Major\",\n                    data_nascimento = as.Date(\"1979-11-23\"),\n                    escolaridade = \"Ensino Médio Completo\",\n                    fumante = TRUE),\n  paciente_3 = list(idade = 29,\n                    sexo = \"Feminino\",\n                    altura = 1.60,\n                    peso = 55,\n                    diagnostico = \"Asma\",\n                    data_nascimento = as.Date(\"1995-03-30\"),\n                    escolaridade = \"Ensino Superior Incompleto\",\n                    fumante = FALSE),\n  paciente_4 = list(idade = 52,\n                    sexo = \"Masculino\",\n                    altura = 1.80,\n                    peso = 90,\n                    diagnostico = \"Esquizofrenia\",\n                    data_nascimento = as.Date(\"1972-06-10\"),\n                    escolaridade = \"Ensino Fundamental Completo\",\n                    fumante = TRUE),\n  paciente_5 = list(idade = 40,\n                    sexo = \"Feminino\",\n                    altura = 1.70,\n                    peso = 70,\n                    diagnostico = \"Doença Pulmonar Obstrutiva Crônica\",\n                    data_nascimento = as.Date(\"1984-01-25\"),\n                    escolaridade = \"Ensino Médio Incompleto\",\n                    fumante = TRUE))\n\n\n\n6.7.2 Acessando Elementos de uma Lista\nOs elementos de uma lista podem ser acessados de várias maneiras. A notação $ é usada para acessar elementos nomeados:\n\n# Acessando um determinado paciente\npacientes$paciente_1\n\n$idade\n[1] 34\n\n$sexo\n[1] \"Feminino\"\n\n$altura\n[1] 1.65\n\n$peso\n[1] 62\n\n$diagnostico\n[1] \"Transtorno de Ansiedade Generalizada\"\n\n$data_nascimento\n[1] \"1990-04-15\"\n\n$escolaridade\n[1] \"Ensino Superior Completo\"\n\n$fumante\n[1] FALSE\n\n\nPodemos usar esse mesmo operador $ em sequencia para acessar um informação de uma lista que está dentro de outro lista. Poe exemplo o sexo do paciente_1.\n\n# Acessando uma informação de uma lista, dentro de outro lista\npacientes$paciente_1$sexo\n\n[1] \"Feminino\"\n\n\nEnquanto a notação $ é usada para acessar elementos nomeados, A notação [[ ]] é utilizada para acessar elementos individuais,\n\n# Acessando o vetor\npacientes$paciente_1$sexo\n\n[1] \"Feminino\"\n\n\nVeremos adiante que diversos pacotes do R possuem funcionalidades para melhorar o código, como o pacote purrr do tidyverse tem a função pluck():\n\n# Usando a função pluck do purrr\nlibrary(purrr)\npluck(pacientes, \"paciente_1\", \"sexo\")\n\n[1] \"Feminino\"\n\n\nNa seção de análises estatísticas você verá que muitos das análises tem como resultado uma lista e voê precisará acessar os elementos dessa lista para obter as informções específicas que deseja, tal como, por exemplo, o valor de p. Vamos criar uma matriz de exemplo e realizar um teste do chi quadrado.\n\nmydata <- matrix(c(35,13,29,17,12,21),nrow=3,ncol=2)\nmytest <- chisq.test(mydata,correct=FALSE)\nmytest\n\n\n    Pearson's Chi-squared test\n\ndata:  mydata\nX-squared = 1.8963, df = 2, p-value = 0.3875\n\n\n\nstr(mytest)\n\nList of 9\n $ statistic: Named num 1.9\n  ..- attr(*, \"names\")= chr \"X-squared\"\n $ parameter: Named int 2\n  ..- attr(*, \"names\")= chr \"df\"\n $ p.value  : num 0.387\n $ method   : chr \"Pearson's Chi-squared test\"\n $ data.name: chr \"mydata\"\n $ observed : num [1:3, 1:2] 35 13 29 17 12 21\n $ expected : num [1:3, 1:2] 31.53 15.16 30.31 20.47 9.84 ...\n $ residuals: num [1:3, 1:2] 0.618 -0.554 -0.239 -0.767 0.688 ...\n $ stdres   : num [1:3, 1:2] 1.283 -0.985 -0.489 -1.283 0.985 ...\n - attr(*, \"class\")= chr \"htest\"\n\n\nObserve que o resultado do teste chi-quadrado é uma lista. Para acessarmos o valor de p vamos prescisar acessar essa lista usando o operador $. Podemos, se precisarmos, armazenar esse valor numa variável.\n\np <- mytest$p.value\np\n\n[1] 0.3874529\n\n\nResumindo, as listas são uma ferramenta essencial em R para trabalhar com dados complexos e heterogêneos, permitindo que você agrupe diferentes tipos de informações em uma única estrutura. Essa capacidade é especialmente útil na análise de dados na área da saúde, onde os dados frequentemente variam em tipo e formato. Em suas análises você frequentemente irá lidar com listas e precisará acessar os elementos individuais dessas listas."
  },
  {
    "objectID": "05-R-Objects-Variables-Vectors.html#nomes-de-variáveis-e-objetos",
    "href": "05-R-Objects-Variables-Vectors.html#nomes-de-variáveis-e-objetos",
    "title": "6  Objetos do R",
    "section": "6.8 Nomes de Variáveis e Objetos",
    "text": "6.8 Nomes de Variáveis e Objetos\nUma variável é um objeto que armazena dados, tais como valores numéricos, datas, caracteres, palavras, valores lógicos etc. Uma variável é um objeto para armazenar um determinado tipo de dado de uma pesquisa. Se uma variável de minha pesquisa é a medida da pressão dos pacientes, posso no R criar um a variável chamada pa, nivel.pressorico ou pressao.arterial para armazenar esse conjunto de dados.\n\n6.8.1 Estilos de nomeação de variáveis e objetos\nComo você deve ter notado, variáveis devem ter nomes fáceis de serem compreendidos, nomes que mostrem o que significam. Se uma variável serve para armazenar a glicemia é mais adequado que essa variável seja denominada glicemia do que apenas x. Por outro lado, devemos usar nomes sucintos e evitar nomes grandes, glicemia é mais apropriado do que nivel.de.glicose, que é demasiadamente extenso.\n\n\n6.8.2 Nomes compostos\nEntretanto, quando houver necessidade de usar nomes compostos, um modo dequado é usar um ponto separando as palavras, tais como: glico.fem ou idade.media.\nEvite usar o underline em variáveis, a separação de palavras pelo o underline é geralmente usado para nomear arquivos tais como: research_results_fase_1.csv.\nEvite usar maiúsculas para separar as palavras de uma variável, pois esse estilo geralmente é usado para nomear funções, tal como em solveEquation. Veja que as palavras são separadas pelo uso de uma maiúscula no início das palavras, exceto a primeira. Esse modo criar nomes é geralmente usado para nomearmos funções, portanto, vamos evitar fazer isso ao criarmos nomes de variáveis.\nAlém dessa dica, existem regras formais para criar nomes de variáveis:\n1. O nome de uma variável deve SEMPRE começar com uma letra.\n2. O nome de uma variável NÃO pode começar com números ou caracteres especiais.\n3. O nome de uma variável NÃO pode conter espaços.\n4. O nome de uma variável NÃO pode conter caracteres com acentos gramaticais.\nEsse último ponto é importante: o nome de uma variável não pode conter acentos. É importante para usuários da língua portuguesa se atentarem a isso ao criarem variáveis em suas pesquisas.\n\n\n6.8.3 Case Sensitive\nUm ponto importante: o R é case sensitive, ou seja, maiúsculas e minúsculas são considerados caracteres diferentes: portanto as variáveis idade e Idade são diferentes. A dica é evitar usar maiúsculas em nomes de variáveis, para não criar confusão."
  },
  {
    "objectID": "05-R-Objects-Variables-Vectors.html#examinando-objetos-do-r",
    "href": "05-R-Objects-Variables-Vectors.html#examinando-objetos-do-r",
    "title": "6  Objetos do R",
    "section": "6.9 Examinando objetos do R",
    "text": "6.9 Examinando objetos do R\nA linguatem R possui muitas funções para examinar as características de objetos, por exemplo:\n\nclass() - retorna o tipo de objeto\ntypeof() - retorna o tipo de dados do objeto\nstr() - retorna a estrutura do objeto\nlength() -retorna o tamanho do objeto\nattributes() - retorna os metadados do objeto\n\nVeja o funcionamento dessas funções aplicada a uma variável simples:\n\n# criando uma variável numérica\nx <- 3\n\n# examinando a variável x\nclass(x)\n\n[1] \"numeric\"\n\ntypeof(x)\n\n[1] \"double\"\n\nlength(x)\n\n[1] 1\n\nattributes(x)\n\nNULL\n\nstr(x)\n\n num 3\n\n\nOu seja, é um objeto da classe “numeric”, do tipo “double”, de tamanho “1”. Não há atributos. Finalmente, sua estrutura é apenas o valor “3”, do tipo numérico.\n\nnome <- \"José\"\nclass(nome)\n\n[1] \"character\"\n\ntypeof(nome)\n\n[1] \"character\"\n\nlength(nome)\n\n[1] 1\n\nattributes(nome)\n\nNULL\n\nstr(nome)\n\n chr \"José\"\n\n\n\nteste <- FALSE\nclass(teste)\n\n[1] \"logical\"\n\ntypeof(teste)\n\n[1] \"logical\"\n\nlength(teste)\n\n[1] 1\n\nattributes(teste)\n\nNULL\n\nstr(teste)\n\n logi FALSE\n\n\nVamos aplicar agora essas funções em alguns vetores:\n\nz <- c(1, 2, 3)\nclass(z)\n\n[1] \"numeric\"\n\ntypeof(z)\n\n[1] \"double\"\n\nlength(z)\n\n[1] 3\n\nattributes(z)\n\nNULL\n\nstr(z)\n\n num [1:3] 1 2 3\n\n\n\nfrutas <- c(\"bananas\", \"maçãs\", \"melão\")\nclass(frutas)\n\n[1] \"character\"\n\ntypeof(frutas)\n\n[1] \"character\"\n\nlength(frutas)\n\n[1] 3\n\nattributes(frutas)\n\nNULL\n\nstr(frutas)\n\n chr [1:3] \"bananas\" \"maçãs\" \"melão\"\n\n\nVeja agora como a função str() nos ajuda a compreender melhor a estrutura de conjunto de dados num dataset, usando o dataset esoph do R, que contém dados de um estudo de caso controle de câncer de esôfago na frança.\n\nstr(esoph)\n\n'data.frame':   88 obs. of  5 variables:\n $ agegp    : Ord.factor w/ 6 levels \"25-34\"<\"35-44\"<..: 1 1 1 1 1 1 1 1 1 1 ...\n $ alcgp    : Ord.factor w/ 4 levels \"0-39g/day\"<\"40-79\"<..: 1 1 1 1 2 2 2 2 3 3 ...\n $ tobgp    : Ord.factor w/ 4 levels \"0-9g/day\"<\"10-19\"<..: 1 2 3 4 1 2 3 4 1 2 ...\n $ ncases   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ncontrols: num  40 10 6 5 27 7 4 7 2 1 ...\n\n\nComo podemos ver acima a função str() mostrou a estrutura desse data frame. Podemos ver que as variáveis agegp, alcgp e tobgp são variáveis categóricas ordinais, ou seja, tem uma ordenação.\nUsando o comando ?esoph podemos descobrir o significado exato de cada variável.\n\n# use esse comando no console e veja o significado de cada elemento do data frame na aba help no painel à direita inferior do Rstudio.\n?esoph\n\n\nA variável agegp indica a faixa etária do participante e tem seis níveis de faixas etárias\nA variável alcgp indica a quantidade de alcool que o participante consome em gramas por dia e tem 4 níveis\nA variável tobgp indica a quantidade de tabaco que o participante consome em gramas por dia e tem 4 níveis\nAs variáveis ncases e ncontrols são numéricas."
  },
  {
    "objectID": "06-Dataframes-and-Tibbles.html#data-frames",
    "href": "06-Dataframes-and-Tibbles.html#data-frames",
    "title": "7  Data Frames e Tibbles",
    "section": "7.1 Data frames",
    "text": "7.1 Data frames\nData frames são a forma usual do R para armazenar dados. Veremos depois que as tibbles são a versão mais nova dos data frames, com melhorias em vários aspectos.\nSuperficialmente os data frames e as tibbles são como planilhas do Excel, com colunas e linhas, onde cada coluna é uma variável da pesquisa (ex: sexo, idade, peso) e cada linha uma observação (ex: um paciente ou um caso).\n\n\n\n\n\nExemplo de data frame\n\n\n\n\nO R possui vários datasets (conjuntos de dados) para facilitar o aprendizado. Para saber mais sobre os datasets inclusos no R digite no console o comando abaixo: > data()\nPodemos carregar os datasets já inclusos no R com a função mesma função data(), bastando incluir como argumento o nome do dataset desejado. No exemplo a seguir iremos carregar o dataset USArrests. Este dataset contém estatísticas das prisões por 100.000 habitantes por assalto, assassinato e estupro em cada um dos 50 estados dos EUA em 1973, como também a porcentagem da população urbana.\n\ndata(USArrests)\n\nComo esse dataset carregado podemos agora visualizar os dados simplesmente digitando o nome do dataset no console.\n\nhead(USArrests)\n\n           Murder Assault UrbanPop Rape\nAlabama      13.2     236       58 21.2\nAlaska       10.0     263       48 44.5\nArizona       8.1     294       80 31.0\nArkansas      8.8     190       50 19.5\nCalifornia    9.0     276       91 40.6\nColorado      7.9     204       78 38.7\n\n\nExperimente também usar a função str(), que mostra a estrutura dos dados de um objeto.\nVocê verá que o dataset USArrests é um data frame com 50 observações (50 linhas) e 4 variáveis (Murder, Assault, UrbanPop, Rape), como mostrado abaixo.\n\nstr(USArrests)\n\n'data.frame':   50 obs. of  4 variables:\n $ Murder  : num  13.2 10 8.1 8.8 9 7.9 3.3 5.9 15.4 17.4 ...\n $ Assault : int  236 263 294 190 276 204 110 238 335 211 ...\n $ UrbanPop: int  58 48 80 50 91 78 77 72 80 60 ...\n $ Rape    : num  21.2 44.5 31 19.5 40.6 38.7 11.1 15.8 31.9 25.8 ...\n\n\nVejamos a estrutura de um dataset com 403 pacientes e 19 variáveis num estudo sobre diabetes, obesidade e outros fatores de risco para doenças coronarianas. O data frame contém então 403 linhasa e 19 colunas. Esse dataset foi obtido no site da universidade de Vanderbilt no link a seguir:\nhttps://hbiostat.org/data/repo/diabetes.csv\nPara usar esse dataset é necessário fazer o download desse arquivo e depois carregar esse arquivo no R. Veremos mais tarde como fazer isso.\n\n\n  n   id colesterol glicose hdl ratio glicohemoglobina     cidade idade   sexo\n1 1 1000        203      82  56   3.6             4.31 Buckingham    46 female\n2 2 1001        165      97  24   6.9             4.44 Buckingham    29 female\n3 3 1002        228      92  37   6.2             4.64 Buckingham    58 female\n4 4 1003         78      93  12   6.5             4.63 Buckingham    67   male\n5 5 1005        249      90  28   8.9             7.72 Buckingham    64   male\n6 6 1008        248      94  69   3.6             4.81 Buckingham    34   male\n  altura      peso biotipo sistolica diastolica cintura quadril time.ppn\n1 157.48  54.88463  medium       118         59      29      38      720\n2 162.56  98.88306   large       112         68      46      48      360\n3 154.94 116.11955   large       190         92      49      57      180\n4 170.18  53.97745   large       110         50      33      38      480\n5 172.72  83.00734  medium       138         80      44      41      300\n6 180.34  86.18248   large       132         86      36      42      195\n\n\n\nstr(diabetes)\n\n'data.frame':   403 obs. of  18 variables:\n $ n               : int  1 2 3 4 5 6 7 8 9 10 ...\n $ id              : int  1000 1001 1002 1003 1005 1008 1011 1015 1016 1022 ...\n $ colesterol      : int  203 165 228 78 249 248 195 227 177 263 ...\n $ glicose         : int  82 97 92 93 90 94 92 75 87 89 ...\n $ hdl             : int  56 24 37 12 28 69 41 44 49 40 ...\n $ ratio           : num  3.6 6.9 6.2 6.5 8.9 ...\n $ glicohemoglobina: num  4.31 4.44 4.64 4.63 7.72 ...\n $ cidade          : chr  \"Buckingham\" \"Buckingham\" \"Buckingham\" \"Buckingham\" ...\n $ idade           : int  46 29 58 67 64 34 30 37 45 55 ...\n $ sexo            : chr  \"female\" \"female\" \"female\" \"male\" ...\n $ altura          : num  157 163 155 170 173 ...\n $ peso            : num  54.9 98.9 116.1 54 83 ...\n $ biotipo         : chr  \"medium\" \"large\" \"large\" \"large\" ...\n $ sistolica       : int  118 112 190 110 138 132 161 NA 160 108 ...\n $ diastolica      : int  59 68 92 50 80 86 112 NA 80 72 ...\n $ cintura         : int  29 46 49 33 44 36 46 34 34 45 ...\n $ quadril         : int  38 48 57 38 41 42 49 39 40 50 ...\n $ time.ppn        : int  720 360 180 480 300 195 720 1020 300 240 ...\n\n\nPodemos criar um data frame com a função data.frame(), como a seguir:\n\nnome  <- c(\"Henrique\", \"Antônio\", \"Fabiano\") \nidade <- c(45, 40, 48) \nstaff  <- data.frame(nome, idade) \nstaff\n\n      nome idade\n1 Henrique    45\n2  Antônio    40\n3  Fabiano    48\n\n\nA última linha acima criou o data frame, com as as duas colunas (nome e idade) e as 3 linhas, uma para cada participante da pesquisa e armazenou esse data frame no objeto staff. Veja que o objeto staff é um data.frame do R.\n\nclass(staff)\n\n[1] \"data.frame\"\n\n\nPodemos visualizarmos a estrutura desse data frame com a função str(staff).\n\nstr(staff)\n\n'data.frame':   3 obs. of  2 variables:\n $ nome : chr  \"Henrique\" \"Antônio\" \"Fabiano\"\n $ idade: num  45 40 48\n\n\nPara visualizarmos o data frame basta digitar seu nome staff.\n\nstaff\n\n      nome idade\n1 Henrique    45\n2  Antônio    40\n3  Fabiano    48"
  },
  {
    "objectID": "06-Dataframes-and-Tibbles.html#tidy-wide-x-long",
    "href": "06-Dataframes-and-Tibbles.html#tidy-wide-x-long",
    "title": "7  Data Frames e Tibbles",
    "section": "7.2 tidy: wide x long",
    "text": "7.2 tidy: wide x long\nA palavra data frame pode ser traduzida grosseiramente por quadro de dados e se refere a dados dispostos numa estrutura com linhas e colunas. Ou seja, um data frame é um objeto com estrutura bidimensional, composto de linhas e colunas, tais como uma matriz de dados.\nA forma de organização mais comum de dados num data frame é chamada de tidy (Wickham 2014) que significa, segundo o dicionário Cambridge, “having everything ordered and arranged in the right place”.\nUm dataset ou um data frame organizado (tidy data) as informações estão dispostas da seguinte forma:\n\nCada variável é uma coluna (ou cada coluna é uma variável).\nCada observação é uma linha (ou cada linha é uma observação).\nCada célula é um valor de uma variável em uma determinada observação.\n\n\n\n\n\n\nTidy Data\n\n\n\n\nExistem duas formas de organizar os dados numa tabela: wide e long. Vamos ver cada uma dessas formas a seguir.\nVamos primeiro criar um pequeno data frame para exemplo, no qual 3 pacientes se submeteram a dois tipos de tratamento, obtendo um determinado resultado para cada tratamento.\n\n# criando os vetores do data frame simulado\npacientes   <- c(\"João\", \"José\", \"Maria\")\ntratamentoA <- c(25,16,20) \ntratamentoB <- c(12,8,9) \n\n# criando o data frame a partir dos vetores já criados\nresult <- data.frame(pacientes, tratamentoA, tratamentoB)\n\n# mostrando o data frame criado\nresult\n\n  pacientes tratamentoA tratamentoB\n1      João          25          12\n2      José          16           8\n3     Maria          20           9\n\n\nEsse data frame é um exemplo de dados no formado wide (largo). E é muitas vezes a forma usual de um conjunto de dados.\nEntretanto, frequentemente, precisamos colocar esses dados numa outra disposição que facilita a análise dos dados. O formato long (comprido) é essa outra forma.\nPodemos ajustar esse data frame no formato long, colocando o tipo de tratamento numa coluna e o resultado noutra coluna. Ou seja, as duas colunas anteriores chamadas tratamentoA e tratamentoB serão juntadas em uma única coluna, chamada tratamento e os resultados passarão a ser uma única coluna.\nVeja no exemplo abaixo a transformação desse conjunto de dados para o formato long:\n\nlibrary(tidyr)\nresult |>  \n  pivot_longer(!pacientes,  \n               names_to = \"tratamento\", \n               values_to = \"resultado\")\n\n# A tibble: 6 × 3\n  pacientes tratamento  resultado\n  <chr>     <chr>           <dbl>\n1 João      tratamentoA        25\n2 João      tratamentoB        12\n3 José      tratamentoA        16\n4 José      tratamentoB         8\n5 Maria     tratamentoA        20\n6 Maria     tratamentoB         9\n\n\nNão se preocupe com o código usado aqui para fazer essa transformação. O objetivo aqui é entender que existem dois tipos de formatação do data frame, wide e long e que existem ferramentas para essa transformação num sentido e no outro.\nSugiro a leitura do artigo Tidy Data de Hadley Wickham, publicado no Journal of Statistical Software, Vol VV, Issue 2, no link a seguir: https://vita.had.co.nz/papers/tidy-data.pdf"
  },
  {
    "objectID": "06-Dataframes-and-Tibbles.html#tibbles-os-dataframes-do-tidyverse",
    "href": "06-Dataframes-and-Tibbles.html#tibbles-os-dataframes-do-tidyverse",
    "title": "7  Data Frames e Tibbles",
    "section": "7.3 Tibbles, os dataframes do tidyverse",
    "text": "7.3 Tibbles, os dataframes do tidyverse\nTibbles são data frames mais amigáveis. As tiblles foram criadas para resolver alguns problemas dos data frames e fazem parte do pacote tibble do tidyverse. Veremos nos capítulos adiante o que são pacotes, o que é o tidyverse.\nTibbles são a versão moderna dos data frames do R. Um dataframe é uma estrutura de dados em R que organiza dados em uma tabela, onde cada coluna pode conter um tipo diferente de dados (como números, texto, ou datas). Cada linha do dataframe representa uma observação.\nPor exemplo, imagine que você tem uma tabela com informações sobre pacientes:\n\n\n\nNome\nIdade\nTipo Sanguíneo\n\n\n\n\nJoão\n30\nA+\n\n\nMaria\n25\nB-\n\n\nAna\n40\nO+\n\n\n\nEssa tabela pode ser representada como um dataframe em R.\n\n7.3.1 O que são Tibbles?\nTibbles são uma versão moderna dos dataframes, oferecida pelo pacote tibble, parte do tidyverse. Eles são projetados para serem mais simples e robustos do que os dataframes tradicionais. Embora sejam semelhantes aos dataframes, as tibbles trazem várias vantagens que facilitam o trabalho com dados em R.\n\n\n7.3.2 Vantagens das Tibbles\n\nExibição Melhorada:\n\nQuando você exibe uma tibble, ela é formatada de forma amigável. Apenas as primeiras 10 linhas e as colunas que cabem na tela são mostradas, evitando sobrecarregar a tela com informações.\nDataframes tradicionais podem mostrar grandes quantidades de dados de uma só vez, o que pode ser confuso.\n\n\n\n# Exibindo um dataframe tradicional\ndf <- data.frame(nome = c(\"João\", \"Maria\", \"Ana\", \"Marcos\", \"Antônio\", \n                          \"Pedro\", \"José\", \"Gustavo\", \"Carlos\", \"Rafaela\", \n                          \"Luiza\", \"Lucas\", \"Laura\", \"Lavinia\", \"Carla\"), \n                 idade = c(30, 25, 40, 35, 60, \n                           75, 27, 54, 59, 12, \n                           19, 22, 65, 87, 90), \n                 tipoSanguineo = c(\"A+\", \"B-\", \"O+\", \"A+\", \"B-\", \n                                   \"O+\", \"A+\", \"B-\", \"O+\",\"B-\", \n                                   \"O+\", \"A+\", \"A+\", \"B-\", \"O+\"))\ndf\n\n      nome idade tipoSanguineo\n1     João    30            A+\n2    Maria    25            B-\n3      Ana    40            O+\n4   Marcos    35            A+\n5  Antônio    60            B-\n6    Pedro    75            O+\n7     José    27            A+\n8  Gustavo    54            B-\n9   Carlos    59            O+\n10 Rafaela    12            B-\n11   Luiza    19            O+\n12   Lucas    22            A+\n13   Laura    65            A+\n14 Lavinia    87            B-\n15   Carla    90            O+\n\n\n\n# Exibindo uma tibble\nlibrary(tibble)\ntib <- tibble(nome = c(\"João\", \"Maria\", \"Ana\", \"Marcos\", \"Antônio\", \n                          \"Pedro\", \"José\", \"Gustavo\", \"Carlos\", \"Rafaela\", \n                          \"Luiza\", \"Lucas\", \"Laura\", \"Lavinia\", \"Carla\"), \n             idade = c(30, 25, 40, 35, 60, \n                       75, 27, 54, 59, 12, \n                       19, 22, 65, 87, 90), \n             tipoSanguineo = c(\"A+\", \"B-\", \"O+\", \"A+\", \"B-\", \n                               \"O+\", \"A+\", \"B-\", \"O+\",\"B-\", \n                               \"O+\", \"A+\", \"A+\", \"B-\", \"O+\"))\nprint(tib)\n\n# A tibble: 15 × 3\n   nome    idade tipoSanguineo\n   <chr>   <dbl> <chr>        \n 1 João       30 A+           \n 2 Maria      25 B-           \n 3 Ana        40 O+           \n 4 Marcos     35 A+           \n 5 Antônio    60 B-           \n 6 Pedro      75 O+           \n 7 José       27 A+           \n 8 Gustavo    54 B-           \n 9 Carlos     59 O+           \n10 Rafaela    12 B-           \n11 Luiza      19 O+           \n12 Lucas      22 A+           \n13 Laura      65 A+           \n14 Lavinia    87 B-           \n15 Carla      90 O+           \n\n\n\nColunas Consistentes:\n\nAs tibbles sempre mantêm as colunas como os tipos de dados corretos. Por exemplo, se você tiver uma coluna de números, ela não será automaticamente convertida em caracteres, mesmo se houver um valor de texto nela.\nDataframes tradicionais às vezes convertem automaticamente os tipos de dados de colunas, o que pode causar problemas.\n\nFacilidade de Subsetting (Subconjuntos):\n\nSubsetting em tibbles é mais intuitivo. Você pode usar colchetes [], $ ou funções específicas do tidyverse sem surpresas.\nDataframes tradicionais podem se comportar de maneiras inesperadas ao fazer subsetting, especialmente com colunas de uma única linha.\n\n\n\n# Subsetting com tibble\ntib$nome  # Acesso à coluna 'Nome'\n\n [1] \"João\"    \"Maria\"   \"Ana\"     \"Marcos\"  \"Antônio\" \"Pedro\"   \"José\"   \n [8] \"Gustavo\" \"Carlos\"  \"Rafaela\" \"Luiza\"   \"Lucas\"   \"Laura\"   \"Lavinia\"\n[15] \"Carla\"  \n\n\n\n# Subsetting com tibble\ntib[1, ]  # Acesso à primeira linha\n\n# A tibble: 1 × 3\n  nome  idade tipoSanguineo\n  <chr> <dbl> <chr>        \n1 João     30 A+           \n\n\n\n# Subsetting com dataframe tradicional pode causar problemas se não tomar cuidado\ndf$nome # Acesso à coluna 'Nome'\n\n [1] \"João\"    \"Maria\"   \"Ana\"     \"Marcos\"  \"Antônio\" \"Pedro\"   \"José\"   \n [8] \"Gustavo\" \"Carlos\"  \"Rafaela\" \"Luiza\"   \"Lucas\"   \"Laura\"   \"Lavinia\"\n[15] \"Carla\"  \n\n\n\n# Subsetting com dataframe tradicional pode causar problemas se não tomar cuidado\ndf[1, ] # Acesso à primeira linha\n\n  nome idade tipoSanguineo\n1 João    30            A+\n\n\n\nMensagens de Erro Mais Úteis:\n\nAs tibbles fornecem mensagens de erro mais claras e informativas, ajudando a entender o que deu errado e como corrigir.\n\nMelhor Compatibilidade com o Tidyverse:\n\nAs tibbles são projetadas para funcionar perfeitamente com outras ferramentas do tidyverse (como dplyr e ggplot2), facilitando operações de manipulação de dados e visualização.\n\n\n\n\n7.3.3 Criando e Usando Tibbles\nAqui está um exemplo de como criar e usar tibbles no R:\n\n# Instale e carregue o pacote tibble\n# install.packages(\"tibble\")\nlibrary(tibble)\n\n# Criando uma tibble\ndados_pacientes <- tibble(nome = c(\"João\", \"Maria\", \"Ana\", \"Marcos\", \"Antônio\", \n                                  \"Pedro\", \"José\", \"Gustavo\", \"Carlos\", \"Rafaela\", \n                                  \"Luiza\", \"Lucas\", \"Laura\", \"Lavinia\", \"Carla\"), \n                         idade = c(30, 25, 40, 35, 60, \n                                   75, 27, 54, 59, 12, \n                                   19, 22, 65, 87, 90), \n                         tipoSanguineo = c(\"A+\", \"B-\", \"O+\", \"A+\", \"B-\", \n                                           \"O+\", \"A+\", \"B-\", \"O+\",\"B-\", \n                                           \"O+\", \"A+\", \"A+\", \"B-\", \"O+\"))\n\n\n# Exibindo a tibble\ndados_pacientes\n\n# A tibble: 15 × 3\n   nome    idade tipoSanguineo\n   <chr>   <dbl> <chr>        \n 1 João       30 A+           \n 2 Maria      25 B-           \n 3 Ana        40 O+           \n 4 Marcos     35 A+           \n 5 Antônio    60 B-           \n 6 Pedro      75 O+           \n 7 José       27 A+           \n 8 Gustavo    54 B-           \n 9 Carlos     59 O+           \n10 Rafaela    12 B-           \n11 Luiza      19 O+           \n12 Lucas      22 A+           \n13 Laura      65 A+           \n14 Lavinia    87 B-           \n15 Carla      90 O+           \n\n\n\n# Acessando colunas\ndados_pacientes$nome\n\n [1] \"João\"    \"Maria\"   \"Ana\"     \"Marcos\"  \"Antônio\" \"Pedro\"   \"José\"   \n [8] \"Gustavo\" \"Carlos\"  \"Rafaela\" \"Luiza\"   \"Lucas\"   \"Laura\"   \"Lavinia\"\n[15] \"Carla\"  \n\n\n\n# Filtrando dados com o dplyr (do tidyverse)\nlibrary(dplyr)\npacientes_mais_jovens <- dados_pacientes %>% filter(idade < 35)\npacientes_mais_jovens\n\n# A tibble: 6 × 3\n  nome    idade tipoSanguineo\n  <chr>   <dbl> <chr>        \n1 João       30 A+           \n2 Maria      25 B-           \n3 José       27 A+           \n4 Rafaela    12 B-           \n5 Luiza      19 O+           \n6 Lucas      22 A+           \n\n\n\n\n7.3.4 transformando data frames em tibbles\nCaso você tenha um data frame, é fácil transformá-lo numa tibble usando a função as.tibble().\nO código a seguir lê um banco de dados chamado diabetes.csv que está na pasta dataset do projeto. A leitura será feita através da função base do R read.csv(), que coloca os dados lidos num data frame. Em seguida, usaremos a função as.tibble() para transformar o data frame numa tibble.\n\n# lendo os dados com a função read.csv do R Base\ndiabetes <- read.csv(\"dataset/diabetes.csv\") \n\n# verificando que os dados foram armazenados num data frame\nstr(diabetes)\n\n'data.frame':   403 obs. of  18 variables:\n $ n               : int  1 2 3 4 5 6 7 8 9 10 ...\n $ id              : int  1000 1001 1002 1003 1005 1008 1011 1015 1016 1022 ...\n $ colesterol      : int  203 165 228 78 249 248 195 227 177 263 ...\n $ glicose         : int  82 97 92 93 90 94 92 75 87 89 ...\n $ hdl             : int  56 24 37 12 28 69 41 44 49 40 ...\n $ ratio           : num  3.6 6.9 6.2 6.5 8.9 ...\n $ glicohemoglobina: num  4.31 4.44 4.64 4.63 7.72 ...\n $ cidade          : chr  \"Buckingham\" \"Buckingham\" \"Buckingham\" \"Buckingham\" ...\n $ idade           : int  46 29 58 67 64 34 30 37 45 55 ...\n $ sexo            : chr  \"female\" \"female\" \"female\" \"male\" ...\n $ altura          : num  157 163 155 170 173 ...\n $ peso            : num  54.9 98.9 116.1 54 83 ...\n $ biotipo         : chr  \"medium\" \"large\" \"large\" \"large\" ...\n $ sistolica       : int  118 112 190 110 138 132 161 NA 160 108 ...\n $ diastolica      : int  59 68 92 50 80 86 112 NA 80 72 ...\n $ cintura         : int  29 46 49 33 44 36 46 34 34 45 ...\n $ quadril         : int  38 48 57 38 41 42 49 39 40 50 ...\n $ time.ppn        : int  720 360 180 480 300 195 720 1020 300 240 ...\n\n\n\n# transformando o data frame numa tibble\ndiabetes <- as_tibble(diabetes)\n\n# verificando que os dados agora esão armazenados numa tibble\nstr(diabetes)\n\ntibble [403 × 18] (S3: tbl_df/tbl/data.frame)\n $ n               : int [1:403] 1 2 3 4 5 6 7 8 9 10 ...\n $ id              : int [1:403] 1000 1001 1002 1003 1005 1008 1011 1015 1016 1022 ...\n $ colesterol      : int [1:403] 203 165 228 78 249 248 195 227 177 263 ...\n $ glicose         : int [1:403] 82 97 92 93 90 94 92 75 87 89 ...\n $ hdl             : int [1:403] 56 24 37 12 28 69 41 44 49 40 ...\n $ ratio           : num [1:403] 3.6 6.9 6.2 6.5 8.9 ...\n $ glicohemoglobina: num [1:403] 4.31 4.44 4.64 4.63 7.72 ...\n $ cidade          : chr [1:403] \"Buckingham\" \"Buckingham\" \"Buckingham\" \"Buckingham\" ...\n $ idade           : int [1:403] 46 29 58 67 64 34 30 37 45 55 ...\n $ sexo            : chr [1:403] \"female\" \"female\" \"female\" \"male\" ...\n $ altura          : num [1:403] 157 163 155 170 173 ...\n $ peso            : num [1:403] 54.9 98.9 116.1 54 83 ...\n $ biotipo         : chr [1:403] \"medium\" \"large\" \"large\" \"large\" ...\n $ sistolica       : int [1:403] 118 112 190 110 138 132 161 NA 160 108 ...\n $ diastolica      : int [1:403] 59 68 92 50 80 86 112 NA 80 72 ...\n $ cintura         : int [1:403] 29 46 49 33 44 36 46 34 34 45 ...\n $ quadril         : int [1:403] 38 48 57 38 41 42 49 39 40 50 ...\n $ time.ppn        : int [1:403] 720 360 180 480 300 195 720 1020 300 240 ...\n\n\nVeremos mais adiante que a função read_csv() do readr já lê os dados como uma tibble.\n\n# lendo os dados com a função read.csv do R Base\nlibrary(readr)\ndiabetes <- read_csv(\"dataset/diabetes.csv\") \n\nRows: 403 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): cidade, sexo, biotipo\ndbl (15): n, id, colesterol, glicose, hdl, ratio, glicohemoglobina, idade, a...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# verificando que os dados foram armazenados num data frame\nstr(diabetes)\n\nspc_tbl_ [403 × 18] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ n               : num [1:403] 1 2 3 4 5 6 7 8 9 10 ...\n $ id              : num [1:403] 1000 1001 1002 1003 1005 ...\n $ colesterol      : num [1:403] 203 165 228 78 249 248 195 227 177 263 ...\n $ glicose         : num [1:403] 82 97 92 93 90 94 92 75 87 89 ...\n $ hdl             : num [1:403] 56 24 37 12 28 69 41 44 49 40 ...\n $ ratio           : num [1:403] 3.6 6.9 6.2 6.5 8.9 ...\n $ glicohemoglobina: num [1:403] 4.31 4.44 4.64 4.63 7.72 ...\n $ cidade          : chr [1:403] \"Buckingham\" \"Buckingham\" \"Buckingham\" \"Buckingham\" ...\n $ idade           : num [1:403] 46 29 58 67 64 34 30 37 45 55 ...\n $ sexo            : chr [1:403] \"female\" \"female\" \"female\" \"male\" ...\n $ altura          : num [1:403] 157 163 155 170 173 ...\n $ peso            : num [1:403] 54.9 98.9 116.1 54 83 ...\n $ biotipo         : chr [1:403] \"medium\" \"large\" \"large\" \"large\" ...\n $ sistolica       : num [1:403] 118 112 190 110 138 132 161 NA 160 108 ...\n $ diastolica      : num [1:403] 59 68 92 50 80 86 112 NA 80 72 ...\n $ cintura         : num [1:403] 29 46 49 33 44 36 46 34 34 45 ...\n $ quadril         : num [1:403] 38 48 57 38 41 42 49 39 40 50 ...\n $ time.ppn        : num [1:403] 720 360 180 480 300 195 720 1020 300 240 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   n = col_double(),\n  ..   id = col_double(),\n  ..   colesterol = col_double(),\n  ..   glicose = col_double(),\n  ..   hdl = col_double(),\n  ..   ratio = col_double(),\n  ..   glicohemoglobina = col_double(),\n  ..   cidade = col_character(),\n  ..   idade = col_double(),\n  ..   sexo = col_character(),\n  ..   altura = col_double(),\n  ..   peso = col_double(),\n  ..   biotipo = col_character(),\n  ..   sistolica = col_double(),\n  ..   diastolica = col_double(),\n  ..   cintura = col_double(),\n  ..   quadril = col_double(),\n  ..   time.ppn = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\n\n\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of Statistical Software 59 (10): 23."
  },
  {
    "objectID": "07-Operators.html#operadores-aritméticos",
    "href": "07-Operators.html#operadores-aritméticos",
    "title": "8  Operadores no R",
    "section": "8.1 Operadores Aritméticos",
    "text": "8.1 Operadores Aritméticos\nOs operadores mais comuns do R são os aritméticos:\n+ soma\n- subtração\n* multiplicação\n/ divisão\n^ potência\nVeja nos exemplos abaixo algumas operações matemáticas simples:\n\n4*3+2\n\n[1] 14\n\n\nO número [1] entre colchetes que aparece antes do resultado indica que o valor apresentado é o 1º da lista de resultados. Nesse caso só existe um valor, então essa informação não tem utilidade. Em alguns casos o resultado da operação é um conjunto de números, ocupando mais de uma linha, nesses casos, esse nº entre colchetes pode ter alguma utilidade.\n\n8.1.1 Precedência de Operações\nAssim como na matemática, também no R existem regras de precedência de operações com um detalhe: os parênteses sempre tem preferência, ou precedência, sendo usados para colocarmos as operações na ordem desejada. ou seja, as operações entre parênteses tem prioridade sobre outras operações. Veja o exemplo abaixo\n\n(4*3) + 2 \n\n[1] 14\n\n\n\n4*(3 + 2) \n\n[1] 20"
  },
  {
    "objectID": "07-Operators.html#operador-de-atribuição--",
    "href": "07-Operators.html#operador-de-atribuição--",
    "title": "8  Operadores no R",
    "section": "8.2 Operador de Atribuição <-",
    "text": "8.2 Operador de Atribuição <-\nMuitos dos símbolos usualmente usados na matemática são denominados operadores. Na matemática os símbolos +, -, *, / e ^ são operadores aritméticos.\nUm operador importante é o =. Esse sinal no R não significa igualdade. O símbolo de igual = é chamado de operador de designação ou de atribuição, e serve para copiar uma constante, um literal, um resultado de expressão ou um resultado de função para uma variável.\nNa linguagem R é mais comum usarmos um outro operador de atribuição: <- justamente para não causar confusão com a igualdade.\nO operador de atribuição serve para atribuirmos um dado a um objeto e tem a forma de uma seta para esquerda, formada pelo sinal de menor imediatamente seguida do sinal de menos\n<-.\nIsso forma uma seta, indicando que o resultado da operação será colocado no objeto à esquerda da seta.\n\nx <- 2\ny <- 3\nz <- (x+y)^2\nz <- \"Maria\" \n\nObserve que ao criar uma variável para armazenar uma palavra ou um caractere, é necessário colocar essa palavra entre aspas. O R entende que está entre aspas é uma palavra ou um texto e não um número."
  },
  {
    "objectID": "07-Operators.html#operadores-de-comparação-relacionais",
    "href": "07-Operators.html#operadores-de-comparação-relacionais",
    "title": "8  Operadores no R",
    "section": "8.3 Operadores de Comparação (Relacionais)",
    "text": "8.3 Operadores de Comparação (Relacionais)\nOperadores de comparação, ou relacionais, realizam ações de verificação da relação entre dois objetos, comparando se são iguais, diferentes, maiores ou menores. O resultado de uma operação dessas é sempre uma variável lógica (TRUE ou FALSE). Esse resultado é armazenado em variáveis chamadas de booleanas ou lógicas.\n\n\n\n\n\nOperadores Relacionais no R\n\n\n\n\nPerceba que o operador de igualdade é o == e não o =. O simbolo = é o operador de atribuição e não de igualdade. É frequente a confusão entre entre esses operadores. Devido a isso, no R é usual utilizarmos o <-como o operador de atribuição.\nVeja nos códigos abaixo exemplos do uso dos operadores relacionais. Perceba que o resultado é sempre uma variável lógica (TRUE ou FALSE).\n\n4 < 5\n\n[1] TRUE\n\n\n\n3 == 3\n\n[1] TRUE\n\n\n\na <- 3^2\nb <- 3*3\na > b\n\n[1] FALSE\n\na < b\n\n[1] FALSE\n\na == b\n\n[1] TRUE"
  },
  {
    "objectID": "07-Operators.html#operadores-lógicos",
    "href": "07-Operators.html#operadores-lógicos",
    "title": "8  Operadores no R",
    "section": "8.4 Operadores Lógicos",
    "text": "8.4 Operadores Lógicos\nOperadores relacionais comparam dois objetos. Quando precisamos realizar mais de uma comparação ao mesmo tempo, precisamos usar os operadores lógicos. No R, os principais operadores lógicos são, & e | , que significam, respectivamente, AND e OR. O resultado de comparações múltiplas terá também como resultado uma variável lógica (TRUE ou FALSE).\nVeja abaixo alguns exemplos.\n\nA <- 30\nB <- 20\nC <- 10\n\n# testaremos abaixo se A é, ao mesmo tempo, maior que B e C\n# o resultado só será TRUE se A for maior que ambos\n(A > B) & (A > C)\n\n[1] TRUE\n\n\n\n# testaremos agora se B é maior que um dos outros dois A ou C\n# basta B ser maior que qualquer um dos outros para o resultado ser TRUE\n(B > A) | (B > C)\n\n[1] TRUE"
  },
  {
    "objectID": "07-Operators.html#operador-de-extração",
    "href": "07-Operators.html#operador-de-extração",
    "title": "8  Operadores no R",
    "section": "8.5 Operador de Extração: $",
    "text": "8.5 Operador de Extração: $\nO operador $ é usado para acessarmos as colunas de um data frame e extrairmos os valores dessa coluna. Vamos criar um pequeno data frame para exemplo:\n\nnome  <- c(\"Henrique\", \"Antônio\", \"Fabiano\") \nidade <- c(45, 40, 48) \nstaff  <- data.frame(nome, idade) \n\nPara extrairmos os valores da variábel nessa coluna com as idades basta usarmos staff$idade, como abaixo:\n\nstaff$idade \n\n[1] 45 40 48\n\n\nVeja que o comando formado por A$B extrai os dados armazenados na variável B do data frame A.\nUsamos esse operador $ para realizar qualquer cálculo estatístico nos valores armazenados em uma variável de um data frame. Por exemplo, para calcular a média das idades dos pacientes no data frame acima basta usar a função mean(), colocando mydf$idade como argumento da função, como abaixo:\n\n# calcula a média da variável idade no data frame staff\nmean(staff$idade)\n\n[1] 44.33333\n\n\n\n# calcula a mediana da variável idade no data frame staff\nmedian(staff$idade)\n\n[1] 45\n\n\n\n# calcula o desvio padrão da variável idade no data frame staff\nsd(staff$idade)\n\n[1] 4.041452"
  },
  {
    "objectID": "07-Operators.html#operador-de-sequenciação",
    "href": "07-Operators.html#operador-de-sequenciação",
    "title": "8  Operadores no R",
    "section": "8.6 Operador de Sequenciação :",
    "text": "8.6 Operador de Sequenciação :\nO operador de sequência : é um dos operadores mais fundamentais e frequentemente utilizados no R. Ele permite criar sequências de números inteiros de forma rápida e eficiente, facilitando a geração de vetores numerados em intervalos regulares. A simplicidade e a utilidade deste operador fazem dele uma ferramenta essencial para qualquer pessoa que esteja trabalhando com a linguagem R.\nA sintaxe básica do operador de sequência é extremamente simples:\ninício:fim\nO operador : cria uma sequência de números inteiros que começa em início e termina em fim, incluindo ambos os extremos. Por exemplo:\n\n# Criando uma sequência de 1 a 10\nx <- 1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nPodemos criar sequencias decrescentes\n\nx <- 100:90\nx\n\n [1] 100  99  98  97  96  95  94  93  92  91  90\n\n\nPodemos criar sequencias combinadas com o uso da função de concatenação c(), tal como mostrado a seguir:\n\n# Combinando duas sequências\nc(1:5, 10:15, 20:25)\n\n [1]  1  2  3  4  5 10 11 12 13 14 15 20 21 22 23 24 25\n\n\nO operador de sequência : é muito eficiente para criar sequências simples de números inteiros. No entanto, para sequências mais complexas ou não lineares, a função seq() pode ser mais apropriada. Além disso, é importante lembrar que o operador : sempre gera sequências de inteiros; para sequências de números não inteiros ou com passos diferentes de 1, a função seq() deve ser utilizada."
  },
  {
    "objectID": "07-Operators.html#operador-de-fórmulas",
    "href": "07-Operators.html#operador-de-fórmulas",
    "title": "8  Operadores no R",
    "section": "8.7 Operador de Fórmulas ~",
    "text": "8.7 Operador de Fórmulas ~\nO operador ~ é utilizado para expressar a relação entre variáveis, indicando a dependência de uma variável resposta em relação a uma ou mais variáveis preditoras. Ele é amplamente utilizado na criação de fórmulas, que são objetos da classe formula no R.\nA sintaxe básica do operador ~ é: resposta ~ preditores, Onde resposta é a variável dependente e preditores são as variáveis independentes. É possível haver mais de uma variável preditora. Nesse caso as variáveis preditoras são agregadas com o operador +. Por exemplo: resposta ~ preditor1 + preditor2 + preditor3.\nSuponha que temos um conjunto de dados sobre o peso e a altura de indivíduos e queremos criar um modelo que descreva o peso em função da altura. Podemos criar um objeto da classe fórmula simplesmente escrevendo peso ~ altura. Observe que os objetos da classe fórmula não são avaliados numericamente, a não ser quando são inseridos em alguma função.\nEsse é justamente o poder das fórmulas no R, permitem capturar os relações entre variáveis sem avaliá-las para que possam ser interpretadas por alguma função.\n\n# Dados de exemplo\nmeus_dados <- data.frame(peso   = c(60,    65,    70,    75,    80,    85,      90,    95,     100,    110),\n                         altura = c(1.55,  1.60,  1.65,  1.70,  1.75,  1.80,    1.85,  1.90,   1.95,   2.00), \n                         sexo   = c(\"Fem\", \"Fem\", \"Fem\", \"Fem\", \"Fem\", \"Masc\", \"Masc\", \"Masc\", \"Masc\", \"Masc\"))\n\n# Fórmula para a regressão linear\nminha_formula <- peso ~ altura\nstr(minha_formula)\n\nClass 'formula'  language peso ~ altura\n  ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n\n\nEste código cria uma fórmula que representa a relação entre peso e altura. A fórmula peso ~ altura é um objeto da classe formula.\n\n8.7.1 Formulas dentro de funções\nPodemos inserir fórmulas como argumentos de funções. Por exemplo, na construção de um boxplot comparativo: boxplot(y~x, dataframe).\nO código acima pode ser traduzido da seguinte forma: faça um boxplot da distribuição da variável numérica y estratificando de acordo com a variável categórica x, a partir dos dados do data frame indicado. Podemos fazer isso usando os dados criado no código acima.\n\n# usando os dados criados na etapa anterior:\nboxplot(peso~sexo,data=meus_dados)\n\n\n\n\n\n\n8.7.2 Utilizando Fórmulas em Modelos Estatísticos\nUma das aplicações mais comuns do operador ~ é na construção de modelos estatísticos. Vamos ajustar um modelo de regressão linear simples usando os dados de exemplo acima. Veja que a fórmula é um dos argumentos da função lm() que significa Linear Model. A função lm() utiliza a fórmula peso ~ altura como argumento para definir o modelo.\n\n# Ajuste do modelo de regressão linear\nmodelo <- lm(peso ~ altura, data = meus_dados)\n\n# Resumo do modelo\nsummary(modelo)\n\n\nCall:\nlm(formula = peso ~ altura, data = meus_dados)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.4545 -0.8409 -0.2273  0.3864  3.2727 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -104.182      5.608  -18.58 7.27e-08 ***\naltura       105.455      3.149   33.49 6.91e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.43 on 8 degrees of freedom\nMultiple R-squared:  0.9929,    Adjusted R-squared:  0.992 \nF-statistic:  1121 on 1 and 8 DF,  p-value: 6.905e-10"
  },
  {
    "objectID": "07-Operators.html#pipe",
    "href": "07-Operators.html#pipe",
    "title": "8  Operadores no R",
    "section": "8.8 Operador pipe |>",
    "text": "8.8 Operador pipe |>\nPipe, na língua inglesa, significa tubo ou tubulação. Na computação pipe é uma forma de simplificar uma série de comandos em sequência. O nome desse operador tem a ver com o fato de criar uma sequencia de ações, encaminhando os resultados de uma função para a próxima função como se estivessem sendo carregados por um tubo. Esse operador faz parte do pacote magrittr e é automaticamente instalado juntamente com o tidyverse. A partir da versão 4.1, o R passou a ter um operador pipe próprio, sem a necessidade de novos pacotes. Ambos tem funções similares e se comportam de forma parecida, com alguns detalhes diferentes. Esses operadores usam simbolos diferentes, mas funcionam de forma parecida e não entraremos em detalhes das sutis diferenças entre eles.\n\nOperador pipe do pacote magritte: %>%\nOperador pipe do R (4.1 e acima): |>\n\nVeja um exemplo. Suponha que dado um vetor, você precise calcular a média dos valores, depois extrair a raiz quadrada desse valor e, em seguida, arredondar o valor para 2 casas decimais.\nPodemos fazer isso de três formas:\n\nAninhando as operações em parênteses ou\ncriando variáveis intermediários em cada etapa.\nUsando o operador pipe.\n\nVejamos como isso seria feito e quais as deficiências das duas primeiras abordagens.\nCriando um vetor numérico x\n\nx <- c(0,11,222,333,44,55,66,77,88,99,100,110)\n\n1º modo: Usando códigos aninhados entre parênteses, fazendo toda a operação de uma só vez.\n\nround(sqrt(mean(x)),2)\n\n[1] 10.02\n\n\nEssa forma de fazer as operações não é nada elegante. O código fica difícil de ser lido e de ser compreendido. Erros são comuns e corrigi-los é ainda mais difícil. Um modo alternativo é fazer cada operação de uma vez, armazenado o resultado em variáveis intermediárias em cada etapa\n2º modo: Fazendo cada operação separadamente, usando variáveis intermediárias\nCalcule a média dos valores de x e armazenando o resultado em x2\n\nx2 <- mean(x)\nx2\n\n[1] 100.4167\n\n\nCalcule a média dos valores de x2 e armazenando o resultado em x3\n\nx3 <- sqrt(x2)\nx3\n\n[1] 10.02081\n\n\narredonde o valor de x3 para 2 casas decimais depois da vírgula\n\nround(x3, 2)\n\n[1] 10.02\n\n\nEsse modo de realizar essa sequencia de operações é mais fácil de ser compreendido, já que cada etapa do processo é feita separadamente. Entretanto, tem o inconveniente de ser necessário a criação de diversas variáveis intermediárias, o que polui desnecessáriamente o ambiente de trabalho.\n3º modo: Usando o operador pipe %>%\nVeja agora como fazer essas operações de forma elegante com o operador pipe.\n\n# usando o pipe do pacote magritte\nlibrary(magrittr)\nx %>% mean() %>% sqrt() %>% round(2)\n\n[1] 10.02\n\n\n\n# usando o pipe do R\nx |>  mean() |>  sqrt() |>  round(2)\n\n[1] 10.02\n\n\nO código acima pode ser lido da seguinte maneira:\n\nPegue os valores contidos na variável x,\nENTÃO calcule a média,\nENTÃO calcule a raiz quadrada,\nENTÃO arredonde para 2 casas decimais.\n\nVeja como é muito mais natural e mais fácil compreender esse código. O que o operador pipe fez foi enviar o resultado de cada operação para a operação seguinte, como se estivesse passando por um tubo.\nO operador pipe pode ser colocado em diversas linhas para facilitar ainda mais a visualização e compreensão da sequencia de códigos. Essa é o estilo adequado de se usar o operador pipe.\n\n# usando o pipe do pacote magritte\nx %>%   \n  mean() %>%   \n  sqrt() %>%   \n  round(2)\n\n[1] 10.02\n\n\n\n# usando o pipe do R\nx |>   \n  mean() |>   \n  sqrt() |>   \n  round(2)\n\n[1] 10.02\n\n\nVamos ver como funciona o operador pipe em data frames usando como um exemplo o dataset mpg do pacote ggplot2.\nImagine que você precisa extrair a média da quilometragem percorrida na estrada, por carros da marca Ford com tração nas 4 rodas, arredondando o resultado para 2 casas decimais depois da vírgula. Não se preocupe em entender as funções filter(), select() e pull(). Essas funções serão explicadas no capítulo sobre o tidyverse. O objetivo agora é apenas entender como usar o operador pipe %>%.\nSem o uso do operador pipe o código poderia ser feita de duas formas: criando datasets intermediários em cada etapa ou aninhando as operações em parênteses.\nModo 1: Usando comandos aninhados um dentro do outro com parênteses.\n\nlibrary(ggplot2) # necessário para usar o dataset mpg\nlibrary(dplyr) # necessário para usar as funções filter() e select()\n# carregando o dataset mpg\ndata(mpg)\n\n# Executando a operação\nround(mean(filter(mpg, manufacturer == \"ford\" & drv == \"4\")$hwy) ,2)\n\n[1] 17.15\n\n\nVeja como o código fica confuso, difícil de ser lido por seres humanos normais.\nModo 2: Usando datasets intermediários.\n\n# Extrai do data frame mpg os carros da ford com tração nas 4 rodas e cria um novo data frame com esse resultado\nford4x4 <- filter(mpg, manufacturer == \"ford\" & drv == \"4\")\n\n\n# extrai a média dos valores da km percorrida na estrada e coloca esse resultado numa nova variável\nmedia.estrada <- mean(ford4x4$hwy)\n\n\n# arredondando o resultado com 2 casas decimais depois da vírgula e coloca esse resultado numa nova variável\nmedia.arredondada <- round(media.estrada, 2)\n\n\n# mostra o resultado\nmedia.arredondada\n\n[1] 17.15\n\n\nO código acima pode até ser fácil de ler, entretanto, ficou muito grande, ocupando muitas linhas e criando variáveis intermediárias em excesso. O operador pipe também facilita muito trabalhar com data frames. Veja a seguir como podemos simplificar esse código com o pipe:\n\nmpg %>% \n  filter(manufacturer == \"ford\" & drv == \"4\") %>% \n  select(hwy) %>% \n  pull() %>% \n  mean() %>% \n  round(2)\n\n[1] 17.15\n\n\n\nmpg |> \n  filter(manufacturer == \"ford\" & drv == \"4\") |> \n  select(hwy) |> \n  pull() |> \n  mean() |> \n  round(2)\n\n[1] 17.15\n\n\nO código acima pode ser lido da seguinte maneira:\n\nUse o dataset mpg\nFiltre os carros para apenas os carros da Ford com tração nas 4 rodas (filter)\n\nSelecione a variável hwy (quilometragem percorrida na estrada) (select)\n\nExtraia os valores numéricos desse resultado (pull)\n\nCalcule a média desses valores (mean)\n\nArredonde o resultado para 2 casas decimais (round)\n\nDepois de um certo tempo você irá se acostumar com o operador pipe e perceberá o quanto ele é útil, pois as operações são colocadas numa sequência bem mais compreensível.\nO operador pipe do R tem algumas vantagens. Em primeiro lugar, não depende de nenhum pacote; sem segundo lugar, é mais curto para se digitar; em terceiro lugar, é mais rápido."
  },
  {
    "objectID": "08-R-Functions.html#sec-arguments",
    "href": "08-R-Functions.html#sec-arguments",
    "title": "9  Funções no R",
    "section": "9.1 Argumentos de uma função",
    "text": "9.1 Argumentos de uma função\nExistem dois tipos de argumentos de função:\n\ndados, argumentos para calcular o que se pretented;\ncontroles, argumentos controlam outros aspectos da funcão, por exemplo como lidar com dados faltantes.\n\nA função mean() é um exemplo de função que possui argumentos de dados e argumentos de controle. Os argumentos de dados são os valores numéricos que serão usados para calcular a média. Os argumentos de controle são os argumentos que controlam o comportamento da função, como por exemplo, o argumento na.rm que indica se a função deve remover ou não os valores faltantes.\n\nx <- c(1,2,3,4,NA)\nmean(x, na.rm = TRUE) # na.rm=TRUE é um argumento de controle\n\n[1] 2.5\n\n\nOs argumentos de uma função são os parâmetros sobre os quais a função realiza alguma operação. Por exemplo, na função \\(f(x)=sen(x)\\), \\(x\\) é o argumento da função. A operação de calcular o seno será realizada sobre o valor de \\(x\\). Da mesma forma, nas funções \\(f(x)=\\sqrt{x}\\), \\(f(x)=2x\\), e \\(f(x)=x^2\\), \\(x\\) é o argumento das funções.\nAlgumas funções possuem mais de um argumento, tal como a função logarítmica \\(f(x,b)=\\log _{b} (x)\\). Para calcularmos o logaritmo de \\(x\\) na base \\(b\\) , precisamos informar à função o valor de \\(x\\) e de \\(b\\). Então \\(x\\) e \\(b\\) são os argumentos da função \\(f(x,b)=\\log _{b} (x)\\).\nEsse é um exemplo de função que precisa de dois argumentos para ser executada. No R a função para calcular o logaritmo de nra base seria escrita da seguinte maneira:\n\nlog(2,10)\n\n[1] 0.30103\n\n\nToda função no R tem a seguinte estrutura: nome(argumento, argumento, argumento, …). Ou seja, o nome da função, seguido dos argumentos da função entre parênteses. Observe que não há espaços entre o nome da função e os parênteses com os argumentos. Os argumentos, por sua vez, são separados por vírgulas. A inserção dos argumentos numa função pode ser feito de duas maneiras:\n-Pela ordem\n-Pelo nome do argumento\nA função logaritmo interpreta o primeiro o valor como sendo \\(x\\) e o segundo valor como sendo a base \\(b\\). Mas podemos escrever essa função explicitando cada argumento individualmente. Essa forma de escrever, embora mais longa, deixa a função mais compreensiva para o leitor. Além disso, quando inserimos os argumentos pelo nome, a ordem não importa, pois já estamos indicando ao R o significado de cada argumento.\nVeja abaixo as diferentes formas de inserir os argumentos numa função no R.\n\n# inserindo os argumentos pela ordem\nlog(2,10) \n\n[1] 0.30103\n\n\n\n# inserindo os argumentos pelo nome\nlog(x = 2, base = 10) \n\n[1] 0.30103\n\n\nAlém disso, para facilitar o uso, muitas funções no R já tem argumentos padronizados, default. Ou seja, caso não sejam informados, o R irá usar o valor padrão desses argumentos. A função logaritmo no R tem como padrão o logaritmo natural, a base \\(e\\). Então, se a base não for inserida como argumento, o R interpretará que deverá ser usado o valor padrão. Veja abaixo o exemplo, para calcular o logaritmo natural de 10 - \\(log _{e} (10)\\) - simplesmente digitamos no R:\n\n# usando a o argumento default (padrão) da função logaritmo no R\n# será calculado o logaritmo natural (base e) de 10\nlog(10)\n\n[1] 2.302585\n\n\n\n9.1.1 Visualizando os possíveis argumentos de uma função\nPodemos verificar alguns dos argumentos possíveis de serem passados para uma função digitando a tecla tab quando o cursor estiver dentro da função. Quando clicamos a tecla tab o RStudio abre um menu contextual com os mais importantes argumentos da função. Veja nas imagens abaixo alguns exemplos.\n\n\n\n\n\nargumentos da função."
  },
  {
    "objectID": "08-R-Functions.html#criando-suas-próprias-funções",
    "href": "08-R-Functions.html#criando-suas-próprias-funções",
    "title": "9  Funções no R",
    "section": "9.2 Criando suas próprias funções",
    "text": "9.2 Criando suas próprias funções\nO R permite que você crie também suas próprias funções. Isso será útil quando uma determinada análise tem de ser feita diversas vezes, evitando que você precise reescrever o código dessa análise toda vez que tiver de fazê-la novamente.\nPara criar uma função precisamos: 1. Dar um nome para a função a ser criada. 2. Definir os argumentos da função. 3. Definir o que a função irá retornar, seu ouput.\nSuponha que você tenha em seu banco de dados a altura e o peso dos pacientes e necessite calcular o imc (índice de massa corporal). Podemos facilmente criar uma função que recebe os valores do peso e da altura como argumentos, calcula o IMC e retorna esse valor. O termo retornar é usualmente usado para se referir ao objeto que a função devolve depois de receber seus argumentos.\nEntão:\n1. O nome da função será: imc.\n2. Os argumentos da função serão: peso e altura.\n3. A função calcular e retornar um valor numérico.\n\nCom essas informações, basta colocar tudo isso na função.\n\n\nimc <- function(peso, altura)\n{\nreturn(peso/(altura*altura))\n}\n\nA primeira linha acima indica que estamos criando uma função chamada imc que recebe dois argumentos: peso e altura.\nAs linhas entre os {} realizam o cálculo do imc, que é o peso dividido pela altura ao quadrado.\nO comando return() é usado para indicar o que a função irá retornar.\n\nPara usar essa função, basta inserir os argumentos peso e altura na própria função\n\nimc(peso = 64, altura = 1.75)\n\n[1] 20.89796"
  },
  {
    "objectID": "08-R-Functions.html#funções-anônimas",
    "href": "08-R-Functions.html#funções-anônimas",
    "title": "9  Funções no R",
    "section": "9.3 Funções anônimas",
    "text": "9.3 Funções anônimas\nAs funções que criamos com o comando function() acima todas tiveram um nome. Entretanto, o R também permite criar funções anônimas, ou seja, sem nome. Elas também são criadas com o comando function() e são usadas para realizar operações simples e rápidas, quando não há necessidade de reutilizar a função novamente. Funções anônimas são frequentemente utilizadas em conjunto com funções da família apply, como lapply, sapply, que aplicam uma função (anônima) a cada elemento de uma lista ou vetor. Essa combinação permite transformar e processar dados de maneira eficiente e elegante, tornando-as uma ferramenta poderosa para a manipulação e análise de dados em R.\nEntretanto, as funções da família apply são bastante sofisticdas, e estão além do escopo desse livro de introdução ao R. Para mais informações sobre essas funções, consulte a documentação do R ou o livro R for Data Science de Hadley Wickham e Garrett Grolemund."
  },
  {
    "objectID": "09-R-Packages.html#tidyverse",
    "href": "09-R-Packages.html#tidyverse",
    "title": "10  Pacotes do R",
    "section": "10.1 Tidyverse",
    "text": "10.1 Tidyverse\nO tidyverse é uma coleção de pacotes R projetados para ciência de dados, para manipulação, exploração e visualização de dados, inicialmente desenvolvidos por Hadley Wickham, mas que continuam sendo expandidos por vários colaboradores.\nEntre os pacotes mais importantes estão:\n1.readr\nO pacote readr fornece uma maneira rápida e amigável de ler dados tabulados (como .csv, .tsv e fwf). Veremos as funções read_csv() e readcsv2() para leitura de dados em formato csv.\n2.tibble\no pacote tibble atualiza o objeto data frame para a tibble, uma versão mais moderna dos data frames.\n3.tidyr\nO pacote tidyr fornece um conjunto de funções que ajudam você a organizar os dados. Veremos como transformar data frames no formato wide em formato long e vice versa com as funções pivot_longer() e pivot_wider(); veremos como retirar observações com valores NA com a função drop_na() e como substituir observações com valores NA com a função replace_na().\n4.dplyr\nO pacote dplyr fornece uma gramática de manipulação de dados, fornecendo um conjunto consistente de funções que resolvem os desafios mais comuns de manipulação de dados. Veremos como extrair linhas que preencham certos critérios com a função filter(); seleciona uma ou um conjunto de colunas (variáveis) com a função select(); extrair os valores de uma coluna na forma de um vetor com a função pull(); agrupa dados segundo as categorias de uma variável categórica com a função group_by(); criar novas colunas (variáveis) a partir de outras já existentes com a função mutate() e como modifica valores de variáveis, numérica ou categóricas com a função recode().\n5.forcats\nO pacote forcats fornecer um conjunto de ferramentas que resolve problemas comuns com variáveis categóricas.\n6.ggplot2 O pacote ggplot2 é um sistema para criação declarativa de gráficos, baseado em The Grammar of Graphics. Você fornece os dados, diz ao ggplot2 como mapear variáveis, quais tipos de gráficos usar e ele cuida dos detalhes.\nO tidyverse tem diversos outros pacotes para funções mais complexas que estão fora do escopo desse livro, tais como o pacote purrr de programação funcional (FP) do R, para trabalhar com funções e vetores; o pacote pacote stringr para trabalhar com strings dentre vários outros."
  },
  {
    "objectID": "09-R-Packages.html#instalando-o-tidyverse",
    "href": "09-R-Packages.html#instalando-o-tidyverse",
    "title": "10  Pacotes do R",
    "section": "10.2 Instalando o tidyverse",
    "text": "10.2 Instalando o tidyverse\nPara instalar um pacote, você pode usar a função install.packages() no console. É importante salientar que um pacote deve ser sempre instalado a partir do console e nunca a partir de um script ou de qualquer outro documento de texto. Além disso, vale a pena lembrar que um pacote só precisa ser instalado uma única vez.\nPor outro lado, sempre que desejamos usar o pacote precisamos carregar esse pacote na memória (na sessão do R) com o comando library(). Esse carregamento do pacote na sessão deve ser feito toda vez que formos usar o pacote, de preferência no início da sessão. Em geral o comando library() deve ser um dos primeiros comandos de um script ou de um documento RNotebook ou Quarto. Frequentemente você verá que as primeiras linhas de um código contém diversos comandos library() cada um carregando um dos pacotes a serem usados naquela sessão.\nPara instalar o tidyverse usamos o comando install.packages() no console, como mostrado abaixo:\n> install.packages(\"tidyverse\")\n\n\n\n\n\nInstalling the tidyvese package\n\n\n\n\nAo executar esse comando você verá que o R instala diversos pacotes do tidyverse. Será necessária uma conexão com a internet para que esses pacotes sejam todos instalados. Dependendo da velocidade de sua conexão isso pode levar alguns minutos.\n\nAtenção, isso só precisa ser feito uma vez!! Se você já instalou esse pacote, passe para a próxima etapa. Lembre-se, que um pacote só precisa ser instalado uma única vez."
  },
  {
    "objectID": "09-R-Packages.html#carrregando-pacotes",
    "href": "09-R-Packages.html#carrregando-pacotes",
    "title": "10  Pacotes do R",
    "section": "10.3 Carrregando pacotes",
    "text": "10.3 Carrregando pacotes\nA segunda etapa é carregar o pacote na sessão. Isso é feito com o comando library(). O carregamento dos pacotes necessários deve ser feito sempre no início de seu código.\nPara carregar o pacote tidyverse em sua sessão R, use o comando library() no início de seu script ou de seu R Notebook ou documento Quarto, como mostrado abaixo.\n\n\n\n\n\nLoading the tidyvese package\n\n\n\n\nObserve que no comando library() o nome do pacote não precisa ser escrito entre aspas."
  },
  {
    "objectID": "09-R-Packages.html#datasets-do-ggplot2",
    "href": "09-R-Packages.html#datasets-do-ggplot2",
    "title": "10  Pacotes do R",
    "section": "10.4 Datasets do ggplot2",
    "text": "10.4 Datasets do ggplot2\nO pacote ggplot2 também possui vários datasets (conjuntos de dados) para facilitar o aprendizado. Podemos carregar os datasets já inclusos no ggplot2 com a função mesma função data(), bastando incluir como argumento o nome do dataset desejado, desde que que o ggplot2 ou o tidyverse já tenham sido previamente carregados.\nPara acessar o dataset mpg use o código abaixo:\n\nlibrary(ggplot2) # necessário para acessar os datasets do ggplot2\ndata(mpg)\n\nExperimente usar a função str(), que mostra a estrutura dos dados de um objeto. Você verá que o dataset mpg é um data frame com 234 observações (234 linhas) e 11 variáveis, como mostrado abaixo.\n\nstr(mpg)\n\ntibble [234 × 11] (S3: tbl_df/tbl/data.frame)\n $ manufacturer: chr [1:234] \"audi\" \"audi\" \"audi\" \"audi\" ...\n $ model       : chr [1:234] \"a4\" \"a4\" \"a4\" \"a4\" ...\n $ displ       : num [1:234] 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ...\n $ year        : int [1:234] 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ...\n $ cyl         : int [1:234] 4 4 4 4 6 6 6 4 4 4 ...\n $ trans       : chr [1:234] \"auto(l5)\" \"manual(m5)\" \"manual(m6)\" \"auto(av)\" ...\n $ drv         : chr [1:234] \"f\" \"f\" \"f\" \"f\" ...\n $ cty         : int [1:234] 18 21 20 21 16 18 18 18 16 20 ...\n $ hwy         : int [1:234] 29 29 31 30 26 26 27 26 25 28 ...\n $ fl          : chr [1:234] \"p\" \"p\" \"p\" \"p\" ...\n $ class       : chr [1:234] \"compact\" \"compact\" \"compact\" \"compact\" ...\n\n\nO acrônimo mpg significa Miles Per Gallon - uma medida de quantas milhas um carro pode viajar se você colocar apenas um galão de gasolina ou diesel em seu tanque (1 galão equivale a 3.79 litros e uma milha equivale a 1.6km). Esta medida padronizada serve comparar carros com base na sua eficiência. O conjunto de dados mpg que vem junto com o ggplot2 é apenas um subconjunto dos dados de economia de combustível que a EPA (Enviroment Protection Agency - USA) disponibiliza em http://fueleconomy.gov. O conjunto completo dos dados podem ser obtidos nesse site, no link seguir: http://fueleconomy.gov/feg/download.shtml.\nEsse dataset possui 243 linhas (observações) com 11 variáveis. O significado de cada variável está descrito na documentação de ajuda do dataset mpg e pode ser visualizado com o comando ?mpg no console. A tabela a seguir mostra o significado de cada variável desse dataset.\n\n\n\n\n\ndicionário de variáveis do dataset mpg\n\n\n\n\n\n\n\n\nHornik, Kurt. 2012. “Are There Too Many r Packages?” Journal Article. Austrian Journal of Statistics 41 (1): 59-66-59-66."
  },
  {
    "objectID": "10-Reading_data.html#formatos-de-arquivos-de-dados.",
    "href": "10-Reading_data.html#formatos-de-arquivos-de-dados.",
    "title": "11  Lendo dados",
    "section": "11.1 Formatos de arquivos de dados.",
    "text": "11.1 Formatos de arquivos de dados.\nVamos primeiro entender esses diferentes formatos de arquivos de dados. Cada documento em digital possui uma estrutura particular. por exemplos, aquivos .doc ou .docx do Word possuem uma estrutura própria da Microsoft, que o aplicativo Word compreende e, portanto, consegue abrir. Arquivos do tipo PDF (.pdf) possuem uma outra estrutura e, portanto, necessitam de softwares que saibam ler essa estrutura para poderem serem abertos.\nExistem diversos formatos de arquivos para armazenar dados, cada um apropriado para ser lido por determinados aplicativos. As letras finais em cada arquivo, depois do ponto final (extensão), indicam o tipo de arquivo. Vejamos alguns tipos comuns de arquivos\n\n\n\n\n\nfile extensions\n\n\n\n\nAlguns formatos de arquivos dependem de um software específico para sua leitura. Outros formatos são menos específicos, podendo ser lidos por um grande número de softwares, como é o caso dos arquivos .txt e dos arquivos .pdf. Esses formatos são mais universais, sendo padrões comuns para comunicação de informações. Dados de pesquisa, em formato de tabelas como mostrado, são usualmente armazenados em arquivos próprios para essa finalidade. Um formato comum é o usado por softwares de planilhas eletrônicas como o Excel da Microsoft. Existem inúmeros softwares desse tipo e cada um utiliza um formato específico, o que é justamente a desvantagem desse formato. o Excel usa arquivos que terminam com a extensão .xls ou .xlsx, o software de planilhas da Apple usa arquivos que terminam com a extensão .numbers, etc. O problema é que cada arquivo desse só pode ser lido pelo próprio software que criou o arquivo.\nUm dos formatos mais usuais para arquivar dados é o .csv, que em inglês significa “comma-separated values”, ou seja “dados separados por vírgulas” (Shafranovich 2005; Mitlöhner et al. 2016). Esse é um formato comum de arquivo de dados suportado por inúmeros softwares em todas as plataformas de computador (Mac, Windows, Linux etc), sendo por isso mesmo um dos tipos de arquivos mais usados para transferência de dados entre programas. Todo software de planilhas, tal como o Excel (PC ou Mac), Numbers (Mac), Libre Office etc. são capazes de ler e salvar os dados nesse formato."
  },
  {
    "objectID": "10-Reading_data.html#os-arquivos-.csv",
    "href": "10-Reading_data.html#os-arquivos-.csv",
    "title": "11  Lendo dados",
    "section": "11.2 Os arquivos .csv",
    "text": "11.2 Os arquivos .csv\nA extensão .csv no final do nome de um arquivo indica que esse é um arquivo de dados no formato separado por vírgulas. A estrutura desse arquivo é bastante simples: existem várias linhas, cada linha com vários dados, separados por vírgulas.\nExistem, entretanto variações nesse formato, por exemplo, no Brasil as casas decimais são separadas por vírgulas, nesse caso o delimitador dos valores não poderia ser a vírgula e é usado então o ponto e vírgula. Portanto, ao ler dados no formato .csv é sempre importante informar se os dados são separados por , ou ; e se o separador do decimal é a virgula, ou o ponto final. Caso contrário a leitura dos dados poderá ser corrompida. Um outro detalhe é que, em alguns arquivos, os valores faltantes são indicados por NA, em outros por um espaço em branco, ou por outro símbolo. É importante informar ao R como esses valores faltantes estão indicados no arquivo.\nUm arquivo de dados do tipo .csv pode ser visualizado através de qualquer leitor simples de texto, tal como o TextEdit do Mac ou o o Notepad no Windows. Abaixo podemos ver como um conjunto de dados simples está gravada num arquivo separado por vírgulas. Observe que a primeira linha representa o nome das variáveis.\n\n\n\n\n\ncsv_files\n\n\n\n\nOs arquivos .csv podem ser lidos por softwares de planilhas eletrônicas, tal como o Excel ou Numbers. A figura abaixo mostra como o Excel interpreta a primeira linha como sendo a dos nomes das variáveis e já separa as variáveis nas colunas e os dados de cada participante nas linhas.\n\n\n\n\n\ncsv_files\n\n\n\n\nExistem diversos modos de carregar dados no R. Podemos fazer isso usando os menus do RStudio ou através das funções do R base (read.csv, read.csv2, read.delim, etc.) ou com as funções de leitura mais modernas do pacote readr (read_csv, read_csv2, etc.), que faz parte do tidyverse. Vamos ver como fazer isso de cada uma dessas formas."
  },
  {
    "objectID": "10-Reading_data.html#lendo-dados-com-o-menu-do-rstudio.",
    "href": "10-Reading_data.html#lendo-dados-com-o-menu-do-rstudio.",
    "title": "11  Lendo dados",
    "section": "11.3 Lendo dados com o menu do RStudio.",
    "text": "11.3 Lendo dados com o menu do RStudio.\nO painel Enviroment possui uma aba chamada Import Dataset. Ao clicar nessa opção, podemos escolher que tipo de dados serão importatos (lidos): Texto, Excel, SPSS, SAS ou STATA. Para ler arquivos do tipo .csv podemos usar qualquer das duas primeiras opções From Text (base) ou From Text (readr), como mostra a figura abaixo.\n\n\n\n\n\nImportDataset\n\n\n\n\nVocê deverá escolher o aquivo .csv que deseja carregar no R. Será aberta uma aba para definir algumas opções.\nA figura abaixo mostra a janela de opções que será aberta ao clicar em From Text (base).\n\n\n\n\n\nImportDataset_artrite\n\n\n\n\nVocê deverá informar ao R alguns parâmetros:.\n\n\nHeading: Há um cabeçalho com o nome das variáveis?\n\nAs linhas tem nomes?\n\nQual o elemento que separa os valores? Virgula, ponto e vírgula, tabulação ou outro?\n\nQual o element que separal o decimal: Vírgula ou ponto final?\n\nHá elementos entre aspas? Qual tipo de aspas são usados: ” ” ou ’ ’ ?\n\nHá algum simbolo para comentários?\n\nComo estão registrados os valore NA: NA, em branco, ou de outra forma?\n\nVocê deseja que os elementos em texto sejam carregados no formato factor?\n\nO R já deverá ter escolhido a maioria desses parâmetros. Se deu tudo certo, os dados deverão aparecer na janela inferior, chamada de data frame, todos alinhados em colunas como mostrado a imagem acima. Agora basta clicar em import.\nEntretanto, apesar da facilidade de importar dados dessa forma. Essa não é a maneira ideal. A melhor técnica é criar o código que irá realizar a importação e incoporar esse código no início de seu script. Assim, automatizamos o processo de leitura dos dados e evitamos ter de clicar na função Import Dataset toda vez que formos trabalhar com nossos dados."
  },
  {
    "objectID": "10-Reading_data.html#lendo-dados-com-read.csv",
    "href": "10-Reading_data.html#lendo-dados-com-read.csv",
    "title": "11  Lendo dados",
    "section": "11.4 Lendo dados com read.csv()",
    "text": "11.4 Lendo dados com read.csv()\nCaso o arquivo esteja no formato .csv com as seus valores separados por vírgula (que é o padrão usual), podemos usar a função read.csv( ) para carregar os dados, bastando indicar o nome do arquivo a ser lido. Se por acaso o arquivo se chama diabetes.csv, então o comando de leitura será:\nread.csv(file = \"diabetes.csv\").\nO primeiro argumento da função read.csv é o mais importante, é o caminho e o nome do arquivo a ser lido. Um detalhe importante é saber qual é o working directory que você está usando. Lembre-se que a melhor forma de trabalhar no RStudio é criando um projeto, que define o diretório de trabalho como a pasta do projeto. Já detalhamos isso em capítulos anteriores sobre Working Directories e Projetos do RStudio (Chapter 5).\nO código acima ira funcionar se o arquivo chamado diabetes.csv estiver dentro do atual diretório de trabalho do R.\nSe o arquivo estiver numa pasta chamada dataset, dentro do diretório de trabalho, então teremos de incluir esse caminho no nome, tudo dentro das aspas, como abaixo:\nread.csv(file = \"dataset/diabetes.csv\").\nOu seja, com os dados no formato csv, a leitura dos dados é extremamente fácil com o comando acima. Esse comando lê o arquivo chamado diabetes.csv, que está na pasta dataset, dentro do diretório de trabalho atual.\nMas falta ainda um detalhe: é preciso colocar os dados lidos numa variável. O comando correto deve ser parecido com a linha abaixo.\nmydata <- read.csv(file = \"dataset/diabetes.csv\")\nNo caso acima a variável, ou melhor, o objeto, que vai receber os dados foi chamado de mydata e os dados estão sendo lidos de um arquivo chamado diabetes.csv. Dessa forma, os dados são lidos e colocados na variável mydata. Você verá que, ao ler um arquivo de dados dessa forma, o objeto mydata será um data frame, com linhas representando cada paciente (observação) e colunas representando as variáveis da pesquisa.\nCaso o arquivo contenha dados separados por ponto e vírgula, a função a ser usada é read.csv2():\nmydata <- read.csv2(file = \"dataset/diabetes.csv\")\nAmbas as funções read.csv() e read.csv2() são derivadas da função read.table(). Essas funções podem receber diversos argumentos para otimizar a leitura dos dados.\n\n\n\n\n\nread.table\n\n\n\n\nO comando acima poderia ser reescrito com todos esses argumentos de forma explícita como abaixo:\n\ndiabetes <- read.table(file       =\"dataset/diabetes.csv\", \n                       header     = TRUE,\n                       sep        = \",\",\n                       dec        = \".\",\n                       na.strings = \"NA\")\n\nO código acima faz o seguinte:\n\nLê um arquivo denominado diabetes.csv; que está na pasta dataset\n\nNo qual há um cabeçalho com os nomes da variáveis: header = TRUE\n\nCujos dados estão separados por vírgula: sep = \",\"\n\nCujos decimais são identificados pelo ponto final : dec  = \".\"\n\nE os valores faltantes estão intensificados no arquivo pelas letras NA: na.strings = \"NA\".\n\nFinalmente, esse data frame é armazenado num objeto chamado diabetes."
  },
  {
    "objectID": "10-Reading_data.html#lendo-arquivos-na-internet",
    "href": "10-Reading_data.html#lendo-arquivos-na-internet",
    "title": "11  Lendo dados",
    "section": "11.5 Lendo arquivos na internet",
    "text": "11.5 Lendo arquivos na internet\nLembre-se que o principal argumento da função read.csv() é o caminho do arquivo. Podemos também usar um caminho de um arquivo na internet. O arquivo diabetes.csv pode ser obtido na internet no site do departamento de estatística da Universidade de Vanderbilt.\nA página com os bancos de dados pode ser acessada no seguinte link: https://hbiostat.org/data\nÉ possível então navegar por essa página e fazer o download manualmente do dataset diabetes.csv.\nMas podemos automatizar esse processo inserindo o endereço exato do banco de dados na função read.csv(): https://hbiostat.org/data/repo/diabetes.csv\nVeja o código abaixo:\n\nmydata <- read.csv(file = \"https://hbiostat.org/data/repo/diabetes.csv\")\n\nna verdade nem precisamos explicitar o argumento file, podemos inserir apenas o endereço e obteremos o mesmo resultado. Lembre-se que é preciso colocar o endereço entre aspas.\n\nmydata <- read.csv(\"https://hbiostat.org/data/repo/diabetes.csv\")"
  },
  {
    "objectID": "10-Reading_data.html#lendo-dados-com-readr",
    "href": "10-Reading_data.html#lendo-dados-com-readr",
    "title": "11  Lendo dados",
    "section": "11.6 Lendo dados com readr",
    "text": "11.6 Lendo dados com readr\nO pacote readr do tidyverse fornece funções para leitura mais amigável de dados tabulados (como .csv, .tsv e .fwf), sendo preferírel em relação às funções base do R.\nO pacote readr vem também com diversos bancos de dados para servirem de exemplo, que podem ser acessados com a função readr_example(). Para a lista completa dos exemplos basta usar esse comando como mostrado a seguir.\nLembre-se que para usar as funções de algum pacote é preciso primeiro instalar o pacote com o comando install.packages() no console. Além disso, no corpo do código, é preciso inserir o comando library() com o nome do pacote que será usado. Só precisamos inserir o comando library() uma única vez. O estilo ideal de escrever é sempre carregar os pacotes necessários no início do código.\n\nlibrary(readr)\nreadr_example()\n\n [1] \"challenge.csv\"               \"chickens.csv\"               \n [3] \"epa78.txt\"                   \"example.log\"                \n [5] \"fwf-sample.txt\"              \"massey-rating.txt\"          \n [7] \"mini-gapminder-africa.csv\"   \"mini-gapminder-americas.csv\"\n [9] \"mini-gapminder-asia.csv\"     \"mini-gapminder-europe.csv\"  \n[11] \"mini-gapminder-oceania.csv\"  \"mtcars.csv\"                 \n[13] \"mtcars.csv.bz2\"              \"mtcars.csv.zip\"             \n[15] \"whitespace-sample.txt\"      \n\n\nQuando inserimos o nome do do banco de dados desejado como argumento da função, o resultado é o endereço do banco de dados em seu computador.\n\nreadr_example(\"chickens.csv\")\n\n[1] \"/Users/henriquealvarenga/Library/Caches/org.R-project.R/R/renv/cache/v5/macos/R-4.4/aarch64-apple-darwin20/readr/2.1.5/9de96463d2117f6ac49980577939dfb3/readr/extdata/chickens.csv\"\n\n\nAgora, para podermos usar esse banco de dados, basta usar a função read_csv() usando esse endereço, como feito abaixo:\n\nread_csv(readr_example(\"chickens.csv\"))\n\n# A tibble: 5 × 4\n  chicken                 sex     eggs_laid motto                               \n  <chr>                   <chr>       <dbl> <chr>                               \n1 Foghorn Leghorn         rooster         0 That's a joke, ah say, that's a jok…\n2 Chicken Little          hen             3 The sky is falling!                 \n3 Ginger                  hen            12 Listen. We'll either die free chick…\n4 Camilla the Chicken     hen             7 Bawk, buck, ba-gawk.                \n5 Ernie The Giant Chicken rooster         0 Put Captain Solo in the cargo hold. \n\n\nPodemos usar o pipe para o código ficar mais limpo:\n\nreadr_example(\"chickens.csv\") |> \n  read_csv()\n\nRows: 5 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): chicken, sex, motto\ndbl (1): eggs_laid\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 5 × 4\n  chicken                 sex     eggs_laid motto                               \n  <chr>                   <chr>       <dbl> <chr>                               \n1 Foghorn Leghorn         rooster         0 That's a joke, ah say, that's a jok…\n2 Chicken Little          hen             3 The sky is falling!                 \n3 Ginger                  hen            12 Listen. We'll either die free chick…\n4 Camilla the Chicken     hen             7 Bawk, buck, ba-gawk.                \n5 Ernie The Giant Chicken rooster         0 Put Captain Solo in the cargo hold. \n\n\nFinalmente, o código acima apenas lê os dados e mostra, mas precisamos armazenar os dados num objeto na memória do R, como feito a seguir:\n\ngalinhas <- readr_example(\"chickens.csv\") |> \n            read_csv()\n\nRows: 5 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): chicken, sex, motto\ndbl (1): eggs_laid\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nObserve que a função readr() mostra os detalhes do que ela fez:\n1. Mostra que o arquivo lido tinha 5 linhas e 4 colunas.\n2. Mostra que interpretou que o delimitador entre os elementos era a vírgula: Delimiter: \",\".\n3. Mostra que intrepretou as variáveis chicken, sex e motto como texto (char, caracteres).\n4. Mostra que intrepretou a variável eggs_laid como numérica (double).\n5. Explica que você pode usar o comando spec() para ver as especificações das colunas\n6. Explica que você pode usar o argumento show_col_types = FALSE para que o comando não mostre essas explicações todas.\n\ngalinhas\n\n# A tibble: 5 × 4\n  chicken                 sex     eggs_laid motto                               \n  <chr>                   <chr>       <dbl> <chr>                               \n1 Foghorn Leghorn         rooster         0 That's a joke, ah say, that's a jok…\n2 Chicken Little          hen             3 The sky is falling!                 \n3 Ginger                  hen            12 Listen. We'll either die free chick…\n4 Camilla the Chicken     hen             7 Bawk, buck, ba-gawk.                \n5 Ernie The Giant Chicken rooster         0 Put Captain Solo in the cargo hold. \n\n\nVamos repetir a leitura, agora com o argumento show_col_types = FALSE:\n\ngalinhas <- readr_example(\"chickens.csv\") |> \n            read_csv(show_col_types = FALSE) # lendo os dados sem mostrar todas as explicações\n\nPodemos verificar esses detalhes com a função spec(). Observe que essa função vai inspecionar o objeto que recebeu o arquivo que foi lido (galinhas) e não o arquivo csv. Portanto o argumento é galinhas não chickens.csv.\n\nspec(galinhas)\n\ncols(\n  chicken = col_character(),\n  sex = col_character(),\n  eggs_laid = col_double(),\n  motto = col_character()\n)"
  },
  {
    "objectID": "10-Reading_data.html#a-função-read_csv",
    "href": "10-Reading_data.html#a-função-read_csv",
    "title": "11  Lendo dados",
    "section": "11.7 A função read_csv()",
    "text": "11.7 A função read_csv()\nAs funções de leitura do pacote readr tem diversas vantagens sobre as funções básicas de leitura de dados do R.\nEm primeiro lugar, ao ler os dados usando read_csv() é criada uma tibble e não um data frame. E como já discutirmos antes, uma tibble é uma versão melhorada de um data frame.\nAlém disso, a função read_csv() é mais rápida que a versão base do R.\nEm resumo, sugiro usar a função read_csv() ou read_csv2() do pacote readr em vez das funções base do R read.csv() e read.csv2().\n\n11.7.0.1 Argumentos de read_csv() ou read_csv2()\nAs funções do pacote readr podem ser ajustadas com diversos argumentos.\nO primeiro argumento é o mais importante, é o caminho e o nome do arquivo a ser lido. Um detalhe importante é saber qual é o working directory que você está usando. Lembre-se que a melhor forma de trabalhar no RStudio é criando um projeto, que define o diretório de trabalho como a pasta do projeto. Já detalhamos isso em capítulos anteriores sobre Working Directories e Projetos do RStudio (Chapter 5).\nO arquivo diabetes.csv que eu tenho em meu computador está salvo na pasta dataset, dentro da pasta do meu projeto. Portanto, preciso informar isso nos argumentos da função read_csv().\nÉ necessário também armazenar os dados lidos num objeto, que irei chamar de diabetes. Obs: eu poderia escolher outro nome, não é necessário que o objeto que irá armazenar os dados tenha o mesmo nome que o arquivo com os dados.\nEu fiz o o download dos dados (https://hbiostat.org/data/repo/diabetes.csv) e e salvei esses dados numa pasta chamada dataset em meu projeto, então o código para ler esses dados é o seguinte. Nesse meu arquivo eu já modifiquei alguns dos nomes das variáveis para portugues.\n\ndiabetes <- read_csv(\"dataset/diabetes.csv\")\n\nRows: 403 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): cidade, sexo, biotipo\ndbl (15): n, id, colesterol, glicose, hdl, ratio, glicohemoglobina, idade, a...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nPodemos ler esses dados diretamente do site, como já fizemos anteriormente, nesse arquivo os nomes das variáveis ainda estão com os nomes originais em inglês.\n\ndiabetes <- read_csv(file = \"https://hbiostat.org/data/repo/diabetes.csv\")\n\nRows: 403 Columns: 19\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): location, gender, frame\ndbl (16): id, chol, stab.glu, hdl, ratio, glyhb, age, height, weight, bp.1s,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nPara mostrar a tibble basta digitar no console o nome da tibble:\n\ndiabetes\n\n# A tibble: 403 × 19\n      id  chol stab.glu   hdl ratio glyhb location     age gender height weight\n   <dbl> <dbl>    <dbl> <dbl> <dbl> <dbl> <chr>      <dbl> <chr>   <dbl>  <dbl>\n 1  1000   203       82    56  3.60  4.31 Buckingham    46 female     62    121\n 2  1001   165       97    24  6.90  4.44 Buckingham    29 female     64    218\n 3  1002   228       92    37  6.20  4.64 Buckingham    58 female     61    256\n 4  1003    78       93    12  6.5   4.63 Buckingham    67 male       67    119\n 5  1005   249       90    28  8.90  7.72 Buckingham    64 male       68    183\n 6  1008   248       94    69  3.60  4.81 Buckingham    34 male       71    190\n 7  1011   195       92    41  4.80  4.84 Buckingham    30 male       69    191\n 8  1015   227       75    44  5.20  3.94 Buckingham    37 male       59    170\n 9  1016   177       87    49  3.60  4.84 Buckingham    45 male       69    166\n10  1022   263       89    40  6.60  5.78 Buckingham    55 female     63    202\n# ℹ 393 more rows\n# ℹ 8 more variables: frame <chr>, bp.1s <dbl>, bp.1d <dbl>, bp.2s <dbl>,\n#   bp.2d <dbl>, waist <dbl>, hip <dbl>, time.ppn <dbl>\n\n\nObserve que as variáveis location, gender e frame foram intrepretadas como char. Essas variáveis são melhor analisadas quando são do tipo factor. Temos duas alternativas para resolver esse problema:\n\nTransformar em factor depois de ler, com a função as.factor().\nIndicar que são factor na própria função read_csv().\n\nVamos ver como fazer isso de cada uma dessas maneiras.\nTransformando variáveis em factor depois de ler os dados\nA função as.factor() tem como argumento um vetor, um dataframe ou uma tibble.\n\nTransformando um vetor numérico em factor:\n\n\n# criando um vetor numérico\nx <- c(1:10)\n\n# verificando a estrutura do vetor x antes de transformar em factor\nstr(x)\n\n int [1:10] 1 2 3 4 5 6 7 8 9 10\n\n# transformando em factor\nx2 <- as.factor(x)\n\n\n# verificando a estrutura do vetor x2 depois de transformar em factor\nstr(x2)\n\n Factor w/ 10 levels \"1\",\"2\",\"3\",\"4\",..: 1 2 3 4 5 6 7 8 9 10\n\n\n\nTransformando um vetor de caracteres em factor:\n\n\n# criando um vetor com caracteres\nx <- c(\"A\",\"B\", \"C\", \"D\")\n\n# verificando a estrutura do vetor x antes de transformar em factor\nstr(x)\n\n chr [1:4] \"A\" \"B\" \"C\" \"D\"\n\n# transformando em factor\nx2 <- as.factor(x)\n\n\n# verificando a estrutura do vetor x2 depois de transformar em factor\nstr(x2)\n\n Factor w/ 4 levels \"A\",\"B\",\"C\",\"D\": 1 2 3 4\n\n\n\nTransformando uma coluna de um data frame ou tibble em factor\n\n\ndiabetes$location  <- as.factor(diabetes$location)\ndiabetes$gender    <- as.factor(diabetes$gender)\ndiabetes$frame     <- as.factor(diabetes$frame)\n\nVeja que agora essas variáveis são do tipo factor.\n\nstr(diabetes) \n\nspc_tbl_ [403 × 19] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id      : num [1:403] 1000 1001 1002 1003 1005 ...\n $ chol    : num [1:403] 203 165 228 78 249 248 195 227 177 263 ...\n $ stab.glu: num [1:403] 82 97 92 93 90 94 92 75 87 89 ...\n $ hdl     : num [1:403] 56 24 37 12 28 69 41 44 49 40 ...\n $ ratio   : num [1:403] 3.6 6.9 6.2 6.5 8.9 ...\n $ glyhb   : num [1:403] 4.31 4.44 4.64 4.63 7.72 ...\n $ location: Factor w/ 2 levels \"Buckingham\",\"Louisa\": 1 1 1 1 1 1 1 1 1 1 ...\n $ age     : num [1:403] 46 29 58 67 64 34 30 37 45 55 ...\n $ gender  : Factor w/ 2 levels \"female\",\"male\": 1 1 1 2 2 2 2 2 2 1 ...\n $ height  : num [1:403] 62 64 61 67 68 71 69 59 69 63 ...\n $ weight  : num [1:403] 121 218 256 119 183 190 191 170 166 202 ...\n $ frame   : Factor w/ 3 levels \"large\",\"medium\",..: 2 1 1 1 2 1 2 2 1 3 ...\n $ bp.1s   : num [1:403] 118 112 190 110 138 132 161 NA 160 108 ...\n $ bp.1d   : num [1:403] 59 68 92 50 80 86 112 NA 80 72 ...\n $ bp.2s   : num [1:403] NA NA 185 NA NA NA 161 NA 128 NA ...\n $ bp.2d   : num [1:403] NA NA 92 NA NA NA 112 NA 86 NA ...\n $ waist   : num [1:403] 29 46 49 33 44 36 46 34 34 45 ...\n $ hip     : num [1:403] 38 48 57 38 41 42 49 39 40 50 ...\n $ time.ppn: num [1:403] 720 360 180 480 300 195 720 1020 300 240 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_double(),\n  ..   chol = col_double(),\n  ..   stab.glu = col_double(),\n  ..   hdl = col_double(),\n  ..   ratio = col_double(),\n  ..   glyhb = col_double(),\n  ..   location = col_character(),\n  ..   age = col_double(),\n  ..   gender = col_character(),\n  ..   height = col_double(),\n  ..   weight = col_double(),\n  ..   frame = col_character(),\n  ..   bp.1s = col_double(),\n  ..   bp.1d = col_double(),\n  ..   bp.2s = col_double(),\n  ..   bp.2d = col_double(),\n  ..   waist = col_double(),\n  ..   hip = col_double(),\n  ..   time.ppn = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\nTransformando variáveis em factor no momento da leitura dos dados\nPodemos usar o argumento col_types da função read_csv() para indicarmos qual o tipo correto da variável de cada coluna ou de algumas colunas em particular. No código abaixo foi indicado que as colunas (variáveis) sexo, cidade e biotipo deveriam ser interpretadas como factor.\n\ndiabetes <- read_csv(file = \"https://hbiostat.org/data/repo/diabetes.csv\", \n                     col_types = list(gender   = col_factor(), \n                                      location = col_factor(),\n                                      frame    = col_factor()))\nstr(diabetes)\n\nspc_tbl_ [403 × 19] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id      : num [1:403] 1000 1001 1002 1003 1005 ...\n $ chol    : num [1:403] 203 165 228 78 249 248 195 227 177 263 ...\n $ stab.glu: num [1:403] 82 97 92 93 90 94 92 75 87 89 ...\n $ hdl     : num [1:403] 56 24 37 12 28 69 41 44 49 40 ...\n $ ratio   : num [1:403] 3.6 6.9 6.2 6.5 8.9 ...\n $ glyhb   : num [1:403] 4.31 4.44 4.64 4.63 7.72 ...\n $ location: Factor w/ 2 levels \"Buckingham\",\"Louisa\": 1 1 1 1 1 1 1 1 1 1 ...\n $ age     : num [1:403] 46 29 58 67 64 34 30 37 45 55 ...\n $ gender  : Factor w/ 2 levels \"female\",\"male\": 1 1 1 2 2 2 2 2 2 1 ...\n $ height  : num [1:403] 62 64 61 67 68 71 69 59 69 63 ...\n $ weight  : num [1:403] 121 218 256 119 183 190 191 170 166 202 ...\n $ frame   : Factor w/ 3 levels \"medium\",\"large\",..: 1 2 2 2 1 2 1 1 2 3 ...\n $ bp.1s   : num [1:403] 118 112 190 110 138 132 161 NA 160 108 ...\n $ bp.1d   : num [1:403] 59 68 92 50 80 86 112 NA 80 72 ...\n $ bp.2s   : num [1:403] NA NA 185 NA NA NA 161 NA 128 NA ...\n $ bp.2d   : num [1:403] NA NA 92 NA NA NA 112 NA 86 NA ...\n $ waist   : num [1:403] 29 46 49 33 44 36 46 34 34 45 ...\n $ hip     : num [1:403] 38 48 57 38 41 42 49 39 40 50 ...\n $ time.ppn: num [1:403] 720 360 180 480 300 195 720 1020 300 240 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_double(),\n  ..   chol = col_double(),\n  ..   stab.glu = col_double(),\n  ..   hdl = col_double(),\n  ..   ratio = col_double(),\n  ..   glyhb = col_double(),\n  ..   location = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),\n  ..   age = col_double(),\n  ..   gender = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),\n  ..   height = col_double(),\n  ..   weight = col_double(),\n  ..   frame = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),\n  ..   bp.1s = col_double(),\n  ..   bp.1d = col_double(),\n  ..   bp.2s = col_double(),\n  ..   bp.2d = col_double(),\n  ..   waist = col_double(),\n  ..   hip = col_double(),\n  ..   time.ppn = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr>"
  },
  {
    "objectID": "10-Reading_data.html#lendo-arquivos-em-outros-formatos",
    "href": "10-Reading_data.html#lendo-arquivos-em-outros-formatos",
    "title": "11  Lendo dados",
    "section": "11.8 Lendo arquivos em outros formatos",
    "text": "11.8 Lendo arquivos em outros formatos\nO R também pode ler arquivos em outros formatos, tal como Excel, SAS, STATA, SPSS etc. Existem pacotes específicos para ler cada um desses formatos.\n\nO pacote readxl serve para ler arquivos do Excel, sendo capaz de ler .xls quanto os novos formatos .xlsx. A função para ler esses arquivos é read_excel().\nO pacote XML é capaz de ler arquivos XML, a função para ler esses arquivos é xmlParse() ou xmlToDataFrame().\nOs pacotes rjson e jsonlite tem funções para leitura arquivos JSON. A função para ler esses arquivos é fromJSON().\nO pacote haven do tidyverse é capaz de ler vários de vários tipos, tais como SAS, SPSS e STATA, através das seguintes funções: read_sas(), read_sav(), read_por(), read_dta(), read_xpt().\nO pacote foreign possui também funções para ler arquivos SPSS, a função para ler esses arquivos é read.spss().\nTabela de Funções e Pacotes de Leitura de Dados\n\n\n\n\n\n\n\n\n\nFunção\nPacote\nDescrição\nExemplo\n\n\n\n\nread.table()\nbase\nLeitura de arquivos tabulares\ndata <- read.table(\"file.txt\", header = TRUE)\n\n\nread.csv()\nbase\nLeitura de arquivos CSV\ndata <- read.csv(\"https://hbiostat.org/data/repo/diabetes.csv\")\n\n\nread_csv()\nreadr\nLeitura de arquivos CSV\ndata <- read_csv(\"https://hbiostat.org/data/repo/diabetes.csv\")\n\n\nread_excel()\nreadxl\nLeitura de arquivos Excel\ndata <- read_excel(\"file.xlsx\", sheet = 1)\n\n\nfromJSON()\njsonlite\nLeitura de arquivos JSON\ndata <- fromJSON(\"file.json\")\n\n\nread_xml()\nxml2\nLeitura de arquivos XML\ndata <- read_xml(\"file.xml\")\n\n\nread_sas()\nhaven\nLeitura de arquivos SAS\ndata <- read_sas(\"file.sas7bdat\")\n\n\nread_sav()\nhaven\nLeitura de arquivos SAV\ndata <- read_sav(\"file.sav\")\n\n\nread_dta()\nhaven\nLeitura de arquivos Stata\ndata <- read_dta(\"file.dta\")\n\n\nread_por()\nhaven\nLeitura de arquivos POR\ndata <- read_por(\"file.por\")\n\n\nread_xpt()\nhaven\nLeitura de arquivos transportados\ndata <- read_xpt(\"file.xpt\")\n\n\nread_stata()\nhaven\nLeitura de arquivos Stata\ndata <- read_stata(\"file.dta\")\n\n\nread_spss()\nforeign\nLeitura de arquivos SPSS\ndata <- read.spss(\"file.sav\", to.data.frame = TRUE)\n\n\n\n\n\n\n\nMitlöhner, Johann, Sebastian Neumaier, Jürgen Umbrich, and Axel Polleres. 2016. “Characteristics of Open Data CSV Files.” In 2016 2nd International Conference on Open and Big Data (OBD), 72–79. https://doi.org/10.1109/OBD.2016.18.\n\n\nShafranovich, Yakov. 2005. “Common Format and MIME Type for Comma-Separated Values (CSV) Files.” https://www.rfc-editor.org/rfc/pdfrfc/rfc4180.txt.pdf."
  },
  {
    "objectID": "11-Manipulating_data.html#sec-tidyr",
    "href": "11-Manipulating_data.html#sec-tidyr",
    "title": "12  Manipulando dados",
    "section": "12.1 Organizando e transformando dados com tidyr",
    "text": "12.1 Organizando e transformando dados com tidyr\nNa análise de dados na área da saúde, frequentemente lidamos com conjuntos de dados que precisam ser organizados de maneira eficiente para facilitar a análise e a visualização. O pacote tidyr do R é uma ferramenta poderosa para a manipulação e transformação de dados, permitindo que você organize seus dados de forma “arrumada” (tidy).\nO tidyr faz parte do universo tidyverse, uma coleção de pacotes R projetados para ciência de dados. Ele fornece funções que facilitam a conversão de dados em formatos que são mais compatíveis com outros pacotes do tidyverse, como dplyr, ggplot2 e readr.\nNeste capítulo, exploraremos as principais funções do tidyr, incluindo:\n\npivot_longer() e pivot_wider(): funções para converter dados entre formatos largos e longos, sucessores modernos das funções gather() e spread(), oferecendo maior flexibilidade e controle.\nseparate() e unite(): funções para dividir e combinar colunas, respectivamente.\ndrop_na(): função para remover linhas com valores ausentes.\nreplace_na(): função para remover linhas com valores ausentes.\n\nVamos começar explorando como o tidyr pode simplificar a manipulação de dados e permitir que você se concentre nas análises que realmente importam para suas pesquisas e práticas na área da saúde.\n\n12.1.1 Reformatação de Dados: Longo para Largo e Vice-Versa\nEm análise de dados, os termos “dados longos” e “dados largos” referem-se a diferentes formas de estruturar conjuntos de dados. Dados largos, também conhecidos como formato “tidy”, são caracterizados por uma estrutura em que cada variável tem sua própria coluna e cada observação tem sua própria linha. Este formato é intuitivo para visualização direta e facilita a manipulação de dados em muitos casos, especialmente quando se trabalha com pacotes do tidyverse.\nPor outro lado, dados longos possuem uma coluna para variáveis e outra para valores, permitindo múltiplas entradas para uma mesma entidade. Este formato é particularmente útil para análises temporais ou categóricas, onde múltiplas medições são realizadas para cada entidade. A habilidade de transformar dados entre esses formatos, utilizando funções como pivot_longer() e pivot_wider(), é crucial para uma análise eficiente e precisa, adaptando os dados à necessidade específica da tarefa analítica.\n\n\n\n\n\nLong data frame\n\n\n\n\n\n12.1.1.1 A função pivot_longer() e pivot_wider\nNa seção sobre data frames mostramos que o layout mais comum de um data frame é chamado de wide, na qual as linhas representam observações e as colunas representam variáveis. Mas nem sempre os data frames vem organizados da forma como precisamos. Às vezes uma variável está distribuída em mais de uma coluna.\nNum dataset que construimos em seções anteriores, por exemplo, existem duas colunas para representar os resultados de 2 diferentes tipos de tratamento, A e B. Essa separação pode ajudar a comparar visualmente os 2 tratamentos numa tabela.\nMas, pode ser interessante agrupar essas duas colunas num única variável, que poderíamos chamar de tratamento. Ou seja, podemos representar esse dados de duas formas, chamadas de wide ou long.\nEsse agrupamento de duas ou mais colunas em uma única variável é feito com a função pivot_longer().\nVamos recriar esse dataset novamente aqui, com 3 pacientes e os 2 tipos de tratamento:\n\n# criando os vetores do data frame simulado\npacientes   <- c(\"João\", \"José\", \"Maria\")\ntratamentoA <- c(25,16,20) \ntratamentoB <- c(12,8,9) \n\n# criando o data frame a partir dos vetores já criados\nresult <- data.frame(pacientes, tratamentoA, tratamentoB)\n\n# mostrando o data frame criado\nresult\n\n  pacientes tratamentoA tratamentoB\n1      João          25          12\n2      José          16           8\n3     Maria          20           9\n\n\nVeja que esse novo data frame possui 3 linhas e as colunas tratamentoA e tratamentoB com os resultados de cada tratamento.\nO que precisamos é unir essas duas últimas colunas (tratamentoA e tratamentoB) em uma única coluna que iremos denominar simplesmente de tratamento.\nObserve que o data frame no formato long terá 6 linhas, o dobro do anterior, e que os valores das duas antigas colunas(tratamentoA e tratamentoB) foram todos inseridos na coluna denominada tratamento. Observe que os resultados de cada tratamento foram colocados numa outra coluna que denominei de scores.\nOu seja, não há perda de informação, apenas uma modificação do layout do data frame, que é usualmente denominado de long, pelo fato de ser mais comprido que o anterior.\nEssa transformação é realizada com a função pivo_longer(), como mostram os códigos abaixo.\n\n# carregando o tidyr para usar a função pivot_longer\nlibrary(tidyr) \n\n# transformando a tibble para o formato long\nresult.long <- pivot_longer(result,                               \n                            cols=c(\"tratamentoA\", \"tratamentoB\"), \n                            names_to = \"tratamento\",               \n                            values_to = \"scores\")                 \nresult.long \n\n# A tibble: 6 × 3\n  pacientes tratamento  scores\n  <chr>     <chr>        <dbl>\n1 João      tratamentoA     25\n2 João      tratamentoB     12\n3 José      tratamentoA     16\n4 José      tratamentoB      8\n5 Maria     tratamentoA     20\n6 Maria     tratamentoB      9\n\n\nOu usando o operador pipe:\n\nresult.long <- result |> \n                pivot_longer(cols=c(\"tratamentoA\", \"tratamentoB\"), \n                             names_to = \"tratamento\",\n                             values_to = \"scores\")              \nresult.long \n\n# A tibble: 6 × 3\n  pacientes tratamento  scores\n  <chr>     <chr>        <dbl>\n1 João      tratamentoA     25\n2 João      tratamentoB     12\n3 José      tratamentoA     16\n4 José      tratamentoB      8\n5 Maria     tratamentoA     20\n6 Maria     tratamentoB      9\n\n\nO que a função pivot_longer() fez foi:\n\nCarregou o data frame indicado (result),\nSelecionou as colunas indicadas no argumento cols=c(\"tratamentoA\" e \"tratamentoB\").\nCriou uma coluna chamada tratamento e colocou nessa coluna os nomes tratamentoA e tratamentoB.\nCriou uma coluna chamada scores e colocou nessa coluna os valores que antes estavam nas colunas tratamentoA e tratamentoB.\n\nA função pivot_wider() faz justamente o oposto.\n\nresult.long |> pivot_wider(names_from = \"tratamento\", \n                            values_from = \"scores\")\n\n# A tibble: 3 × 3\n  pacientes tratamentoA tratamentoB\n  <chr>           <dbl>       <dbl>\n1 João               25          12\n2 José               16           8\n3 Maria              20           9\n\n\nVejamos como a transformação do data frame na versão long facilita a criação de um gráfico. Com esse novo formato, podemos usare a função geom_boxplot do ggplot para criar boxplots de cada tipo de tratamento, o que seria bem mais difícil no data frame do tipo wide.\n\nlibrary(ggplot2)\nggplot(result.long) +\n  geom_boxplot(aes(x=tratamento, y=scores)) +\n  theme_classic()\n\n\n\n\n\n\n\n12.1.2 Separando e unindo colunas\nQuando trabalhamos com conjuntos de dados na área da saúde, muitas vezes encontramos situações em que precisamos dividir uma coluna em várias ou combinar várias colunas em uma só. As funções separate() e unite() do pacote tidyr são projetadas exatamente para essas tarefas.\n\n12.1.2.1 Função separate()\nA função separate() é usada para dividir uma coluna em duas ou mais colunas. Esta função é especialmente útil quando uma coluna contém informações que podem ser separadas por um delimitador (como uma vírgula, espaço ou qualquer outro caractere).\nImagine que temos um conjunto de dados com uma coluna chamada data_hora que contém informações de data e hora combinadas numa única coluna como mostrado no código abaixo:\n\nlibrary(tidyr)\n\n# Exemplo de dados\ndados <- data.frame(id_paciente = c(1, 2, 3),\n                    data_hora = c(\"2024-05-01 14:30\", \"2024-05-02 09:15\", \"2024-05-03 18:45\"))\nprint(dados)\n\n  id_paciente        data_hora\n1           1 2024-05-01 14:30\n2           2 2024-05-02 09:15\n3           3 2024-05-03 18:45\n\n\nNesse caso, será útil colocar a data em uma coluna e a hora em outra coluna. A sintaxe da função separate é a seguinte:\nseparate(data, col, into, sep = \" \")\n\ndata: O conjunto de dados, o dataset\ncol: A coluna a ser separada.\ninto: Um vetor de novos nomes de colunas.\nsep: O delimitador que separa os valores (por padrão, é um espaço).\n\n\n# Usando separate para dividir a coluna data_hora em data e hora\ndados_separados <- separate(dados, \n                            col = \"data_hora\", \n                            into = c(\"data\", \"hora\"), \n                            sep = \" \")\n\nprint(dados_separados)\n\n  id_paciente       data  hora\n1           1 2024-05-01 14:30\n2           2 2024-05-02 09:15\n3           3 2024-05-03 18:45\n\n\nPodemos também separar a data em dia mes e ano, como mostrado no código abaixo\n\n# Usando separate para dividir a coluna data_hora em data e hora\ndados_dma <- separate(dados_separados, \n                      col = \"data\", \n                      into = c(\"ano\", \"mes\", \"dia\"), \n                      sep = \"-\")\n\nprint(dados_dma)\n\n  id_paciente  ano mes dia  hora\n1           1 2024  05  01 14:30\n2           2 2024  05  02 09:15\n3           3 2024  05  03 18:45\n\n\n\n# Usando separate para dividir a coluna hora em horas e minutos\ndados_hm <- separate(dados_dma, \n                      col = \"hora\", \n                      into = c(\"horas\", \"minutos\"), \n                      sep = \":\")\n\nprint(dados_hm)\n\n  id_paciente  ano mes dia horas minutos\n1           1 2024  05  01    14      30\n2           2 2024  05  02    09      15\n3           3 2024  05  03    18      45\n\n\n\n\n12.1.2.2 Função unite()\nA função unite() é usada para combinar duas ou mais colunas em uma única coluna. Essa função é útil quando queremos simplificar nosso conjunto de dados ou criar uma nova coluna combinada. A sintaxe dessa função é:\nunite(data, col, ..., sep = \"_\")\n-data: O conjunto de dados. -col: O nome da nova coluna. -…: As colunas a serem unidas. -sep: O delimitador a ser usado para unir os valores (por padrão, é um sublinhado “_”).\nVeja como unir as colunas que acabamos de separar:\n\n# Usando unite para combinar as colunas data e hora em data_hora\ndados <- unite(dados_hm, col = \"data_hora\", horas, minutos, sep = \":\")\n\nprint(dados)\n\n  id_paciente  ano mes dia data_hora\n1           1 2024  05  01     14:30\n2           2 2024  05  02     09:15\n3           3 2024  05  03     18:45\n\n\nA função unite() não suporte múltiplas uniões em um único comando. Assim, para unir novamente também as colunas ano, mes e dia, precisamos de uma nova linha com unite.\n\n# Usando unite para combinar as colunas data e hora em data_hora\nprint(dados_hm)\n\n  id_paciente  ano mes dia horas minutos\n1           1 2024  05  01    14      30\n2           2 2024  05  02    09      15\n3           3 2024  05  03    18      45\n\ndados_hm <- unite(dados_hm, col = \"data_hora\", horas, minutos, sep = \":\")\ndados_hm <- unite(dados_hm, col = \"data\", ano, mes, dia, sep = \"-\")\n\nprint(dados_hm)\n\n  id_paciente       data data_hora\n1           1 2024-05-01     14:30\n2           2 2024-05-02     09:15\n3           3 2024-05-03     18:45\n\n\n\n\n\n12.1.3 NA Values\nÉ muito frequente que faltem dados em pesquisas. Às vezes uma questão de um questionário deixou de ser respondida, às vezes um dado não foi encontrado etc. Esses dados são representados no R como NA, que significa NOT AVAILABLE. É importante reconhecer a existência desses dados faltantes pois a presença desses dados faltantes pode impedir que sejam executados cálculos matemáticos. Afinal de contas, o que poderia significar 3*NA? Experimente fazer essa conta no R.\n\n12.1.3.1 Desconsiderar valores NA\nComo vimos anteriormente, nem todos argumentos são valores numéricos. Alguns argumentos servem para indicar como a função deve se comportar. Um argumento importante de muitas funções é o na.rm = TRUE. a expressão na.rm=TRUE é uma abreviação de REMOVE NOT AVAILABLE DATA, ou seja, remova os dados faltantes. Ao indicarmos que esse argumento é verdadeiro (TRUE), o R irá desconsiderar dados em branco ou faltantes ao fazer os cálculos. Sem esse argumento, frequentemente os cálculos não são realizados.\nCriando uma variável peso com valores NA\n\npeso <- c(50,55,8, NA) \npeso\n\n[1] 50 55  8 NA\n\n\nTentando calcular a média do peso, sem retirar os valores NA\n\nmean(peso)\n\n[1] NA\n\n\nVeja que o resultado obtido foi NA, ou seja, o R não conseguiu fazer os cálculos. Uma das formas de resolver esse problema é retirar os valores NA antes de fazer os cálculos. Isso pode ser feito através do argumento na.rm = TRUE.\nTentando calcular a média do peso, indicando ao R para retirar os valores NA com o o argumento na.rm = TRUE\n\n# calcula a média do peso, retirando os valores NA, utilizando o argumento na.rm = TRUE\nmean(peso, na.rm = TRUE)\n\n[1] 37.66667\n\n\nVeremos a seguir como resolver problemas de valores NA em data frames usando o pacote dplyr, com as funções drop_na() e replace_na().\n\n\n12.1.3.2 A função drop_na()\nEm muitos conjuntos de dados, especialmente na área da saúde, é comum encontrar valores ausentes (NA). Esses valores podem surgir por diversos motivos, como erros de coleta de dados ou dados que não foram registrados. A função drop_na() do pacote tidyr é uma ferramenta eficaz para lidar com esses valores ausentes, permitindo a remoção de linhas que contêm NAs de forma fácil e eficiente.\nA função drop_na() serve para excluirmos linhas com valores NA antes de executarmos algum cálculo estatístico. Lembre-se que muitas funções estatísticas não conseguem ser executadas se houver valores NA nos dados.\nVamos criar uma tabela com valores NA e então tentar calcular a média de alguma das variáveis sem retirar os valores NA e, em seguida, retirando os valores NA.\n\nmydata <- tibble(\n  id     = 1:10,\n  sex    = c(\"Male\", \"Male\",\"Male\",\"Male\",\"Male\", \"Female\", \"Female\", \"Female\", \"Female\", \"Female\"),\n  age    = c(44, 18,  29,  33, 57,  47,  33,  71,  34,  NA),\n  height = c(NA, 172, 175, NA, 170, 169, 145, 179, 155, 149),\n  weight = c(70, 120, 90,  NA, 89,  72,  89,  91,  74,  70)\n)\n\nmydata\n\n# A tibble: 10 × 5\n      id sex      age height weight\n   <int> <chr>  <dbl>  <dbl>  <dbl>\n 1     1 Male      44     NA     70\n 2     2 Male      18    172    120\n 3     3 Male      29    175     90\n 4     4 Male      33     NA     NA\n 5     5 Male      57    170     89\n 6     6 Female    47    169     72\n 7     7 Female    33    145     89\n 8     8 Female    71    179     91\n 9     9 Female    34    155     74\n10    10 Female    NA    149     70\n\n\n1ª Tentativa: tentando calcular a média das idades sem retirar os valores NA.\n\nlibrary(dplyr) # necessário para usar a função pull\nmydata |> \n  select(age) |> \n  pull() |> \n  mean()\n\n[1] NA\n\n\n2ª Tentativa: tentando calcular a média das idades usando o argumento na.rm=TRUE.\n\nmydata |> \n  select(age) |> \n  pull() |> \n  mean(na.rm = TRUE)\n\n[1] 40.66667\n\n\nConseguimos calcular usando a função mean() com o argumento na.rm=TRUE. Entretanto, nem todas funções aceitam o argumento na.rm=TRUE. E as vezes precisamos retirar os valores NA numa sequencia diferente dentro do pipe. Podemos entáo resolver isso usando a função drop_na().\nVejamos o resultado usando a função drop_na(). Perceba que a função drop_na() precisa ser usada antes da função pull(). Isso é porque a função drop_na() atua em um data frame e a função pull() recebe um data frame e tem como output um vetor. Então, na sequencia do código, depois do pull() o que existe é um vetor e não um data frame. Por isso a função drop_na() não pode ser usada depois do pull().\n\nmydata |>\n  select(age) |> \n  drop_na() |> \n  pull() |>  \n  mean()\n\n[1] 40.66667\n\n\nVejamos alguns outros exemplos mais simples de como usar a função drop_na().\n\nlibrary(tidyr)\nlibrary(tibble)\n\n# Exemplo de dados de pacientes com NAs \npacientes <- tibble(id_paciente = 1:10,\n                    nome   = c(\"Ana\", \"Bruno\", NA, \"Diana\", \"Eduardo\", \n                             \"Fernanda\", \"Gustavo\", NA, \"Isabela\", \"João\"),\n                    idade  = c(25, 30, 35, 40, NA, 28, 33, 45, NA, 50),\n                    cidade = c(\"São Paulo\", \"Rio de Janeiro\", \"Belo Horizonte\", NA, \n                               \"Curitiba\", \"Porto Alegre\", \"Salvador\", \"Brasília\", \"Fortaleza\", NA))\n\nprint(pacientes)\n\n# A tibble: 10 × 4\n   id_paciente nome     idade cidade        \n         <int> <chr>    <dbl> <chr>         \n 1           1 Ana         25 São Paulo     \n 2           2 Bruno       30 Rio de Janeiro\n 3           3 <NA>        35 Belo Horizonte\n 4           4 Diana       40 <NA>          \n 5           5 Eduardo     NA Curitiba      \n 6           6 Fernanda    28 Porto Alegre  \n 7           7 Gustavo     33 Salvador      \n 8           8 <NA>        45 Brasília      \n 9           9 Isabela     NA Fortaleza     \n10          10 João        50 <NA>          \n\n\nPodemos usar a função drop_na() para retirar todas as linhas que tenham dados faltantes em toda a tibble\n\n# Remover linhas com NAs nas colunas 'nome' e 'idade'\npacientes2 <- drop_na(pacientes)\nprint(pacientes2)\n\n# A tibble: 4 × 4\n  id_paciente nome     idade cidade        \n        <int> <chr>    <dbl> <chr>         \n1           1 Ana         25 São Paulo     \n2           2 Bruno       30 Rio de Janeiro\n3           6 Fernanda    28 Porto Alegre  \n4           7 Gustavo     33 Salvador      \n\n\nÀs vezes, pode ser necessário remover linhas com NAs apenas em colunas específicas, enquanto preserva outras linhas com NAs em colunas menos críticas. Vamos considerar o mesmo conjunto de dados, mas desta vez removeremos apenas as linhas com NAs nas colunas nome e idade.\n\n# Remover linhas com NAs na coluna 'idade'\npacientes3 <- drop_na(pacientes, idade)\nprint(pacientes3)\n\n# A tibble: 8 × 4\n  id_paciente nome     idade cidade        \n        <int> <chr>    <dbl> <chr>         \n1           1 Ana         25 São Paulo     \n2           2 Bruno       30 Rio de Janeiro\n3           3 <NA>        35 Belo Horizonte\n4           4 Diana       40 <NA>          \n5           6 Fernanda    28 Porto Alegre  \n6           7 Gustavo     33 Salvador      \n7           8 <NA>        45 Brasília      \n8          10 João        50 <NA>          \n\n\n\n\n12.1.3.3 A função replace_na()\nNem sempre deletar da análise os valores NA é a melhor solução. Ao deletar um dado NA da amostra, podemos estar aumentando artificialmente o desvio padrão. Algumas vezes pode ser interessante substituir os valores NA por outro valor. Por exemplo, no caso de dados numéricos, é uma técnica comum substituir os valores NA pela média. Isso não modifica a média do conjunto, e evita que o desvio padrão seja artificialmente aumentado.\nPara substituir um valor numérico faltante pela média dos dados utilizando a função replace_na() do pacote tidyr, você pode seguir os passos abaixo. Primeiro, calcule a média dos valores existentes na coluna, ignorando os valores ausentes (NA). Em seguida, utilize replace_na() para substituir os valores ausentes pela média calculada.\nAqui está um exemplo detalhado, usando também a função mutate do pacote dplyr que será discutido no capítulo seguinte.\nVamos usar um conjunto de dados de pacientes e substituir os valores ausentes na coluna idade pela média das idades não ausentes.\n\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(dplyr)\n\n# Exemplo de dados de pacientes com NAs usando tibble\npacientes <- tibble(id_paciente = 1:10,\n                    nome   = c(\"Ana\", \"Bruno\", NA, \"Diana\", \"Eduardo\", \n                             \"Fernanda\", \"Gustavo\", NA, \"Isabela\", \"João\"),\n                    idade  = c(25, 30, 35, 40, NA, 28, 33, 45, NA, 50),\n                    cidade = c(\"São Paulo\", \"Rio de Janeiro\", \"Belo Horizonte\", NA, \"Curitiba\", \n                               \"Porto Alegre\", \"Salvador\", \"Brasília\", \"Fortaleza\", NA))\n\n\nprint(pacientes)\n\n# A tibble: 10 × 4\n   id_paciente nome     idade cidade        \n         <int> <chr>    <dbl> <chr>         \n 1           1 Ana         25 São Paulo     \n 2           2 Bruno       30 Rio de Janeiro\n 3           3 <NA>        35 Belo Horizonte\n 4           4 Diana       40 <NA>          \n 5           5 Eduardo     NA Curitiba      \n 6           6 Fernanda    28 Porto Alegre  \n 7           7 Gustavo     33 Salvador      \n 8           8 <NA>        45 Brasília      \n 9           9 Isabela     NA Fortaleza     \n10          10 João        50 <NA>          \n\n\n\nmean(pacientes$idade, na.rm = TRUE)\n\n[1] 35.75\n\nsd(pacientes$idade, na.rm = TRUE)\n\n[1] 8.647873\n\n\n\n# Calcular a média da coluna idade, ignorando NAs\nmedia_idade <- mean(pacientes$idade, na.rm = TRUE)\n\n# Substituir os valores ausentes na coluna idade com a média\npacientes <- pacientes |>\n  mutate(idade = replace_na(idade, media_idade))\n\nprint(pacientes)\n\n# A tibble: 10 × 4\n   id_paciente nome     idade cidade        \n         <int> <chr>    <dbl> <chr>         \n 1           1 Ana       25   São Paulo     \n 2           2 Bruno     30   Rio de Janeiro\n 3           3 <NA>      35   Belo Horizonte\n 4           4 Diana     40   <NA>          \n 5           5 Eduardo   35.8 Curitiba      \n 6           6 Fernanda  28   Porto Alegre  \n 7           7 Gustavo   33   Salvador      \n 8           8 <NA>      45   Brasília      \n 9           9 Isabela   35.8 Fortaleza     \n10          10 João      50   <NA>          \n\n\nObserve que os valores agora são mostrados com 2 casas decimais. Isso ocorre porque ao calcular a média da idade o R transformou esses dados que antes eram numeros inteiros (int) em números reais (dbl).\n\n# recalculando a média das idades, agora não precisamos mais de informar na.rm = TRUE\nmean(pacientes$idade)\n\n[1] 35.75\n\nsd(pacientes$idade)\n\n[1] 7.626707\n\n\nVeja que a média não foi alterada após a substituição dos valores faltantes pela própria média. O desvio padrão, por outro lado fica um pouco menor.\nPodemos usar replace_na() também para substituir o texto de variáveis. Por exemplo, podemos colocar o texto “Não informado” ou “Desconhecido” em campos onde havia NAs.\n\nlibrary(tidyr)\nlibrary(tibble)\n\n# Exemplo de dados de pacientes com NAs usando tibble\npacientes <- tibble(id_paciente = 1:10,\n                    nome   = c(\"Ana\", \"Bruno\", NA, \"Diana\", \"Eduardo\", \n                             \"Fernanda\", \"Gustavo\", NA, \"Isabela\", \"João\"),\n                    idade  = c(25, 30, 35, 40, NA, 28, 33, 45, NA, 50),\n                    cidade = c(\"São Paulo\", \"Rio de Janeiro\", \"Belo Horizonte\", NA, \"Curitiba\", \n                               \"Porto Alegre\", \"Salvador\", \"Brasília\", \"Fortaleza\", NA))\n\n# Substituir valores ausentes por valores específicos\npacientes_substituidos <- replace_na(pacientes, \n                                     list(nome = \"Desconhecido\",\n                                          cidade = \"Não Informado\"))\n\nprint(pacientes_substituidos)\n\n# A tibble: 10 × 4\n   id_paciente nome         idade cidade        \n         <int> <chr>        <dbl> <chr>         \n 1           1 Ana             25 São Paulo     \n 2           2 Bruno           30 Rio de Janeiro\n 3           3 Desconhecido    35 Belo Horizonte\n 4           4 Diana           40 Não Informado \n 5           5 Eduardo         NA Curitiba      \n 6           6 Fernanda        28 Porto Alegre  \n 7           7 Gustavo         33 Salvador      \n 8           8 Desconhecido    45 Brasília      \n 9           9 Isabela         NA Fortaleza     \n10          10 João            50 Não Informado"
  },
  {
    "objectID": "11-Manipulating_data.html#sec-dplyr",
    "href": "11-Manipulating_data.html#sec-dplyr",
    "title": "12  Manipulando dados",
    "section": "12.2 Manipulando dados com dplyr",
    "text": "12.2 Manipulando dados com dplyr\nA análise de dados envolve frequentemente a transformação e manipulação de grandes conjuntos de dados para torná-los prontos para a análise. No contexto médico, isso pode incluir a limpeza de dados de pacientes, o cálculo de estatísticas resumidas, a filtragem de observações relevantes e a combinação de diferentes fontes de dados.\nO pacote dplyr, parte integrante do tidyverse, é uma ferramenta poderosa para essas tarefas, proporcionando uma sintaxe clara e eficiente para a manipulação de dados em R.\nO dplyr oferece um conjunto de funções intuitivas e expressivas para a manipulação de dados tabulares. Estas funções permitem realizar operações como seleção de colunas, filtragem de linhas, agrupamento de dados, criação de novas variáveis e combinações de datasets. O foco do dplyr é a simplicidade e a legibilidade do código, o que facilita a escrita de scripts claros e concisos, mesmo para iniciantes.\n\n12.2.1 Funções Mais Importantes do dplyr\nO dplyr é um dos pacotes mais populares do tidyverse para manipulação de dados. Aqui estão algumas das funções mais importantes e frequentemente utilizadas no dplyr:\n\nfilter(): Filtra linhas em um conjunto de dados com base em condições específicas.\nselect(): Seleciona colunas específicas de um conjunto de dados.\npull(): Extrai uma coluna de um conjunto de dados como um vetor.\nmutate(): Adiciona novas colunas ou modifica colunas existentes em um conjunto de dados.\narrange(): Ordena as linhas de um conjunto de dados com base em uma ou mais colunas.\ngroup_by(): Agrupa os dados com base em uma ou mais colunas, preparando-os para operações de agregação.\nungroup(): Remove agrupamentos de um conjunto de dados.\nrename(): Renomeia colunas em um conjunto de dados.\nrecode(): Recodifica valores, substituindo valores existentes por novos valores.\nbind_rows(): Empilha dois ou mais conjuntos de dados um em cima do outro (concatenação vertical).\nbind_cols(): Combina dois ou mais conjuntos de dados lado a lado (concatenação horizontal).\ndistinct(): Retorna linhas distintas, removendo duplicatas de um conjunto de dados.\ncount(): Conta o número de observações em cada grupo.\nsummarize() / summarise(): Resume os dados em uma única linha ou várias linhas, aplicando funções de agregação.\n\nEssas funções são fundamentais para a manipulação e transformação de dados em R, permitindo que você limpe, organize e analise seus dados de maneira eficiente.\n\n\n12.2.2 Filtrando linhas com filter()\nNum data frame as linhas representam as diferentes observações e as colunas representam as variáveis. Por exemplo, em pesquisas na área de saúde, geralmente cada linha representa um participante da pesquisa e as colunas as vriáveis da pesquisa.\nFrequentemente precisamos acessar subgrupos de um grande conjunto de dados, ou seja, precisamos selecionar subgrupos nos quais desejamos fazer nossa análise. Isso é feito no R com a função filter() do pacote dplyr que faz parte do tidyverse.\nO modo de usar a função filter() é muito simples: o primeiro argumento é o data frame a ser usado, em seguida as expressões lógicas para filtrar/selecionar as linhas do data frame, como mostraremos a seguir, usando novamente o dataset mpg do pacote ggplot2 (Esse pacote também faz parte do tidyverse).\nVamos carregar esses dados com a função data():\n\nlibrary(ggplot2) # necessária para poder ter acesso ao dataset mpg\ndata(mpg)\n\nRelembrando o significado de cada variável do dataset mpg:\n\n\n\n\n\nmpg dictionary\n\n\n\n\nSabemos que para acessar uma variável de um data frame usamos o operador $ e que a variável com os nomes das montadores é manufacturer. Vamos então checar quais são as montadoras dos carros dessa pacote com o comando unique(). Essa função lista os elementos de um conjunto, sem repetição:\n\nunique(mpg$manufacturer)\n\n [1] \"audi\"       \"chevrolet\"  \"dodge\"      \"ford\"       \"honda\"     \n [6] \"hyundai\"    \"jeep\"       \"land rover\" \"lincoln\"    \"mercury\"   \n[11] \"nissan\"     \"pontiac\"    \"subaru\"     \"toyota\"     \"volkswagen\"\n\n\nComo podemos ver, esse banco de dados tem carros de várias montadoras. Em análises estatísticas que é frequentemente necessário separar os dados de acordo com alguma regra, por exemplo, de acordo com a montadora. Podemos, por exemplo desejar analisar apenas os carros das montadoras tradicionais no Brasil (Ford, Chevrolet, Volkswagen). Vamos fazer um novo data frame com essas montadoras. Para isso usamos a função filter() como descrito anteriormente e criar um novo data frame chamado cfv, letras iniciais dessas montadoras.\n\ncfv <- filter(mpg, manufacturer %in% c(\"chevrolet\", \"ford\", \"volkswagen\"))\n\nObserve que usamos um novo operador nessa função %in%. Esse operador procurou dentro da variável manufacturer os nomes “chevrolet”, “ford”, “volkswagen”. A função filter() por sua vez, selecionou essas montadoras e o resultado foi colocado num novo data frame chamado de cfv.\nVeja que agora nosso data frame só possui essas três montadoras.\n\nunique(cfv$manufacturer)\n\n[1] \"chevrolet\"  \"ford\"       \"volkswagen\"\n\n\nPodemos visualizar o consumo dessas três marcar selecionadas num boxplot comparativo, como feito a seguir:\n\nboxplot(cty~manufacturer,   # plota o consumo de acordo com a montadora\n       data=cfv,        # indica que os dados estão no data frame cfv\n       col=\"lightblue\") # colore os box com a cor lightblue\n\n\n\n\nPodemos ver com essa análise inicial que os carros da volkswagen percorrem mais milhas com um galão que os carros da Chevrolet e da Ford. Mas quais são esses carros?\nPodemos usar o comando filter() para filtramos os dados de acordo com regras numéricas. Por exemplo, para sabermos quais são os carros que conseguem percorrer mais de 30 milhas com um galão usamos também a função filter() como abaixo, no qual criamos um novo data frame com o nome bestcars.\n\nbestcars <- filter(cfv, cty > 30)\n\nPara mostrar o conteúdo desse novo data frame que chamamos de bestaras basta digitar o nome do data frame no console. E para saber apenas o nome dos modelos desses carros, basta usar o operador $, como mostrado abaixo:\n\nbestcars$model\n\n[1] \"jetta\"      \"new beetle\"\n\n\nSe desejássemos separar apenas UMA determinada montadora, poderíamos da mesma forma usar a função filter. Lembrando que o operador de igualdade no R é um igual duplo ==. Por exemplo, podemos criar um dataframe apenas com os carros da Jeep.\n\njeep <- filter(mpg, manufacturer == \"jeep\")\njeep\n\n# A tibble: 8 × 11\n  manufacturer model       displ  year   cyl trans drv     cty   hwy fl    class\n  <chr>        <chr>       <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n1 jeep         grand cher…   3    2008     6 auto… 4        17    22 d     suv  \n2 jeep         grand cher…   3.7  2008     6 auto… 4        15    19 r     suv  \n3 jeep         grand cher…   4    1999     6 auto… 4        15    20 r     suv  \n4 jeep         grand cher…   4.7  1999     8 auto… 4        14    17 r     suv  \n5 jeep         grand cher…   4.7  2008     8 auto… 4         9    12 e     suv  \n6 jeep         grand cher…   4.7  2008     8 auto… 4        14    19 r     suv  \n7 jeep         grand cher…   5.7  2008     8 auto… 4        13    18 r     suv  \n8 jeep         grand cher…   6.1  2008     8 auto… 4        11    14 p     suv  \n\n\n\n\n12.2.3 Selecionando colunas com select()\nA função select() seleciona as colunas desejadas, ou seja, as variáveis desejadas. Muitas vezes um data frame possui muitas colunas e pode ser útil criar um novo data frame apenas com as variáveis de interesse. A função select() faz justamente isso. O dataset mpg possui 11 variáveis. Se nossa análise vai usar apenas manufacturer, displ e cty, podemos criar um novo data frame com apenas essas variáveis.\n\nlibrary(dplyr)\nlibrary(ggplot2) # necessária para poder ter acesso ao dataset mpg\nnewdf <- select(mpg, manufacturer, displ, cty)\n\nPara verificar esse novo data frame basta usar a função str() e veremos que agora só existem 3 variáveis.\n\nstr(newdf)\n\ntibble [234 × 3] (S3: tbl_df/tbl/data.frame)\n $ manufacturer: chr [1:234] \"audi\" \"audi\" \"audi\" \"audi\" ...\n $ displ       : num [1:234] 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ...\n $ cty         : int [1:234] 18 21 20 21 16 18 18 18 16 20 ...\n\n\nQuando trabalhamos com datasets com centenas ou milhares de variáveis, usar a função select() é bastante útil.\n\n\n12.2.4 Extraindo valores com pull()\nA função pull() funciona de forma parecida com o operador $. Ambos tem a função de extrair valores de um data frame. Já vimos como usar o operador $ para extrair valores de uma variável e usar esses valores em funções estatísticas tais como mean(), median() e sd(). Vamos relembrar como isso foi feito usando o dataset mpg.\n\n# calculando a média das milhas por galão na cidade \nlibrary(dplyr)\nlibrary(ggplot2) # necessária para poder ter acesso ao dataset mpg\nmean(mpg$cty) \n\n[1] 16.85897\n\n\nMas as vezes são necessárias diversas operações antes de encontrar o conjunto numérico desejado para calcular uma média. Por exemplo, se quisermos calcular a média das milhas percorridas com um galão em automóveis do tipo SUV? vamos ver como podemos fazer isso usando o operador pipe |> e as funções select(), filter() e pull().\n\ndata(mpg)\nmpg |> filter(class==\"suv\") |>\n        select(cty) |>\n        mean()\n\nWarning in mean.default(select(filter(mpg, class == \"suv\"), cty)): argument is\nnot numeric or logical: returning NA\n\n\n[1] NA\n\n\nO código acima falhou!. O motivo é que o argumento passado pelo pipe para a função mean() não é um vetor, mas sim uma data frame (ou uma tibble). Podemos conferir isso no código abaixo, onde substituimos a função mean() pela função class() que informa o tipo de objeto.\n\nmpg |> filter(class==\"suv\") |>\n        select(cty) |>\n        class()\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nPara que a função mean() possa calcular a média é necessário que o argumento passado para essa função seja um conjunto numérico, ou seja, um vetor numérico. É aí que entra a função pull(), que extrai os valores do data frame e repassa esse valores adiante pelo pipe. Vejamos agora como consertar o código.\n\nmpg |> filter(class==\"suv\") |>\n        select(cty) |>\n        pull() |>\n        mean()\n\n[1] 13.5\n\n\n\n\n12.2.5 Criando novas variáveis com mutate()\nÉ frequente a necessidade de modificar ou criar novas variáveis no processo de análise de dados. Uma situação comum é a necessidade de transformarmos a unidade de medida de libras para peso, de milhas para quilômetros, de horas para minutos etc.\nNo dataset mpg a medida da distância percorrida é dada em milhas. Podemos usar a função mutate() do pacote dplyr que faz parte do tidyverse para criar uma nova variável com a medida em quilômetros. Veja no código abaixo como fazer isso.\n\nlibrary(dplyr)\nlibrary(ggplot2) # necessária para poder ter acesso ao dataset mpg\nmutate(cty.km = cty*1.609344, mpg) \n\n# A tibble: 234 × 12\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows\n# ℹ 1 more variable: cty.km <dbl>\n\n\nO código acima por ser lido da seguinte maneira: crie uma variável com o nome cty.km com valores iguais aos da variável cty multiplicado por 1.609344, proveniente do dataset mpg. Esse código, entretanto, tem um problema: o resultado dessa operação não foi salvo em nenhuma variável. Ao ser executado, esse código irá apenas mostrar todo o resultado sem salvar nada. Para que a nova variável seja salva é necessário acrescenta essa etapa no código como feito abaixo.\n\nmpg <- mutate(cty.km = cty*1.609344, mpg) \n\nPodemos também reescrever esse código usando o operador pipe |> ou |>, tornando esse código mais fácil de ser compreendido.\n\nmpg <- mpg |> \n       mutate(cty.km = cty*1.609344) \n\nO coódigo acima pode ser lido da seguinte forma: use o dataset mpg, crie uma variável com o nome cty.km com valores iguais aos da variável cty multiplicado por 1.609344. Finalmente, acrescente essa nova variável no dataset mpg.\nVeja que, quando usamos o operador pipe, o dataset usado é informado antes do operador pipe e as funções a seguir já não precisam mais dessa informação nos seus argumentos.\n\n\n12.2.6 Ordenando dados com arrange()\nNa manipulação de dados, a ordenação é uma operação fundamental que ajuda a organizar e visualizar melhor os dados. A função arrange() do pacote dplyr permite ordenar as linhas de um data frame com base em uma ou mais colunas. Essa função é essencial para classificar dados em ordem crescente ou decrescente, facilitando a análise e a interpretação.\nSintaxe:\narrange(data, ...)\n- data: O data frame a ser ordenado.\n- …: As colunas pelas quais o data frame será ordenado.\nPor padrão, a ordenação é crescente. Para ordenar de forma decrescente, use o argumento desc().\n\nlibrary(dplyr)\nlibrary(tibble)\n\n# Exemplo de dados de pacientes\npacientes <- tibble(id_paciente = 1:10,\n                    nome   = c(\"Ana\", \"Bruno\", \"Carlos\", \"Diana\", \"Eduardo\", \n                             \"Fernanda\", \"Gustavo\", \"Helena\", \"Isabela\", \"João\"),\n                    idade  = c(25, 30, 35, 40, 50, 28, 33, 50, 22, 50),\n                    cidade = c(\"São Paulo\", \"Rio de Janeiro\", \"Belo Horizonte\", \"Curitiba\", \"Porto Alegre\", \n                               \"Salvador\", \"Brasília\", \"Fortaleza\", \"Manaus\", \"Recife\"))\n\nprint(pacientes)\n\n# A tibble: 10 × 4\n   id_paciente nome     idade cidade        \n         <int> <chr>    <dbl> <chr>         \n 1           1 Ana         25 São Paulo     \n 2           2 Bruno       30 Rio de Janeiro\n 3           3 Carlos      35 Belo Horizonte\n 4           4 Diana       40 Curitiba      \n 5           5 Eduardo     50 Porto Alegre  \n 6           6 Fernanda    28 Salvador      \n 7           7 Gustavo     33 Brasília      \n 8           8 Helena      50 Fortaleza     \n 9           9 Isabela     22 Manaus        \n10          10 João        50 Recife        \n\n\n\n# Ordenar os dados pela coluna idade em ordem crescente\npacientes_ordenados <- arrange(pacientes, idade)\nprint(pacientes_ordenados)\n\n# A tibble: 10 × 4\n   id_paciente nome     idade cidade        \n         <int> <chr>    <dbl> <chr>         \n 1           9 Isabela     22 Manaus        \n 2           1 Ana         25 São Paulo     \n 3           6 Fernanda    28 Salvador      \n 4           2 Bruno       30 Rio de Janeiro\n 5           7 Gustavo     33 Brasília      \n 6           3 Carlos      35 Belo Horizonte\n 7           4 Diana       40 Curitiba      \n 8           5 Eduardo     50 Porto Alegre  \n 9           8 Helena      50 Fortaleza     \n10          10 João        50 Recife        \n\n\nAgora, vamos ordenar os dados pela coluna idade em ordem decrescente.\n\n# Ordenar os dados pela coluna idade em ordem decrescente\npacientes_ordenados_desc <- arrange(pacientes, desc(idade))\nprint(pacientes_ordenados_desc)\n\n# A tibble: 10 × 4\n   id_paciente nome     idade cidade        \n         <int> <chr>    <dbl> <chr>         \n 1           5 Eduardo     50 Porto Alegre  \n 2           8 Helena      50 Fortaleza     \n 3          10 João        50 Recife        \n 4           4 Diana       40 Curitiba      \n 5           3 Carlos      35 Belo Horizonte\n 6           7 Gustavo     33 Brasília      \n 7           2 Bruno       30 Rio de Janeiro\n 8           6 Fernanda    28 Salvador      \n 9           1 Ana         25 São Paulo     \n10           9 Isabela     22 Manaus        \n\n\nPodemos também ordenar o data frame por múltiplas colunas. Por exemplo, vamos ordenar pela coluna idade em ordem crescente e, em seguida, pela coluna cidade em ordem crescente.\n\n# Ordenar os dados pela coluna idade e depois pela coluna nome\npacientes_ordenados_mult <- arrange(pacientes, idade, cidade)\nprint(pacientes_ordenados_mult)\n\n# A tibble: 10 × 4\n   id_paciente nome     idade cidade        \n         <int> <chr>    <dbl> <chr>         \n 1           9 Isabela     22 Manaus        \n 2           1 Ana         25 São Paulo     \n 3           6 Fernanda    28 Salvador      \n 4           2 Bruno       30 Rio de Janeiro\n 5           7 Gustavo     33 Brasília      \n 6           3 Carlos      35 Belo Horizonte\n 7           4 Diana       40 Curitiba      \n 8           8 Helena      50 Fortaleza     \n 9           5 Eduardo     50 Porto Alegre  \n10          10 João        50 Recife        \n\n\n\n\n12.2.7 Agrupando dadoc com group_by() e by()\nAs funções by() do R base e group_by() do dplyr no tidyverse são usadas para agrupar dados e aplicar operações sobre esses grupos. Ambas são ferramentas poderosas para manipulação de dados, mas possuem diferentes sintaxes e vantagens.\nPropósito e Vantagens\nby()\nA função by() é usada para aplicar uma função a subconjuntos de um data frame, organizados por um fator ou uma combinação de fatores. É uma solução base do R, sem necessidade de carregar pacotes adicionais. As vantagens de by() incluem:\n\nSimplicidade: Uma solução base do R, que não requer pacotes externos.\nFlexibilidade: Pode ser usada com qualquer função que aceite data frames como input.\nCompatibilidade: Por ser parte do R base, funciona em qualquer instalação do R.\nResulta em listas: O output é uma lista, que pode ser útil para manipulações subsequentes.\n\ngroup_by()\nA função group_by() do pacote dplyr, parte do tidyverse, é usada para agrupar dados em um data frame e é geralmente combinada com outras funções como summarise, mutate, etc. As vantagens de group_by() incluem:\n\nFacilidade de uso: Sintaxe intuitiva e fácil de usar.\nIntegração com a pipe (%>%): Permite a construção de pipelines de manipulação de dados de maneira clara e legível.\nFlexibilidade: Pode ser usada com múltiplas colunas para criar grupos mais complexos.\nPerformance: Otimizada para grandes conjuntos de dados.\nCompatibilidade: Facilmente combinada com outros pacotes do tidyverse.\n\n\n12.2.7.1 Agrupando com a função by()\nA função by() estratifica ou agrupa dados segundo alguma variável categórica. Podemos, portanto, aplicar a função summary() no dataset mtcars através da função by(), estratificando o dataset de acordo com o tipo de câmbio (manual ou automático) e aplicando a função summary() em cada grupo. Veja como fazer isso no código abaixo.\n\nby(mtcars, mtcars$am, summary)\n\nmtcars$am: 0\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0  \n 1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5  \n Median :17.30   Median :8.000   Median :275.8   Median :175.0  \n Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3  \n 3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5  \n Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0  \n      drat             wt             qsec             vs               am   \n Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.   :0  \n 1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st Qu.:0  \n Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median :0  \n Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean   :0  \n 3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd Qu.:0  \n Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.   :0  \n      gear            carb      \n Min.   :3.000   Min.   :1.000  \n 1st Qu.:3.000   1st Qu.:2.000  \n Median :3.000   Median :3.000  \n Mean   :3.211   Mean   :2.737  \n 3rd Qu.:3.000   3rd Qu.:4.000  \n Max.   :4.000   Max.   :4.000  \n------------------------------------------------------------ \nmtcars$am: 1\n      mpg             cyl             disp             hp             drat     \n Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.   :3.54  \n 1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st Qu.:3.85  \n Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median :4.08  \n Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean   :4.05  \n 3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd Qu.:4.22  \n Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.   :4.93  \n       wt             qsec             vs               am         gear      \n Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.   :4.000  \n 1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st Qu.:4.000  \n Median :2.320   Median :17.02   Median :1.0000   Median :1   Median :4.000  \n Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean   :4.385  \n 3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd Qu.:5.000  \n Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.   :5.000  \n      carb      \n Min.   :1.000  \n 1st Qu.:1.000  \n Median :2.000  \n Mean   :2.923  \n 3rd Qu.:4.000  \n Max.   :8.000  \n\n\n\n\n12.2.7.2 Agrupando com a função group_by()\nFrequentemente precisamos realizar análises estatísticas em grupos, por exemplo, a média de idade entre os homens e a média de idade entre as mulheres. Para isso será necessário separar esses grupos antes de realizar a análise. Por exemplo, para calcular a média de alguma variável em cada tipo de carro precisamos, criar grupos segundo o tipo de carro e depois calcular a média.\nNas seções anteriores vimos como usar o comando filter() para selecionar subgrupos dentre os dados. Havíamos usado o comando filter() para selecionar algumas das montadoras dentre as várias existentes. Esse comando é útil quando precisamos de apenas alguns grupos dentre os vários existentes. E usamos também a função select() para selecionar as variáveis de interesse.\nO comando group_by(), usado em conjunto com a função summarize(), nos permite fazer exatamente isso de uma forma mais simples.\nO código abaixo cria grupos segundo o tipo de carro (class) e depois calcula a média da distância percorrida na cidade com um galão (variável cty) de cada grupo. O resultado é apresentado numa tabela que pode ser armazenada em um novo objeto, se necessário.\n\nlibrary(dplyr)\nlibrary(ggplot2) # necessária para poder ter acesso ao dataset mpg\nmpg |> \n  group_by(class) |> \n  summarize(mean(cty))\n\n# A tibble: 7 × 2\n  class      `mean(cty)`\n  <chr>            <dbl>\n1 2seater           15.4\n2 compact           20.1\n3 midsize           18.8\n4 minivan           15.8\n5 pickup            13  \n6 subcompact        20.4\n7 suv               13.5\n\n\nPodemos ver que, com um galão de gasolina, os SUVs e as Pickups conseguem percorrer uma distância bem menor que os outros tipos de carros, ou seja, são bem menos econômicos. Já os carros compactos e subcompactos conseguem percorrer uma distância bem maior com apenas um galão, sendo, portanto, mais econômicos.\nPodemos calcular mais de uma medida em cada grupo, bastando incluir o que se deseja calcular como argumento da função summarize(), como mostra o código a seguir.\n\nmpg |> \ngroup_by(class) |> \nsummarize(mean(cty), median(cty), sd(cty), max(cty), min(cty))\n\n# A tibble: 7 × 6\n  class      `mean(cty)` `median(cty)` `sd(cty)` `max(cty)` `min(cty)`\n  <chr>            <dbl>         <dbl>     <dbl>      <int>      <int>\n1 2seater           15.4            15     0.548         16         15\n2 compact           20.1            20     3.39          33         15\n3 midsize           18.8            18     1.95          23         15\n4 minivan           15.8            16     1.83          18         11\n5 pickup            13              13     2.05          17          9\n6 subcompact        20.4            19     4.60          35         14\n7 suv               13.5            13     2.42          20          9\n\n\nPodemos também incluir um nome para cada estatística calculada, como feito abaixo. Lembre-se apenas de não usar acentos, espaços ou caracteres especiais no nome usado.\n\nmpg |> \ngroup_by(class) |> \nsummarize(media=mean(cty), mediana=median(cty), desvio_padrão=sd(cty), maximo=max(cty), minimo=min(cty))\n\n# A tibble: 7 × 6\n  class      media mediana desvio_padrão maximo minimo\n  <chr>      <dbl>   <dbl>         <dbl>  <int>  <int>\n1 2seater     15.4      15         0.548     16     15\n2 compact     20.1      20         3.39      33     15\n3 midsize     18.8      18         1.95      23     15\n4 minivan     15.8      16         1.83      18     11\n5 pickup      13        13         2.05      17      9\n6 subcompact  20.4      19         4.60      35     14\n7 suv         13.5      13         2.42      20      9\n\n\nO comando group_by() também pode ser usado para agrupar dados de acordo com mais de uma variável, bastando separar as variáveis por vírgula dentro do parênteses. Por exemplo, para agrupar os dados de acordo com o tipo de carro e o tipo de tração usamos group_by(drv, class).\n\nmpg |> \n  group_by(drv, class) |> \n  summarize(media=mean(cty))\n\n# A tibble: 12 × 3\n# Groups:   drv [3]\n   drv   class      media\n   <chr> <chr>      <dbl>\n 1 4     compact     18  \n 2 4     midsize     16  \n 3 4     pickup      13  \n 4 4     subcompact  19.5\n 5 4     suv         13.8\n 6 f     compact     20.9\n 7 f     midsize     19.0\n 8 f     minivan     15.8\n 9 f     subcompact  22.4\n10 r     2seater     15.4\n11 r     subcompact  15.9\n12 r     suv         12  \n\n\nÉ possível que você veja uma mensagem “summarise() has grouped output by drv. You can override using the .groups argument.”\nEssa mensagem pode ser desconsiderada. Não se preocupe com isso. No meu código essa mensagem não aparece porque eu defini message=FALSE no cabeçalho do meu code chunk.\n\n\n\n12.2.8 Desagrupando dados com ungroup()\nAo trabalhar com conjuntos de dados, especialmente após aplicar a função group_by() para criar agrupamentos, pode ser necessário remover esses agrupamentos para realizar operações subsequentes que não dependem da estrutura de grupos. A função ungroup() do dplyr é utilizada para desfazer agrupamentos em um data frame, retornando-o ao seu estado original.\n\nlibrary(dplyr)\nlibrary(tibble)\n\n# Exemplo de dados de pacientes\npacientes <- tibble(\n  id_paciente = 1:10,\n  nome = c(\"Ana\", \"Bruno\", \"Carlos\", \"Diana\", \"Eduardo\", \n           \"Fernanda\", \"Gustavo\", \"Helena\", \"Isabela\", \"João\"),\n  idade = c(25, 30, 35, 40, 50, 28, 33, 45, 22, 50),\n  cidade = c(\"São Paulo\", \"Rio de Janeiro\", \"Belo Horizonte\", \"Curitiba\", \n             \"Porto Alegre\", \"Salvador\", \"Brasília\", \"Fortaleza\", \"Manaus\", \"Recife\"))\n\n# Agrupar os dados pela coluna cidade\npacientes_agrupados <- pacientes |>\n  group_by(cidade)\n\n# Realizar alguma operação de agrupamento, por exemplo, calcular a média da idade\nmedia_idade <- pacientes_agrupados |>\n  summarise(media_idade = mean(idade, na.rm = TRUE))\n\nprint(media_idade)\n\n# A tibble: 10 × 2\n   cidade         media_idade\n   <chr>                <dbl>\n 1 Belo Horizonte          35\n 2 Brasília                33\n 3 Curitiba                40\n 4 Fortaleza               45\n 5 Manaus                  22\n 6 Porto Alegre            50\n 7 Recife                  50\n 8 Rio de Janeiro          30\n 9 Salvador                28\n10 São Paulo               25\n\n\n\n# Desagrupar os dados\npacientes_desagrupados <- ungroup(pacientes_agrupados)\n\n# Verificar se os dados foram desagrupados\nprint(pacientes_desagrupados)\n\n# A tibble: 10 × 4\n   id_paciente nome     idade cidade        \n         <int> <chr>    <dbl> <chr>         \n 1           1 Ana         25 São Paulo     \n 2           2 Bruno       30 Rio de Janeiro\n 3           3 Carlos      35 Belo Horizonte\n 4           4 Diana       40 Curitiba      \n 5           5 Eduardo     50 Porto Alegre  \n 6           6 Fernanda    28 Salvador      \n 7           7 Gustavo     33 Brasília      \n 8           8 Helena      45 Fortaleza     \n 9           9 Isabela     22 Manaus        \n10          10 João        50 Recife        \n\n\n\n\n12.2.9 Renomeando colunas rename()\nA função rename() do dplyr é uma ferramenta essencial para renomear colunas em um data frame de forma clara e concisa. Ela permite que você torne os nomes das colunas mais descritivos, corrija erros de nomenclatura e padronize os nomes das colunas para facilitar a leitura e a manipulação dos dados. Seja renomeando uma única coluna ou várias colunas de uma vez, a função rename() simplifica o processo de ajuste dos nomes das colunas para melhor atender às necessidades de sua análise.\nTambém é possível renomear várias colunas de uma só vez, passando múltiplos pares de novo_nome = nome_antigo para a função rename().\nVamos considerar um conjunto de dados de pacientes e renomear a coluna idade para idade_anos e a coluna nome para primeiro_nome.\n\nlibrary(dplyr)\nlibrary(tibble)\n\n# Exemplo de dados de pacientes\npacientes <- tibble(\n  id_paciente = 1:10,\n  nome = c(\"Ana\", \"Bruno\", \"Carlos\", \"Diana\", \"Eduardo\", \n           \"Fernanda\", \"Gustavo\", \"Helena\", \"Isabela\", \"João\"),\n  idade = c(25, 30, 35, 40, 50, 28, 33, 45, 22, 50),\n  cidade = c(\"São Paulo\", \"Rio de Janeiro\", \"Belo Horizonte\", \"Curitiba\", \n             \"Porto Alegre\", \"Salvador\", \"Brasília\", \"Fortaleza\", \"Manaus\", \"Recife\"))\n\n\n# Renomear a coluna idade para idade_anos e nome para primeiro nome\npacientes_2 <- rename(pacientes, \n                      idade_anos = idade, \n                      primeiro_nome = nome)\nprint(pacientes_2)\n\n# A tibble: 10 × 4\n   id_paciente primeiro_nome idade_anos cidade        \n         <int> <chr>              <dbl> <chr>         \n 1           1 Ana                   25 São Paulo     \n 2           2 Bruno                 30 Rio de Janeiro\n 3           3 Carlos                35 Belo Horizonte\n 4           4 Diana                 40 Curitiba      \n 5           5 Eduardo               50 Porto Alegre  \n 6           6 Fernanda              28 Salvador      \n 7           7 Gustavo               33 Brasília      \n 8           8 Helena                45 Fortaleza     \n 9           9 Isabela               22 Manaus        \n10          10 João                  50 Recife        \n\n\n\n\n12.2.10 Recodificando valores com recode()\nFrequentemente necessitamos modificar valores de variáveis ou reduzir o número de variáveis categóricas. A função recode() serve para isso. No exemplo abaixo a variável x contém dados sobre o sexo, mas com nomes heterogêneos para identificar quem é do sexo masculino ou feminino. Com esses diferentes nomes a tabulação dos dados será inadequada.\n\nx <- c(\"Fem\", \"Fem\", \"Fem\", \"Feminino\", \n       \"Masc\", \"Masc\", \"Masc\", \"Masc\", \"Masc\", \"Masculino\" )\ntable(x)\n\nx\n      Fem  Feminino      Masc Masculino \n        3         1         5         1 \n\n\nPodemos resolver esse problema recodificando o valor da variável “Feminino” para “Fem” e “Masculino” para “Masc”. Observe que é preciso atribuir o resultado à um objeto para que a recodificação seja salva.\n\nx2 <- recode(x, Feminino = \"Fem\", Masculino = \"Masc\")\ntable(x2)\n\nx2\n Fem Masc \n   4    6 \n\n\nO código acima poderia ser reescrito com o operador pipe:\n\nx3 <- x |> recode(Feminino = \"Fem\", Masculino = \"Masc\")\ntable(x3)\n\nx3\n Fem Masc \n   4    6 \n\n\nA recodificação de variáveis pode servir também para reduzir o número de categorias de uma variável.\nPor exemplo, no dataset mpg a variável trans (tipo de transmissão) tem 10 categorias, ou seja, 10 diferentes de tipos de transmissão: 8 tipos de marchas automáticas e 2 tipos de marchas manuais.\n\nlibrary(dplyr)\nlibrary(ggplot2) # necessária para poder ter acesso ao dataset mpg\nunique(mpg$trans)\n\n [1] \"auto(l5)\"   \"manual(m5)\" \"manual(m6)\" \"auto(av)\"   \"auto(s6)\"  \n [6] \"auto(l4)\"   \"auto(l3)\"   \"auto(l6)\"   \"auto(s5)\"   \"auto(s4)\"  \n\n\nPara compararmos os carros com marchas automáticas com marchas manuais precisamos reduzir essas 10 categorias para apenas duas: manual e automática.\nPodemos fazer isso criando uma nova variável com apenas essas duas categorias.\nPodemos fazer isso usando função mutate() para criar uma nova variável marcha.\nUsaremos a função recode(), para codificar os valores da variável marcha a partir dos valores da variável trans, e o operador pipe para facilitar tudo isso.\n\nmpg <- mpg |> mutate(marcha = recode(trans,\n                                      \"auto(l3)\"   = \"automatica\",\n                                      \"auto(l4)\"   = \"automatica\", \n                                      \"auto(l5)\"   = \"automatica\",                                                                   \"auto(l6)\"   = \"automatica\", \n                                      \"auto(s4)\"   = \"automatica\",\n                                      \"auto(s5)\"   = \"automatica\", \n                                      \"auto(s6)\"   = \"automatica\",                                                                   \"auto(av)\"   = \"automatica\", \n                                      \"manual(m5)\" = \"manual\", \n                                      \"manual(m6)\" = \"manual\"))\n\nunique(mpg$marcha)\n\n[1] \"automatica\" \"manual\"    \n\n\nVeja que a variável marcha tem apenas 2 níveis: automática e manual:\n\ntable(mpg$marcha)\n\n\nautomatica     manual \n       157         77 \n\n\n\n\n12.2.11 Combinando data frames com bind_rows() e bind_cols()\nAo trabalhar com dados, muitas vezes é necessário combinar vários data frames em um único data frame. As funções bind_rows() e bind_cols() do pacote dplyr são projetada para concatenar data frames verticalmente, empilhando as linhas de cada data frame um em cima do outro, ou horizontalmente combinando suas colunas em um único data frame. Estas funções são particularmente útil quando se tem dados provenientes de diferentes fontes ou partes de um estudo que precisam ser unificados.\n\n12.2.11.1 Combinando por linhas com `bind_rows()\nExemplo 1: Combinar Dois Data Frames Simples\nVamos considerar dois data frames de pacientes e combiná-los verticalmente (por linhas) em um único data frame usando bind_rows(). Essa função funciona empilhando as linhas de cada data frame um em cima do outro.\n\nlibrary(dplyr)\nlibrary(tibble)\n\n# Exemplo de dados de pacientes - Parte 1\npacientes_parte1 <- tibble(id_paciente = 1:5,\n                           nome = c(\"Ana\", \"Bruno\", \"Carlos\", \"Diana\", \"Eduardo\"),\n                           idade = c(25, 30, 35, 40, 50),\n                           cidade = c(\"São Paulo\", \"Rio de Janeiro\", \"Belo Horizonte\", \"Curitiba\", \"Porto Alegre\"))\n\n# Exemplo de dados de pacientes - Parte 2\npacientes_parte2 <- tibble(id_paciente = 6:10,\n                           nome = c(\"Fernanda\", \"Gustavo\", \"Helena\", \"Isabela\", \"João\"),\n                           idade = c(28, 33, 45, 22, 50),\n                           cidade = c(\"Salvador\", \"Brasília\", \"Fortaleza\", \"Manaus\", \"Recife\"))\n\n# Combinar os data frames\npacientes <- bind_rows(pacientes_parte1, pacientes_parte2)\nprint(pacientes)\n\n# A tibble: 10 × 4\n   id_paciente nome     idade cidade        \n         <int> <chr>    <dbl> <chr>         \n 1           1 Ana         25 São Paulo     \n 2           2 Bruno       30 Rio de Janeiro\n 3           3 Carlos      35 Belo Horizonte\n 4           4 Diana       40 Curitiba      \n 5           5 Eduardo     50 Porto Alegre  \n 6           6 Fernanda    28 Salvador      \n 7           7 Gustavo     33 Brasília      \n 8           8 Helena      45 Fortaleza     \n 9           9 Isabela     22 Manaus        \n10          10 João        50 Recife        \n\n\nExemplo 2: Combinar Data Frames com Diferentes Colunas\nQuando os data frames têm diferentes colunas, bind_rows() ainda pode combiná-los, preenchendo as colunas ausentes com NA.\n\n# Exemplo de dados de pacientes - Parte 3 com coluna extra\npacientes_parte3 <- tibble(id_paciente = 11:12,\n                           nome = c(\"Lara\", \"Marcos\"),\n                           idade = c(27, 34),\n                           cidade = c(\"Natal\", \"Maceió\"),\n                           genero = c(\"Feminino\", \"Masculino\"))\n\n# Combinar os data frames\npacientes_completos <- bind_rows(pacientes_parte3, pacientes)\nprint(pacientes_completos)\n\n# A tibble: 12 × 5\n   id_paciente nome     idade cidade         genero   \n         <int> <chr>    <dbl> <chr>          <chr>    \n 1          11 Lara        27 Natal          Feminino \n 2          12 Marcos      34 Maceió         Masculino\n 3           1 Ana         25 São Paulo      <NA>     \n 4           2 Bruno       30 Rio de Janeiro <NA>     \n 5           3 Carlos      35 Belo Horizonte <NA>     \n 6           4 Diana       40 Curitiba       <NA>     \n 7           5 Eduardo     50 Porto Alegre   <NA>     \n 8           6 Fernanda    28 Salvador       <NA>     \n 9           7 Gustavo     33 Brasília       <NA>     \n10           8 Helena      45 Fortaleza      <NA>     \n11           9 Isabela     22 Manaus         <NA>     \n12          10 João        50 Recife         <NA>     \n\n\nExemplo 3: Adicionar uma Coluna de Identificação da Origem\nAo combinar vários data frames, pode ser útil adicionar uma coluna que identifique a origem de cada linha. Podemos fazer isso usando o argumento .id.\n\n# Combinar os data frames com uma coluna de identificação\npacientes_identificados <- bind_rows(parte1 = pacientes_parte1, \n                                     parte2 = pacientes_parte2, \n                                     parte3 = pacientes_parte3, \n                                     .id = \"origem\")\n\nprint(pacientes_identificados)\n\n# A tibble: 12 × 6\n   origem id_paciente nome     idade cidade         genero   \n   <chr>        <int> <chr>    <dbl> <chr>          <chr>    \n 1 parte1           1 Ana         25 São Paulo      <NA>     \n 2 parte1           2 Bruno       30 Rio de Janeiro <NA>     \n 3 parte1           3 Carlos      35 Belo Horizonte <NA>     \n 4 parte1           4 Diana       40 Curitiba       <NA>     \n 5 parte1           5 Eduardo     50 Porto Alegre   <NA>     \n 6 parte2           6 Fernanda    28 Salvador       <NA>     \n 7 parte2           7 Gustavo     33 Brasília       <NA>     \n 8 parte2           8 Helena      45 Fortaleza      <NA>     \n 9 parte2           9 Isabela     22 Manaus         <NA>     \n10 parte2          10 João        50 Recife         <NA>     \n11 parte3          11 Lara        27 Natal          Feminino \n12 parte3          12 Marcos      34 Maceió         Masculino\n\n\n\n\n12.2.11.2 Combinando por colunas bind_cols()\nAs vezes é necessário combinar várias tabelas ou data frames lado a lado, unindo suas colunas. A função bind_cols() do pacote dplyr é projetada para concatenar data frames horizontalmente, combinando suas colunas em um único data frame. Esta função é útil quando você tem diferentes partes de dados que compartilham a mesma estrutura de linhas e deseja uni-los para formar um conjunto de dados completo.\nExemplo: Combinar Dois Data Frames Lado a Lado\nVamos considerar dois data frames de pacientes que contêm informações complementares e combiná-los lado a lado usando bind_cols().\n\nlibrary(dplyr)\nlibrary(tibble)\n\n# Exemplo de dados de pacientes - Parte 1\npacientes_parte1 <- tibble(id_paciente = 1:5,\n                           nome = c(\"Ana\", \"Bruno\", \"Carlos\", \"Diana\", \"Eduardo\"))\n\n# Exemplo de dados de pacientes - Parte 2\npacientes_parte2 <- tibble(idade = c(25, 30, 35, 40, 50),\n                           cidade = c(\"São Paulo\", \"Rio de Janeiro\", \"Belo Horizonte\", \"Curitiba\", \"Porto Alegre\"))\n\n# Combinar os data frames\npacientes <- bind_cols(pacientes_parte1, pacientes_parte2)\n\nprint(pacientes)\n\n# A tibble: 5 × 4\n  id_paciente nome    idade cidade        \n        <int> <chr>   <dbl> <chr>         \n1           1 Ana        25 São Paulo     \n2           2 Bruno      30 Rio de Janeiro\n3           3 Carlos     35 Belo Horizonte\n4           4 Diana      40 Curitiba      \n5           5 Eduardo    50 Porto Alegre  \n\n\n\n\n\n12.2.12 Removendo linhas duplicadas com distinct()\nEm conjuntos de dados, é comum encontrar linhas duplicadas que podem distorcer análises e resultados. A função distinct() do pacote dplyr é utilizada para remover essas duplicatas, retornando apenas as linhas distintas de um data frame. Esta função é útil para garantir a integridade e a limpeza dos dados antes de prosseguir com análises mais detalhadas.\n\nlibrary(dplyr)\nlibrary(tibble)\n\n# Exemplo de dados de pacientes com duplicatas\n# os pacientes com ids 2 e 4 estão duplicados\n\npacientes <- tibble(id_paciente = c(1, 2, 2, 3, 4, 4, 5),\n                    nome = c(\"Ana\", \"Bruno\", \"Bruno\", \"Carlos\", \"Diana\", \"Diana\", \"Eduardo\"),\n                    idade = c(25, 30, 30, 35, 40, 40, 50),\n                    cidade = c(\"São Paulo\", \"Rio de Janeiro\", \"Rio de Janeiro\", \"Belo Horizonte\", \"Curitiba\", \"Curitiba\", \"Porto Alegre\"))\n\n# Remover linhas duplicadas\npacientes_distintos <- distinct(pacientes)\n\nprint(pacientes_distintos)\n\n# A tibble: 5 × 4\n  id_paciente nome    idade cidade        \n        <dbl> <chr>   <dbl> <chr>         \n1           1 Ana        25 São Paulo     \n2           2 Bruno      30 Rio de Janeiro\n3           3 Carlos     35 Belo Horizonte\n4           4 Diana      40 Curitiba      \n5           5 Eduardo    50 Porto Alegre  \n\n\nExemplo 2: Remover Duplicatas com Base em Colunas Específicas\nPodemos especificar colunas específicas para considerar ao remover duplicatas. Neste exemplo, removeremos duplicatas com base nas colunas id, mantendo apenas uma ocorrência de cada combinação. Podemos usar o argumento .keep_all = TRUE para manter todas as colunas do data frame original, mesmo ao remover duplicatas com base em colunas específicas.\n\n# Remover duplicatas com base nas colunas nome e idade\npacientes_distintos_colunas <- distinct(pacientes, id_paciente, .keep_all = TRUE)\nprint(pacientes_distintos_colunas)\n\n# A tibble: 5 × 4\n  id_paciente nome    idade cidade        \n        <dbl> <chr>   <dbl> <chr>         \n1           1 Ana        25 São Paulo     \n2           2 Bruno      30 Rio de Janeiro\n3           3 Carlos     35 Belo Horizonte\n4           4 Diana      40 Curitiba      \n5           5 Eduardo    50 Porto Alegre  \n\n\n\n\n12.2.13 Contando observações com count()\nContar observações em um conjunto de dados é uma operação fundamental em análise de dados. A função count() do pacote dplyr é uma ferramenta poderosa para contar o número de ocorrências de valores em uma ou mais colunas, proporcionando uma maneira rápida e eficiente de resumir dados categóricos.\nExemplo 1: Contar Ocorrências Simples\nVamos considerar um conjunto de dados de pacientes e contar o número de ocorrências de cada doença e do gênero dos participantes.\n\nlibrary(dplyr)\nlibrary(tibble)\n\n# Exemplo de dados de pacientes com diagnósticos e sexo\npacientes <- tibble(id_paciente = 1:20,\n                    sexo = c(\"Feminino\", \"Masculino\", \"Masculino\", \"Feminino\", \"Masculino\", \n                             \"Feminino\", \"Feminino\", \"Masculino\", \"Feminino\", \"Masculino\",\n                             \"Feminino\", \"Masculino\", \"Feminino\", \"Masculino\", \"Feminino\", \n                             \"Masculino\", \"Feminino\", \"Masculino\", \"Feminino\", \"Masculino\"),\n                    diagnostico = c(\"Depressão\", \"Bipolaridade\", \"Pneumonia\", \"AVC\", \"Depressão\", \n                                    \"Pneumonia\", \"Bipolaridade\", \"AVC\", \"Depressão\", \"Pneumonia\",\n                                    \"AVC\", \"Bipolaridade\", \"Depressão\", \"Pneumonia\", \"AVC\", \n                                    \"Bipolaridade\", \"Pneumonia\", \"Depressão\", \"Depressão\", \"Depressão\"))\n\n# Visualizar os dados\nprint(pacientes)\n\n# A tibble: 20 × 3\n   id_paciente sexo      diagnostico \n         <int> <chr>     <chr>       \n 1           1 Feminino  Depressão   \n 2           2 Masculino Bipolaridade\n 3           3 Masculino Pneumonia   \n 4           4 Feminino  AVC         \n 5           5 Masculino Depressão   \n 6           6 Feminino  Pneumonia   \n 7           7 Feminino  Bipolaridade\n 8           8 Masculino AVC         \n 9           9 Feminino  Depressão   \n10          10 Masculino Pneumonia   \n11          11 Feminino  AVC         \n12          12 Masculino Bipolaridade\n13          13 Feminino  Depressão   \n14          14 Masculino Pneumonia   \n15          15 Feminino  AVC         \n16          16 Masculino Bipolaridade\n17          17 Feminino  Pneumonia   \n18          18 Masculino Depressão   \n19          19 Feminino  Depressão   \n20          20 Masculino Depressão   \n\n\n\n# Contar o número de pacientes por genero\ncount(pacientes, sexo)\n\n# A tibble: 2 × 2\n  sexo          n\n  <chr>     <int>\n1 Feminino     10\n2 Masculino    10\n\n\n\n# Contar o número de pacientes por diagnóstico\ncount(pacientes, diagnostico)\n\n# A tibble: 4 × 2\n  diagnostico      n\n  <chr>        <int>\n1 AVC              4\n2 Bipolaridade     4\n3 Depressão        7\n4 Pneumonia        5\n\n\nPara ordenar os resultados em ordem decrescente pelo número de ocorrências, use o argumento sort = TRUE.\n\ncount(pacientes, diagnostico, sort = TRUE)\n\n# A tibble: 4 × 2\n  diagnostico      n\n  <chr>        <int>\n1 Depressão        7\n2 Pneumonia        5\n3 AVC              4\n4 Bipolaridade     4\n\n\nPodemos contar ocorrências em múltiplas colunas como sexo e diagnóstico.\n\n# Contar o número de pacientes por sexo e diagnóstico\ncount(pacientes, diagnostico, sexo)\n\n# A tibble: 8 × 3\n  diagnostico  sexo          n\n  <chr>        <chr>     <int>\n1 AVC          Feminino      3\n2 AVC          Masculino     1\n3 Bipolaridade Feminino      1\n4 Bipolaridade Masculino     3\n5 Depressão    Feminino      4\n6 Depressão    Masculino     3\n7 Pneumonia    Feminino      2\n8 Pneumonia    Masculino     3"
  },
  {
    "objectID": "11-Manipulating_data.html#sec-forcats",
    "href": "11-Manipulating_data.html#sec-forcats",
    "title": "12  Manipulando dados",
    "section": "12.3 Trabalhando com dados categóricos com forcats",
    "text": "12.3 Trabalhando com dados categóricos com forcats\nNo campo da análise de dados, especialmente na área médica, os dados categóricos desempenham um papel crucial. Seja categorizando pacientes pelo genero, agrupando tratamentos ou analisando respostas de pesquisas, gerenciar essas variáveis categóricas de maneira eficiente é essencial. O pacote forcats, parte da coleção tidyverse, oferece um conjunto de ferramentas especificamente projetadas para trabalhar com fatores no R.\nFatores são a estrutura de dados do R para dados categóricos, permitindo que você manipule e analise dados não numéricos com facilidade. Embora o R base forneça funcionalidades básicas para fatores, o forcats aprimora isso, oferecendo ferramentas mais intuitivas para a manipulação de fatores. Este pacote simplifica tarefas como reordenar níveis de fatores, gerenciar valores ausentes e converter fatores para outros tipos de dados, tornando-se uma ferramenta indispensável para analistas de dados médicos.\nNeste capítulo, você aprenderá a aproveitar as capacidades do forcats para agilizar seu fluxo de trabalho de análise de dados.\n\n12.3.1 Variáveis categóricas e factor do R\nR usa o tipo factor para lidar com variáveis categóricas, isto é, variáveis que possuem um conjunto fixo e conhecido de valores possíveis. O objetivo do pacote forcats é fornecer um conjunto de ferramentas que resolva problemas comuns com esse tipo de variável, incluindo a alteração da ordem dos níveis ou dos valores. Esse tipo de variável no R é também útil quando pretendemos apresentar os dados de forma que naão seja a ordem alfabética.\nPor exemplo, se temos um conjunto de dados com os meses do ano, a ordenação correta não é a ordem alfabética, mas sim a sequência dos meses.\n\nmeses <- c(\"Janeiro\", \"Fevereiro\", \"Março\",    \"Abril\", \n           \"Maio\",    \"Junho\",     \"Julho\",    \"Agosto\", \n           \"Setembro\", \"Outubro\",  \"Novembro\", \"Dezembro\")\n\nVeja que ao pedir ao R para ordenar os valores da variável meses, a ordenação segue em ordem alfabética, o que, nesse caso, é totalmente inconveniente.\n\nsort(meses)\n\n [1] \"Abril\"     \"Agosto\"    \"Dezembro\"  \"Fevereiro\" \"Janeiro\"   \"Julho\"    \n [7] \"Junho\"     \"Maio\"      \"Março\"     \"Novembro\"  \"Outubro\"   \"Setembro\" \n\n\nIsso pode ser corrigido transformando a variável num factor e definindo os níveis e a ordenação desses níveis da variável.\nA primeira etapa é definir os níveis:\n\nmeses <-  c(\"Janeiro\", \"Fevereiro\", \"Março\",    \"Abril\", \n            \"Maio\",    \"Junho\",     \"Julho\",    \"Agosto\", \n            \"Setembro\", \"Outubro\",  \"Novembro\", \"Dezembro\")\n\nA segunda etapa é transformar a variável original numa do tipo factor com a função factor().\n\n# carregando o pacote forcats\nlibrary(forcats)\n\nmeses2 <- factor(meses, levels = meses)\nsort(meses2)\n\n [1] Janeiro   Fevereiro Março     Abril     Maio      Junho     Julho    \n [8] Agosto    Setembro  Outubro   Novembro  Dezembro \n12 Levels: Janeiro Fevereiro Março Abril Maio Junho Julho Agosto ... Dezembro\n\n\nQuando omitimos o argumento levels, a ordenação continua sendo alfabética:\n\nmeses3 <- factor(meses)\nsort(meses3)\n\n [1] Abril     Agosto    Dezembro  Fevereiro Janeiro   Julho     Junho    \n [8] Maio      Março     Novembro  Outubro   Setembro \n12 Levels: Abril Agosto Dezembro Fevereiro Janeiro Julho Junho Maio ... Setembro\n\n\nQuando definimos os níveis de uma variável do tipo factor qualquer valor desconhecido é transformado em NA. Veja abaixo o que ocorre quando escrevemos um dos meses de forma errada (Fevereirooo):\n\nmeses_erro <-   c(\"Janeiro\", \"Fevereirooo\", \"Março\",    \"Abril\", \n                   \"Maio\",    \"Junho\",     \"Julho\",    \"Agosto\", \n                   \"Setembro\", \"Outubro\",  \"Novembro\", \"Dezembro\")\n\nmeses_erro <- factor(meses_erro, levels = meses)\nsort(meses_erro)\n\n [1] Janeiro  Março    Abril    Maio     Junho    Julho    Agosto   Setembro\n [9] Outubro  Novembro Dezembro\n12 Levels: Janeiro Fevereiro Março Abril Maio Junho Julho Agosto ... Dezembro\n\n\nO mês de Fevereiro não apareceu quando pedimos ao R para ordenar os valores, pois não havia um mes chamado “Fevereiro”. O data frame tinha um mês chamado “Fevereirooo” e portanto, o comando sort() ignorou esse mês, já que não havia entre os níveis um mês com esse nome.\nIsso pode ser problemático, pois a exclusão foi feita de forma invisível, ou seja, o R não explicitou essa exclusão. É ainda que o pacote forcats mostra sua utilidade.\n\n\n12.3.2 Manipulando variáveis categóricas com forcats\nO pacote forcats é um pacote popular do R desenvolvido por Hadley Wickham que faz parte da coleção de pacotes do tidyverse Ele é projetado para trabalhar com dados categóricos, especificamente factors Algumas vantagens do pacote forcats incluem:\nConsistência: O pacote segue os princípios do tidyverse, garantindo uma interface consistente e intuitiva para trabalhar com factors.\nSimplicidade: forcats fornece um conjunto de funções que simplificam tarefas comuns, como alterar a ordem dos níveis de fatores, reduzir níveis ou reordenar níveis com base em sua frequência ou outros atributos.\nRecodificação e renomeação: funções como fct_recode() e fct_relevel() simplificam a recodificação ou renomeação de níveis de factors, o que pode ser particularmente útil ao limpar e pré-processar dados.\nControle: o forcats facilita o controle explícito da ordem dos níveis das variáveis categóricas ou a definição de níveis específicos como referências nas análises, o que pode ser importante ao trabalhar com variáveis categóricas ordinais.\nVisualização: ao usar o ggplot2, outro pacote do tidyverse, as funções forcats podem ser usadas para personalizar a ordem das categorias exibidas, o que pode levar a gráficos mais informativos e esteticamente agradáveis.\nCompatibilidade: como parte da ordenação, o forcats funciona perfeitamente com outros pacotes de ordenação como dplyr, aligner e ggplot2, tornando-o uma excelente opção para gerenciar e visualizar dados categóricos em um fluxo de trabalho de dados organizado.\nDocumentação: O pacote forcats vem com documentação abrangente e possui forte suporte da comunidade, tornando mais fácil para os usuários encontrar soluções para suas dúvidas e problemas.\nAo oferecer essas vantagens, o pacote forcats torna o trabalho com dados categóricos em R mais eficiente e fácil de usar.\n\n12.3.2.1 Reordenando variáveis categóricas\nGeralmente é útil alterar a ordem dos níveis de fator em uma visualização. Nos exemplos seguintes não se preocupe com os códigos para gerar os gráficos. Em capítulos adiante iremos discutir como criar gráficos com o ggplot2. No momento o que interessa é observar que podemos indicar ao R como deverá ser interpretada a ordenação da variável categórica.\nA técnica ideal é definir essa ordenação antes de gerar o gráfico, como será mostrado nos códigos adiante.\nVejamos esse exemplo de uma tibble com os preços de frutas e legumes.\n\nlibrary(tibble)\n\n# Criando uma tibble fictícia\ndata <- tibble(produto = factor(c(\"abacaxi\", \"goiaba\", \"limão\", \"uva T\", \"kiwi\", \"vagem\", \"jilo\")),\n               preco = c(3.0, 3.5, 1.5, 11.0, 8.39, 4.55, 2.0))\n\nPlotar esses dados sem nenhum ajuste resultaria num gráfico ordenado de forma alfabética.\n\nlibrary(ggplot2)\n\nggplot(data) +\n  geom_bar(aes(x=produto, y=preco), \n           stat = \"identity\", \n           fill=\"lightgreen\", \n           col=\"darkgreen\") +\n  theme_minimal()\n\n\n\n\nPorém, frequentemente é interessante ordenar de acordo com algum padrão que não alfabético, por exemplo, de acordo com o preço. Para isso podemos usar a função fct_reorder() como abaixo. Veja como o mesmo gráfico agora será ordenado segundo o preço.\n\n# carregando o pacote dplyr para usar mutate\nlibrary(dplyr)\n\n# Ordenar a variável produto de acordo com uma outra variável: preco\ndata <- data %>%\n  mutate(produto = fct_reorder(produto, preco))\n\n# plotando novamente o gráfico\nggplot(data) +\n  geom_bar(aes(x=produto, y=preco), \n           stat = \"identity\", \n           fill=\"lightgreen\", \n           col=\"darkgreen\") +\n  theme_minimal()\n\n\n\n\n\n\n\n12.3.3 Agrupando categorias\nAs vezes desejamos colpasar algumas categorias mais específicas para outras mais genéricas. Por exemplo, podemos criar grupos de legumes e frutas a partir dos dados da tible anterior.\nO código a seguir reune cria uma variável tipo, com dois grupos (fruta e legume). Para isso reúne sob o rótulo fruta os produtos “abacaxi”, “goiaba”, “limão”, “uva T” e “kiwi”; e sob o rótulo legume os produtos “vagem” e “jilo”.\n\ndata <- data %>%\n  mutate(tipo = fct_collapse(produto,\n                             \"fruta\" = c(\"abacaxi\", \"goiaba\", \"limão\", \"uva T\", \"kiwi\"),\n                             \"legume\" = c(\"vagem\", \"jilo\")))\n\ndata\n\n# A tibble: 7 × 3\n  produto preco tipo  \n  <fct>   <dbl> <fct> \n1 abacaxi  3    fruta \n2 goiaba   3.5  fruta \n3 limão    1.5  fruta \n4 uva T   11    fruta \n5 kiwi     8.39 fruta \n6 vagem    4.55 legume\n7 jilo     2    legume\n\n\n\n\n12.3.4 Recodificando variáveis categóricas\nPodemos recodificar os níveis da variáveis categórica produto usando fct_recode().\nVamos recodificar:\nuva T para Uva Thompson\nlimão para Limão Thaiti\ngoiaba para Goiaba\nabacaxi para Abacaxi\nkiwi para Kiwi\nvagem para Vagem\njilo para Jiló\nVeja que o novo nome vem na frente do nome antigo dentro do código:\n\n# Recode factor levels\ndata <- data %>%\n  mutate(produto = fct_recode(produto,\n                            \"Uva Thompson\" = \"uva T\",\n                            \"Limão Thaiti\" = \"limão\",\n                            \"Goiaba\"       = \"goiaba\",\n                            \"Abacaxi\"      = \"abacaxi\",\n                            \"Kiwi\"         = \"kiwi\",\n                            \"Vagem\"        = \"vagem\", \n                            \"Jiló\"         = \"jilo\"))\n\n\ndata\n\n# A tibble: 7 × 3\n  produto      preco tipo  \n  <fct>        <dbl> <fct> \n1 Abacaxi       3    fruta \n2 Goiaba        3.5  fruta \n3 Limão Thaiti  1.5  fruta \n4 Uva Thompson 11    fruta \n5 Kiwi          8.39 fruta \n6 Vagem         4.55 legume\n7 Jiló          2    legume\n\n\n\n\n12.3.5 Ordenando de acordo com a frequencia dos elementos\nO pacote forcats tem também uma função que ordena os elementos de acordo com a frequencia deles. Vejamos a aplicação dessa função num data frame que contém as variáveis sexo, idade.\n\nlibrary(tibble)\n\n# criando um data frame com dados de idade e sexo\n# Definir parâmetros da distribuição normal\nmedia_idade   <- 40\ndesvio_padrao <- 10\nn_pessoas     <- 100\n\n# Definir sementes aleatórias para garantir a reprodutibilidade\nset.seed(20)\n\n# Criar uma tibble com o nome df_sexo\ndf_sexo <- tibble(id = 1:n_pessoas,\n                  sexo = sample(c(\"Masculino\", \"Feminino\", \"Outro\", \"Não definido\"), n_pessoas, replace = TRUE),\n                  idade = round(rnorm(n_pessoas, mean = media_idade, sd = desvio_padrao), 0))\n\nprint(df_sexo)\n\n# A tibble: 100 × 3\n      id sexo         idade\n   <int> <chr>        <dbl>\n 1     1 Feminino        51\n 2     2 Outro           40\n 3     3 Outro           42\n 4     4 Não definido    53\n 5     5 Feminino        47\n 6     6 Masculino       41\n 7     7 Feminino        53\n 8     8 Masculino       36\n 9     9 Feminino        32\n10    10 Feminino        44\n# ℹ 90 more rows\n\n\nVeja que a frequencia continua sendo por ordem alfabética.\n\n# plotando um gráfico de barras das frequencias de cada sexo\nggplot(df_sexo) +\n  geom_bar(aes(x=sexo, fill=sexo)) +\n  theme_minimal()\n\n\n\n\nPodemos fazer com que as barras sejam plotadas de acordo com a frequencia, o que faz o gráfico ficar esteticamente mais interessante. Para isso usaremos a função fct_infreq() para indicar que essa variável categórica deverá ser tratada de acordo com a frequencia dos dados.\n\n# indicando que a variável sexo deverá ser ordenada de acordo com a frequencia (decrescente)\ndf_sexo <- df_sexo %>%\n  mutate(sexo = fct_infreq(sexo))\n\n\n# plotando um gráfico de barras das frequencias de cada sexo\nggplot(df_sexo) +\n  geom_bar(aes(x=sexo, fill=sexo)) +\n  theme_minimal()\n\n\n\n\nCaso o interesse seja plotar na ordem inversa, podemos fazer isso com a função fct_rev aplicada juntamente com a função fct_infreq como mostra o código abaixo.\n\n# indicando que a variável sexo deverá ser ordenada de acordo com a frequencia, na ordem crescente\ndf_sexo <- df_sexo %>%\n  mutate(sexo = fct_rev(fct_infreq(sexo)))\n\n\n# plotando um gráfico de barras das frequencias de cada sexo\nggplot(df_sexo) +\n  geom_bar(aes(x=sexo, fill=sexo)) +\n  theme_minimal()\n\n\n\n\n\n\n12.3.6 Categorizando variáveis numéricas com a função cut( )\nA função cut() nos permite criar uma variável categórica a partir de uma variável numérica. Isso é útil em diversas situações como por exemplo criar grupos de crianças, adultos e idosos a partir de uma variável numérica; ou categorizar escores númericos em escalas em níveis de leve, moderado e grave. A função cut() discretiza esses dados e nos permite criar também os rótulos (nomes) para essas categorias.\nA forma usual dessa função é:\n  cut(variável, \n      breaks=c(-Inf, x1, x2, Inf),\n      labels=c(\"label\", \"label\", \"label\"))\nVeja que o parâmetro breaks pode usar -Inf como limite inferior e Inf como limite superior, significando limite infinito negativo e limite infinito positivo. Entretanto, geralmente conhecemos nosso dataset e o ideal é usar os limites máximo e mínino conhecidos.\nEntre esses limites extremos serão definidos os pontos de corte. Veja também que com 4 pontos serão criados 3 categorias. Por padrão os intervalos são do abertos à esquerda e fechados à direita, tal como em (x1, x2]. De tal forma que o intervalo termina no valores indicados, incluindo esse valor.\nOutra funcionalidade bastante útil da função cut() é a possibilidade de criação de rótulos próprios, labels para nomear as categorias criadas. É importante aqui que o número de labels seja exatamente igual ao número de categorias criadas. Com 4 pontos no argumento breaks como no exemplo acima serão criados 3 categorias.\nPara exemplificar o uso da função cut vamos usar o dataset mpg e criar uma variável categórica cty_cat a partir cty (milhas percorridas na estrada com 1 galão de combustível). A variável cty é numérica, com valores variando de 9 milhas a 35 milhas. Vamos definir 3 categorias de carros:\nComo o limite superior do intervalo é aberto, o valor desse ponto de corte será parte da 1º categoria, portanto, o primeiro ponto de corte deve ser 15, já que definimos o primeiro intervalo como menor ou igual a 15. O segundo ponto de corte será 20, pois será o limite superior da segunda categoria é menor ou igual a 20. O código ficará então assim:\n\nlibrary(ggplot2)\ndata(mpg)\nmpg$cty_cat <- cut(mpg$cty,               \n                   breaks=c(0, 15, 20, 35),                  \n                   labels=c(\"Beberrão\",\"Moderado\", \"Econômico\"))\ntable(mpg$cty_cat)\n\n\n Beberrão  Moderado Econômico \n       97        92        45 \n\n\nAgora o data frame mpg contém uma nova variável categórica denominada cty_cat com 3 níveis, o que podemos verificar com a função class() e unique().\n\nclass(mpg$cty_cat)\n\n[1] \"factor\"\n\n\n\nunique(mpg$cty_cat)\n\n[1] Moderado  Econômico Beberrão \nLevels: Beberrão Moderado Econômico\n\n\nEntretanto, ainda falta um pequeno detalhe. A variável criada deveria ser ordenada, mas foi criada como sendo uma variável nominal. Por padrão o R cria uma variável categórica nominal com a função cut(). Para indicar que desejamos que a nova variável seja ordenada devemos incluir o parâmetro ordered_result como sendo TRUE (ordered_result = TRUE).\n\nmpg$cty_cat <- cut(mpg$cty,\n                   \n                   breaks=c(0, 15, 20, 35),                               \n                   labels=c(\"Beberrão\",\"Moderado\", \"Econômico\"),\n                   ordered_result = TRUE)\n\nVamos verificar agora que a variável cty_cat( ) é ordenada e qual a ordenação.\n\nclass(mpg$cty_cat)\n\n[1] \"ordered\" \"factor\" \n\n\n\nunique(mpg$cty_cat)\n\n[1] Moderado  Econômico Beberrão \nLevels: Beberrão < Moderado < Econômico"
  },
  {
    "objectID": "11-Manipulating_data.html#tabulando-dados-categóricos",
    "href": "11-Manipulating_data.html#tabulando-dados-categóricos",
    "title": "12  Manipulando dados",
    "section": "12.4 Tabulando dados categóricos",
    "text": "12.4 Tabulando dados categóricos\nOs dados categóricos desempenham um papel fundamental em pesquisas na área da saúde, sendo essenciais para a compreensão de padrões, tendências e relações dentro dos dados coletados. Dados categóricos são aqueles que podem ser classificados em diferentes categorias ou grupos, como sexo, tipo de doença, grupo sanguíneo, entre outros. Ao contrário dos dados numéricos, que representam quantidades e podem ser submetidos a operações matemáticas diretas, os dados categóricos representam qualidades e são analisados de maneiras distintas.\nA importância dos dados categóricos em estudos de saúde é evidente em diversas situações. Por exemplo, em estudos epidemiológicos, a categorização dos indivíduos por faixa etária, sexo e fatores de risco é crucial para entender a distribuição e os determinantes das doenças. Da mesma forma, em ensaios clínicos, a resposta dos pacientes a diferentes tratamentos pode ser categorizada como “melhora”, “piora” ou “nenhuma mudança”, proporcionando insights valiosos sobre a eficácia dos tratamentos.\nOutro exemplo relevante é a categorização de doenças. As classificações internacionais, como a Classificação Internacional de Doenças (CID), utilizam categorias para agrupar doenças e condições de saúde, facilitando a coleta, análise e comparação de dados em nível global. Isso permite identificar tendências em saúde pública, avaliar a carga de doenças e desenvolver estratégias de prevenção e controle mais eficazes.\nAlém disso, dados categóricos são frequentemente utilizados para estudar a relação entre variáveis. Por exemplo, pode-se investigar a associação entre o tipo de dieta (vegetariana, vegana, onívora) e a incidência de doenças cardiovasculares, ou entre hábitos de vida (não-fumante, ex-fumante, fumante) e o risco de desenvolver câncer.\nUma das principais tarefas ao análisar dados categóricos é sua tabulação, ou seja, a contagem da quantidade ou do percentual em cada grupo e a criação de tabelas de frequencias. Veremos também que frequentemente precisamos recodificar o nome de variáveis, agrupar categorias em níveis mais amplos.\n\n12.4.1 Preparando as variáveis categóricas para tabulação.\nAs funções table() e prop.table() do R possibilitam a criação de tabelas de frequencias de dados categóricos com grande praticidade. Veremos também como usar as funções count() do tidyverse para criar essas tabelas.\nLembre-se que é sempre indicado verificarmos como o R está interpretando as variáveis, para nos certificamos que as variáveis a serem analisadas estão realmente no formato factor, formato para variáveis categóricas do R. Além disso, também é bom indicarmos se há alguma ordenação ou não nessas variáveis antes de qualquer análise.\nQuando lidamos com variáveis categóricas, usar números para identificar os tipos deixa as tabelas muito confusas. Por exemplo, no caso do dataset mtcars precisamos lembrar que “0” significa motores em V e “1” significa motores alinhados. Seria melhor renomear essas variáveis categóricas antes de criar as tabelas, como fizemos na seção sobre o pacote forcats (Section 12.3.4).\nVamos usar como exemplo ainda o dataset mtcars. Inicialmente usaremos a função str() para verificar a estrutura desse arquivo e verificar como o R está interpretando os tipos de cada variável. O comando “?mtcars” digitado no console mostrará no painel help as informações sobre esse dataset.\n\ndata(mtcars)\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\nVeja que o R interpreta diversas variáveis categóricas desse dataset como sendo numéricas.\nA variável am é na verdade categórica, e indica se o carro tem marcha automática (“0”) ou manual (“1”). A variável vs é também categórica, e indica o tipo de motor. O valor “0” indica motor V-Shaped e valor “1” indica motor linear. A variável cyl, apesar de também trazer números, é na também categórica, e indica o número de cilindros do carro, podendo ser 4, 6 ou 8 cilindros.\nA primeira etapa será então transformar essas variáveis em categóricas com as.factor() e a segunda etapa será renomear essas variáveis com rótulos mais descritivos, usando fct_recode()do pacote forcats, para facilitar a interpretação dos dados. No caso da variável cyl, que indica as cilindradas do carro, será útil também indicar a ordenação dessa variável.\n\nlibrary(forcats) # necessário para usar a função fct_recode\n# Transformando a variável 'am' em categórica\nmtcars$am <- as.factor(mtcars$am)\n# Recodificando os rótulos de am\nmtcars$am <- fct_recode(mtcars$am, \"Automático\" = \"0\", \"Manual\" = \"1\")\n\n# Transformando a variável 'vs' em categórica\nmtcars$vs <- as.factor(mtcars$vs)\n# Recodificando os rótulos de  vs\nmtcars$vs <- fct_recode(mtcars$vs, \"Motor em V\" = \"0\", \"Motor em linha\" = \"1\")\n\n# Transformando a variável 'cyl' em categórica\nmtcars$cyl <- as.factor(mtcars$cyl)\n# Recodificando os rótulos de  cyl\nmtcars$cyl <- fct_recode(mtcars$cyl, \"4 Cilindros\" = \"4\", \"6 Cilindros\" = \"6\", \"8 Cilindros\" = \"8\")\n# Indicando a ordenação dos calores dessa variável\nmtcars$cyl <- fct_relevel(mtcars$cyl, \"4 Cilindros\", \"6 Cilindros\", \"8 Cilindros\")\n\nVeja agora essas variáveis estão sendo corretamente interpretadas.\n\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : Factor w/ 3 levels \"4 Cilindros\",..: 2 2 1 2 3 2 3 1 1 2 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : Factor w/ 2 levels \"Motor em V\",\"Motor em linha\": 1 1 2 2 1 2 1 2 2 2 ...\n $ am  : Factor w/ 2 levels \"Automático\",\"Manual\": 2 2 2 1 1 1 1 1 1 1 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\nAgora que já temos nossas variáveis categóricas interpretadas corretamente no R podemos criar nossas tabelas de frequencias.\n\n\n12.4.2 Tabulando variáveis categóricas\n\n12.4.2.1 A função table() do R base\nA função table() do R é utilizada para criar tabelas de contingência a partir de vetores ou fatores. Ela conta as frequências de ocorrência de cada valor único nas variáveis fornecidas, sendo muito útil para resumir e analisar dados categóricos.\n\ntable(mtcars$cyl)\n\n\n4 Cilindros 6 Cilindros 8 Cilindros \n         11           7          14 \n\n\nPodemos também usar o pipe juntamente com a função table(), mas nesse caso, precisamos selecionar as colunas desejadas usando select() antes da função table()\n\nlibrary(dplyr) # necessário para usar as função select()\n\nmtcars  |>   \n  select(cyl) |> \n  table()\n\ncyl\n4 Cilindros 6 Cilindros 8 Cilindros \n         11           7          14 \n\n\nPodemos criar tabelas 2x2 com a função table, bastando para isso selecinar as duas colunas/variáveis desejadas. O código abaixo constroi uma tabela 2x2 com as variáveis cilindradas (cyl) e alinhamento do motor (vs)\n\nlibrary(dplyr) # necessário para usar as função select()\n\nmtcars  |>   \n  select(cyl, vs) |> \n  table()\n\n             vs\ncyl           Motor em V Motor em linha\n  4 Cilindros          1             10\n  6 Cilindros          3              4\n  8 Cilindros         14              0\n\n\n\n12.4.2.1.1 Calculando percentuais com prop.table()\nA função prop.table() calcula percentuais em tabelas. Importante entender que o argumento da função prop.table() é uma tabela criada com a função table(). Ou seja, precisamos primeiro criar a tabela com table() para depois aplicarmos a função prop.table(). Para tornar o código mais fácil de ser lido, é conveniente usar o operador pipe.\n\n# calculando o percentual de carros com motor em V e motores em linha reta\n# nesse exemplo não foi usado o operador pipe.\nprop.table(table(mtcars$vs))\n\n\n    Motor em V Motor em linha \n        0.5625         0.4375 \n\n\nEsse código pode ser escrito de forma mais elegante usando o operador pipe\n\n# calculando o percentual de carros com motor em V e motores em linha reta\n# nesse exemplo usamos o operador pipe.\nmtcars$vs |> \n  table() |> \n  prop.table()\n\n\n    Motor em V Motor em linha \n        0.5625         0.4375 \n\n\nObserve que o código com o pipe fica bem mais elegante, e facilita as próximas etapas. Podemos agora facilmente agregar outras funções, por exemplo, arredondar as casas decimais para apenas duas casas, adicionar uma coluna com o total, multiplicar por 100 para tornar o número um percentual, etc:\n\n# calculando o percentual de carros com motor em V e motores em linha reta\n# nesse exemplo usamos o operador pipe.\nmtcars |>      # iniciando o pipe com a variável dataset mtcars2 (criando anteriormente)\n  select(vs) |> \n  table() |>       # criando a tabela com os valores absolutos\n  prop.table() |>  # calculando os percentuais\n  (`*`)(100) |>    # multiplicando os valores por 100\n  addmargins()     # adicionando uma coluna com o total.\n\nvs\n    Motor em V Motor em linha            Sum \n         56.25          43.75         100.00 \n\n\nPodemos também criar tabelas com mais de uma variável, por exemplo, acrescentando aqui a variável am, que indica o tipo de marcha usado (autmática ou manual).\n\nmtcars |>          # iniciando o pipe o dataset mtcars2 (criando anteriormente)\n  select(vs, am) |> # selecionando as duas variáveis, vs e am\n  table() |>        # criando a tabela com os valores absolutos\n  addmargins()      # adicionando uma coluna com o total.\n\n                am\nvs               Automático Manual Sum\n  Motor em V             12      6  18\n  Motor em linha          7      7  14\n  Sum                    19     13  32\n\n\nEm tabelas com mais de uma variável é preciso ter cuidado com a função prop.table(). Essa função vai calcular os percentuais em cada célula usando o total de elementos. Nessa tabela acima podemos ver que temos 32 carros. Então os percentuais serão calculados com base em 32, como mostrado abaixo:\n\nmtcars |>          # iniciando o pipe o dataset mtcars2 (criando anteriormente)\n  select(vs, am) |> # selecionando as duas variáveis, vs e am\n  table() |>        # criando a tabela com os valores absolutos\n  prop.table() |> \n  (`*`)(100) |>     # multiplicando os valores por 100\n  addmargins()      # adicionando uma coluna com o total.\n\n                am\nvs               Automático  Manual     Sum\n  Motor em V         37.500  18.750  56.250\n  Motor em linha     21.875  21.875  43.750\n  Sum                59.375  40.625 100.000\n\n\nMuitas vezes é intessante calcular os percentuais nas linhas ou nas colunas e não no total. Para isso é necessário adicionar o argumento “1” ou “2” na função prop.table().\n1 - calcula as proporções nas linhas 2 - calcula as proporções nas colunas\n\nmtcars |>          # iniciando o pipe o dataset mtcars2 (criando anteriormente)\n  select(vs, am) |> # selecionando as duas variáveis, vs e am\n  table() |>        # criando a tabela com os valores absolutos\n  prop.table(1) |>  # calculando as proporções nas linhas\n  (`*`)(100) |>     # multiplicando os valores por 100\n  addmargins() |>   # adicionando uma coluna com o total.\n  round(1)          # arredonda os valores para 1 casa decimal\n\n                am\nvs               Automático Manual   Sum\n  Motor em V           66.7   33.3 100.0\n  Motor em linha       50.0   50.0 100.0\n  Sum                 116.7   83.3 200.0\n\n\n\nmtcars |>          # iniciando o pipe o dataset mtcars2 (criando anteriormente)\n  select(vs, am) |> # selecionando as duas variáveis, vs e am\n  table() |>        # criando a tabela com os valores absolutos\n  prop.table(2) |>  # calculando as proporções nas colunas\n  (`*`)(100) |>     # multiplicando os valores por 100\n  addmargins() |>   # adicionando uma coluna com o total.\n  round(1)          # arredonda os valores para 1 casa decimal\n\n                am\nvs               Automático Manual   Sum\n  Motor em V           63.2   46.2 109.3\n  Motor em linha       36.8   53.8  90.7\n  Sum                 100.0  100.0 200.0\n\n\n\n\n12.4.2.1.2 Lidando com NAs na função table()\nFrequentemente existem dados faltantes em datasets. Esses dados são usualmente denotados no R pela sigla NA que indica Not Available (não disponível).\nA função table(), por padrão, não inclui os dados faltantes na tabela gerada. Entretanto, muitas vezes é importante poder ter esses dados incluídos na tabela. Para isso é necessário ajustar um parâmetro da função table, inserindo exclude=false na função como mostremos a seguir.\nPara exemplificar isso vamos primeiro inserir alguns NAs no dataset mtcars. O código abaixo faz com que todos os carros com 8 cilindros, na variável cyl sejam trocados por NA.\n\nmtcars$cyl[mtcars$cyl==\"8 Cilindros\"] <- NA\nmtcars\n\n                     mpg         cyl  disp  hp drat    wt  qsec             vs\nMazda RX4           21.0 6 Cilindros 160.0 110 3.90 2.620 16.46     Motor em V\nMazda RX4 Wag       21.0 6 Cilindros 160.0 110 3.90 2.875 17.02     Motor em V\nDatsun 710          22.8 4 Cilindros 108.0  93 3.85 2.320 18.61 Motor em linha\nHornet 4 Drive      21.4 6 Cilindros 258.0 110 3.08 3.215 19.44 Motor em linha\nHornet Sportabout   18.7        <NA> 360.0 175 3.15 3.440 17.02     Motor em V\nValiant             18.1 6 Cilindros 225.0 105 2.76 3.460 20.22 Motor em linha\nDuster 360          14.3        <NA> 360.0 245 3.21 3.570 15.84     Motor em V\nMerc 240D           24.4 4 Cilindros 146.7  62 3.69 3.190 20.00 Motor em linha\nMerc 230            22.8 4 Cilindros 140.8  95 3.92 3.150 22.90 Motor em linha\nMerc 280            19.2 6 Cilindros 167.6 123 3.92 3.440 18.30 Motor em linha\nMerc 280C           17.8 6 Cilindros 167.6 123 3.92 3.440 18.90 Motor em linha\nMerc 450SE          16.4        <NA> 275.8 180 3.07 4.070 17.40     Motor em V\nMerc 450SL          17.3        <NA> 275.8 180 3.07 3.730 17.60     Motor em V\nMerc 450SLC         15.2        <NA> 275.8 180 3.07 3.780 18.00     Motor em V\nCadillac Fleetwood  10.4        <NA> 472.0 205 2.93 5.250 17.98     Motor em V\nLincoln Continental 10.4        <NA> 460.0 215 3.00 5.424 17.82     Motor em V\nChrysler Imperial   14.7        <NA> 440.0 230 3.23 5.345 17.42     Motor em V\nFiat 128            32.4 4 Cilindros  78.7  66 4.08 2.200 19.47 Motor em linha\nHonda Civic         30.4 4 Cilindros  75.7  52 4.93 1.615 18.52 Motor em linha\nToyota Corolla      33.9 4 Cilindros  71.1  65 4.22 1.835 19.90 Motor em linha\nToyota Corona       21.5 4 Cilindros 120.1  97 3.70 2.465 20.01 Motor em linha\nDodge Challenger    15.5        <NA> 318.0 150 2.76 3.520 16.87     Motor em V\nAMC Javelin         15.2        <NA> 304.0 150 3.15 3.435 17.30     Motor em V\nCamaro Z28          13.3        <NA> 350.0 245 3.73 3.840 15.41     Motor em V\nPontiac Firebird    19.2        <NA> 400.0 175 3.08 3.845 17.05     Motor em V\nFiat X1-9           27.3 4 Cilindros  79.0  66 4.08 1.935 18.90 Motor em linha\nPorsche 914-2       26.0 4 Cilindros 120.3  91 4.43 2.140 16.70     Motor em V\nLotus Europa        30.4 4 Cilindros  95.1 113 3.77 1.513 16.90 Motor em linha\nFord Pantera L      15.8        <NA> 351.0 264 4.22 3.170 14.50     Motor em V\nFerrari Dino        19.7 6 Cilindros 145.0 175 3.62 2.770 15.50     Motor em V\nMaserati Bora       15.0        <NA> 301.0 335 3.54 3.570 14.60     Motor em V\nVolvo 142E          21.4 4 Cilindros 121.0 109 4.11 2.780 18.60 Motor em linha\n                            am gear carb\nMazda RX4               Manual    4    4\nMazda RX4 Wag           Manual    4    4\nDatsun 710              Manual    4    1\nHornet 4 Drive      Automático    3    1\nHornet Sportabout   Automático    3    2\nValiant             Automático    3    1\nDuster 360          Automático    3    4\nMerc 240D           Automático    4    2\nMerc 230            Automático    4    2\nMerc 280            Automático    4    4\nMerc 280C           Automático    4    4\nMerc 450SE          Automático    3    3\nMerc 450SL          Automático    3    3\nMerc 450SLC         Automático    3    3\nCadillac Fleetwood  Automático    3    4\nLincoln Continental Automático    3    4\nChrysler Imperial   Automático    3    4\nFiat 128                Manual    4    1\nHonda Civic             Manual    4    2\nToyota Corolla          Manual    4    1\nToyota Corona       Automático    3    1\nDodge Challenger    Automático    3    2\nAMC Javelin         Automático    3    2\nCamaro Z28          Automático    3    4\nPontiac Firebird    Automático    3    2\nFiat X1-9               Manual    4    1\nPorsche 914-2           Manual    5    2\nLotus Europa            Manual    5    2\nFord Pantera L          Manual    5    4\nFerrari Dino            Manual    5    6\nMaserati Bora           Manual    5    8\nVolvo 142E              Manual    4    2\n\n\nA função table() usual não iria inclui nenhum valor NA e, portanto, podemos ter a falsa impressão que não há dados faltantes.\n\ntable(mtcars$cyl)\n\n\n4 Cilindros 6 Cilindros 8 Cilindros \n         11           7           0 \n\n\nEntretanto, podemos mudar esse comportamento da função table() inserindo o parâmetro exclude = FALSE como a seguir, que mostra haver 14 NAs nessa variável.\n\ntable(mtcars$cyl, exclude = FALSE)\n\n\n4 Cilindros 6 Cilindros 8 Cilindros        <NA> \n         11           7           0          14 \n\n\nPara voltar a usar o dataset mtcars com os dados completos, basta carregar novamente esse dataset.\n\ndata(mtcars)\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\n\n\n12.4.2.2 Cruzando dados com a função xtabs( )\nA função xtabs() serve para criarmos tabelas de cruzamento de dados usando o operador de fórmulas ~ já discutido no capítulo de operadores (Chapter 8). Para demonstrar o uso dessa função vamos usar os dados do dataset mpg do pacote ggplot2.\nA variável drv contém dados acerca do tipo de tração dos carros (f=frontal, r=traseira, 4=4x4) e a variável class contém dados acerca do tipo de carro (compact, midsize, suv, 2seater, minivan, pickup, subcompact).\nA expressão a ser usada como argumento nessa função tem a forma a seguir xtabs(~ variável + variável, dataset)\nVamos criar uma tabela com o tipo de tração drv nas linhas e o tipo de carro class nas colunas, usando a função xtabs().\n\nlibrary(ggplot2)\nxtabs( ~ drv + class, mpg)\n\n   class\ndrv 2seater compact midsize minivan pickup subcompact suv\n  4       0      12       3       0     33          4  51\n  f       0      35      38      11      0         22   0\n  r       5       0       0       0      0          9  11\n\n\n\n\n12.4.2.3 Tabulando dados com count()\nA função count() do pacote dplyr é uma ferramenta poderosa para contar observações em um dataframe, especialmente quando se trabalha com dados em formato de tabela. Ela oferece uma sintaxe simples e intuitiva, permitindo facilmente agregar e contar dados categóricos.\nVamos explorar o uso de count() com o exemplo do dataset mtcars e discutir as diferenças e vantagens em relação à função table() do R base.\nVantagens do count()\nClareza e Consistência: A função count() é mais intuitiva e consistente com outras funções do dplyr, proporcionando uma curva de aprendizado mais suave para os usuários do tidyverse. Tem sintaxe mais legível e intuitiva, especialmente para quem já está familiarizado com o estilo de manipulação de dados do dplyr.\nIntegração com o tidyverse: Permite encadear operações de forma clara e eficiente, melhorando a legibilidade e a manutenção do código.\nFlexibilidade: Facilita operações adicionais como agrupamentos complexos e filtros dentro da mesma cadeia de operações. Integra-se perfeitamente com outras funções do dplyr, permitindo operações adicionais como filtragem, agrupamento e mutação de dados em uma sequência fluida de comandos.\nResultado: A função count() retorna um tibble, que é um tipo de dataframe moderno e mais amigável para manipulação subsequente dentro do universo tidyverse. Por outro lado, a função table() retorna um objeto de classe table, que pode exigir conversão adicional para se integrar com outras funções de manipulação de dados.\nEm resumo, a função count() do dplyr oferece uma abordagem moderna e integrada para contar dados categóricos em dataframes, proporcionando vantagens significativas em termos de sintaxe, flexibilidade e integração com outras funções do tidyverse. Embora table() do R base seja útil e eficiente para contagens rápidas, count() é preferível em contextos onde a manipulação e análise de dados complexos são necessárias.\n\n12.4.2.3.1 Tabulando uma variável com count()\nA função count() pode ser utilizada para contar as ocorrências de cada valor único de uma variável. Vamos contar o número de carros para cada número de cilindros (cyl).\n\nlibrary(dplyr) # necessário para usar a função count\ndata(\"mtcars\")\nmtcars |> \n  count(cyl)\n\n  cyl  n\n1   4 11\n2   6  7\n3   8 14\n\n\nPodemos acrescentar o argumento sort=TRUE para mostrar os grupos com mais elementos no topo.\n\nlibrary(dplyr) # necessário para usar a função count\ndata(\"mtcars\")\nmtcars |> \n  count(cyl, sort = TRUE)\n\n  cyl  n\n1   8 14\n2   4 11\n3   6  7\n\n\n\n\n12.4.2.3.2 Tabulando duas variáveis com count()\nCom a função count() podemos contar o número ocorrências de uma variável categórica, agrupadas segundo uma outra variável categórica. Por exemplo, podemos contar o número de de carros agrupados por número de cilindros (cyl) de acordo com o tipo de marcha (am) - automática ou manual.\n\nlibrary(dplyr) # necessário para usar a função count\nmtcars |>\n  count(cyl, am)\n\n  cyl am  n\n1   4  0  3\n2   4  1  8\n3   6  0  4\n4   6  1  3\n5   8  0 12\n6   8  1  2\n\n\n\n\n\n12.4.2.4 Calculando Proporções com count()\nPodemos calcular as proporções de cada categoria em relação ao total usando a função count() associada com a função mutate(). Vamos contar o número de carros para cada número de cilindros e, em seguida, calcular a proporção de cada contagem em relação ao total.\n\nlibrary(dplyr) # necessário para usar a função count\nmtcars |>\n  count(cyl) |>\n  mutate(proportion = n / sum(n))\n\n  cyl  n proportion\n1   4 11    0.34375\n2   6  7    0.21875\n3   8 14    0.43750\n\n\nPodemos facilmente transformar esses valores em percentuais ajustando o código anterior para multiplicar por 100.\n\nlibrary(dplyr) # necessário para usar a função count\nmtcars |>\n  count(cyl) |>\n  mutate(proportion = (n / sum(n))*100)\n\n  cyl  n proportion\n1   4 11     34.375\n2   6  7     21.875\n3   8 14     43.750\n\n\n\n12.4.2.4.1 Renomeando as colunas de count()\nPodemos facilmente contar o número de carros para cada número de cilindros e renomear as colunas de saída.\n\nlibrary(dplyr) # necessário para usar a função count\nmtcars |>\n  count(cyl, name = \"numero de carros\")\n\n  cyl numero de carros\n1   4               11\n2   6                7\n3   8               14\n\n\n\n\n\n12.4.2.5 Contando depois de filtrar dados\nPodemos combinar a função count() com a função filter() para contar o número de ocorrências de uma variável categórica após filtrar os dados. Vamos contar o número de carros para cada número de marchas (gear), mas somente para os carros com um peso (wt) menor que 4.0 (4.000 libras). Em seguida, ordenar o resultado por número de marchas\n\nlibrary(dplyr) # necessário para usar a função filter e count\nmtcars |>\n  filter(wt < 4.0) |>\n  count(gear) |>\n  arrange(gear)\n\n  gear  n\n1    3 11\n2    4 12\n3    5  5\n\n\nOs exemplos acima ilustram como a função count() do dplyr pode ser utilizada em situações mais complexas, combinando-a com outras funções para realizar filtragens, agrupamentos, transformações e ordenações. Isso demonstra a flexibilidade e poder do dplyr para manipulação de dados em R, tornando a análise mais eficiente e o código mais legível."
  },
  {
    "objectID": "11-Manipulating_data.html#trabalhando-com-dados-numéricos",
    "href": "11-Manipulating_data.html#trabalhando-com-dados-numéricos",
    "title": "12  Manipulando dados",
    "section": "12.5 Trabalhando com Dados Numéricos",
    "text": "12.5 Trabalhando com Dados Numéricos\n\n12.5.1 Estatística Descritiva para dados numéricos\nVamos examinar as principais funções do R para descrever numéricamente um conjunto de dados: as medidas de centralidade (media, mediana), de partição (percentis) e de dispersão (amplitude, variância e desvio padrão). Veremos como aplicar essas funções em vetores e em data frames ou tibbles.\n\n12.5.1.1 Medidas de Centralidade\nAs principais medidas de centralidade, ou posição, (média e mediana) são facilmente calculadas no R com as funções mean() e median(). Essa funções recebem valores numéricos como argumentos. Para exemplificar essas funções vamos usar novamente um vetor numérico simulando um conjunto de idades e pesos. Observe que no conjunto de pesos há uma dado faltante (NA). Podemos inserir tanto o próprio vetor isolado como argumento, como também uma coluna do data frame ou tibble como mostraremos adiante. nos próximos exemplos iremos usar geralmente a forma do tidyverse para calcular medidas estatísticas em variáveis de um data frame, usando o operador $ para acessarmos as colulnas.\n\n# cria um conjunto de idades (anos)\nidade <- c(45, 10, 12, 27, 32, 18, 30)\n# cria um conjunto de pesos (kg)\npeso  <- c(70,  6,  8, 66, 72, 68, NA)\n\ndf <- tibble(idade, peso)\n\n\n# calcula a média aritmética da idade num vetor\nmean(idade)\n\n[1] 24.85714\n\n\nPara calculara a média do peso, será necessário incluir o argumento na.rm=TRUE, pois a variável contem valores NA. Veja o resultado do cálculo com e sem esse argumento.\n\n# calcula a média do peso, sem retirar os NA (o R não consegue calcular)\nmean(peso)\n\n[1] NA\n\n\n\n# calcula a média do peso, retirando os NA\nmean(peso, na.rm = TRUE)\n\n[1] 48.33333\n\n\n\n# calcula a média do peso, retirando os NA, usando a tibble criada\nmean(df$peso, na.rm = TRUE)\n\n[1] 48.33333\n\n\n\n\n12.5.1.2 Medidas de Partição e Posição\n\n12.5.1.2.1 Máximo e Mínimo\n\n# a função min calcular o valor mínimo do conjunto numérico indicado como argumento\nmin(df$idade)\n\n[1] 10\n\n\n\n# a função max calcular o  o valor máximo do conjunto numérico indicado como argumento\nmax(df$idade)\n\n[1] 45\n\n\n\n\n12.5.1.2.2 Quantil, quartil e percentil\nO percentil é uma medida de localização que divide uma amostra ordenada em 100 partes. Cada valor de percentil indica o percentual de dados abaixo daquele valor. Por exemplo, o percentil 25% indica o valor abaixo do qual estão 25% dos dados. Em estatística é usual usar-se o termo quantil ao invés de percentil. A diferença é que o quantil é escrito com valores decimais (0.25) e percentil com valores percentuais (25%). Os percentis (ou quantis) mais importantes são os de 25%, 50% e 75%, conhecidos, respectivamente, como 1º quartil, 2º quartil e 3º quartil, por dividirem a amostra dos dados em 4 partes iguais, cada uma com 1/4 (ou 25%) dos dados.\n\n\n\n\n\nA função quantile() do R calcula todos esses quartis de uma só vez.\n\n# calcula os quartis 25% (1º), 50% (2º) e 75% (3º)\nquantile(df$idade)\n\n  0%  25%  50%  75% 100% \n  10   15   27   31   45 \n\n\nPodemos usar essa função para calcular individualmente o quantil desejado, bastando inserir esse valor como argumento logo depois da variável com os dados. Lembrando que é necessário usar o valor decimal e não o percentual (mais uma dica: lembre-se que no R o decimal é o ponto final e não a vírgula). Mais uma vez, se houver valores NA será necessário incluir o argumento na.rm=TRUE.\n\nquantile(df$idade, 0.25)\n\n25% \n 15 \n\n\n\nquantile(df$idade, 0.10)\n\n 10% \n11.2 \n\n\n\nquantile(df$peso, 0.25, na.rm = TRUE)\n\n 25% \n22.5 \n\n\n\n# a função range retornao valor mínimo e máximo do conjunto numérico indicado como argumento\nrange(df$idade)\n\n[1] 10 45\n\n\n\n# a função diff calcula a diferença entre os valores indicados como argumentos, nesse caso, a amplitude (máximo - mínimo) da idade\ndiff(range(df$idade))\n\n[1] 35\n\n\n\n\n12.5.1.2.3 Amplitude interquartil\nA amplitude interquartil é uma medida de dispersão que mede a amplitude de 50% das observações centrais do conjunto. O primeiro e o terceiro quartis, respectivamente os percentis 25% e 75%, dividem a amostra de forma que 50% dos dados estão entre esses pontos. A amplitude desses dados centrais é conhecida como amplitude interquartil (interquartile range - IQR) e é uma medida de amplitude mais robusta que a amplitude, pois não é sensível aos valores extremos. Seu cálculo é simplesmente o valor do 3º quartil menos o valor do 1º quartil.\nA amplitude interquartil é também conhecida pelos termos em inglês midspread, middle 50% ou H-spread.\n\n# calcula a amplitude interquartil\nIQR(df$idade)\n\n[1] 16\n\n\n\n\n\n12.5.1.3 Medidas de Dispersão\n\n12.5.1.3.1 Variância e Desvio Padrão\nAs funções do R para calcular a variância var() e desvio padrão sd() utilizam as fórmulas para a variância e desvio padrão com a correção de Bessel, feita para corrigir o viés da estimativa da variância e do desvio padrão, que tendem a subestimar a variabilidade da população quando calculados a partir de uma amostra. As funções var() e sd() utilizam no denominador os valores n-1 e não n. Ou seja, as funções do R estão calculando a estimativa da variância da população a partir de uma amostra. Ou seja, essas funções assumem que os dados representam uma amostra da população e não a população inteira.\nQuando for necessário estimar o desvio padrão ou variância levando em consideração apenas os elementos da amostra precisamos fazer um pequeno ajuste.\nVejamos isso nos próximos exemplos.\n\n# criando um vetor de dados distribuidos de frorma normal com 100 elementos\nset.seed(1)\nn=100\nx <- rnorm(n)\n\nVariância com e sem a correção de Bessel\n\n# Calculando a variância com a correção de bessel\n# Ou seja, calculando a estimativa do variância da população a partir de uma amostra\n var(x) \n\n[1] 0.8067621\n\n# Calculando a variância sem a correção de bessel\n# nesse caso precisamos multiplicar o resultado por (n-1)/n\nvar(x) * ((n-1)/n)\n\n[1] 0.7986945\n\n\nDesvio padrão com e sem a correção de Bessel\n\n# Calculando o desvio padrão com a correção de bessel\n# Ou seja, calculando a estimativa do desvio da população a partir de uma amostra\nsd(x) \n\n[1] 0.8981994\n\n# calculando o desvio padrão sem a correção de bessel\n# nesse caso precisamos multiplicar o resultado por sqrt((n-1)/n)\n sd(x) * sqrt((n-1)/n) # população\n\n[1] 0.8936971\n\n\n\n\n\n\n12.5.2 Agrupando dados numéricos\nFrequentemente precisamos agrupar dados numéricos com base em variáveis categóricas. Por exemplo, quando desejamos separar as médias de uma determinada medida entre cada gênero, ou entre diferentes faixas etárias ou entre um grupo experimental e um grupo controle.\nA linguagem R possui funções criadas especialmente para esse fim: a função by() do R base e a função group_by() do tidyverse são as mais importantes para essa finalidade.\nA função by() do R base é usada para aplicar uma função a subconjuntos de um data frame, organizados por um fator ou combinação de fatores. Aqui estão algumas vantagens de usar by():\n\nSimplicidade: Uma solução base do R, sem necessidade de carregar pacotes adicionais.\nFlexibilidade: Pode ser usada com qualquer função que aceite data frames como input, o que permite operações complexas nos subconjuntos de dados.\nCompatibilidade: Por ser parte do R base, não depende de pacotes externos e é garantido funcionar em qualquer instalação do R.\nResulta em listas: O output é uma lista, que pode ser útil para manipulações subsequentes.\n\nA função group_by() do pacote dplyr, que faz parte do tidyverse, é usada para agrupar dados em um data frame. Aqui estão algumas das vantagens de usar group_by():\n\nFacilidade de uso: A sintaxe é intuitiva e fácil de usar, especialmente quando combinada com outras funções do dplyr como summarise, mutate, etc.\nIntegração com a pipe (|>): Permite a construção de pipelines de manipulação de dados de maneira clara e legível.\nFlexibilidade: Pode ser usada com múltiplas colunas para criar grupos mais complexos.\nPerformance: Otimizado para grandes conjuntos de dados, especialmente quando combinado com outras operações do dplyr.\nCompatibilidade: Facilmente combinado com outros pacotes do tidyverse, como ggplot2 para visualização de dados, tidyr para transformação, entre outros.\n\nA função group_by() é geralmente mais fácil de ler e entender, especialmente em pipelines de dados, se integra perfeitamente com outras funções do tidyverse, proporcionando uma maneira coesa e eficiente de manipulação de dados. Por outro lado, by() é útil quando não se deseja depender de pacotes externos e quando se trabalha em um ambiente onde a simplicidade é essencial. Ambas as funções têm suas vantagens e a escolha entre elas pode depender do contexto específico e das necessidades do seu projeto.\n\n12.5.2.1 Agrupando com by()\nA função by() agrupa a variável desejada segundo alguma outra variável categórica. A função by() tem como argumentos:\n\ndata: um objeto do R, geralmente um data frame ou tibble.\n\nINDICES: uma variável categórica (factor) que define a separação dos grupos.\n\nFUN: uma função a ser aplicada aos subconjuntos data frame.\n\nO dataset mtcars do R é um conjunto de dados sobre 32 carros de 1973-1974, com dados sobre 10 aspectos do design dos carros. Nesse dataset variável am representa a marcha do carro, sendo 0 = câmbio automático, 1 = câmbio manual. Podemos, portanto, aplicar a função summary() no dataset mtcars através da função by(), estratificando alguma variável de acordo com o tipo de câmbio (manual ou automático) e aplicando o comando em cada grupo.\nVeja como fazer isso no código abaixo.\n\nby(data =  mtcars, INDICES =  mtcars$am, FUN =   summary)\n\nmtcars$am: 0\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0  \n 1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5  \n Median :17.30   Median :8.000   Median :275.8   Median :175.0  \n Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3  \n 3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5  \n Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0  \n      drat             wt             qsec             vs               am   \n Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.   :0  \n 1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st Qu.:0  \n Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median :0  \n Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean   :0  \n 3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd Qu.:0  \n Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.   :0  \n      gear            carb      \n Min.   :3.000   Min.   :1.000  \n 1st Qu.:3.000   1st Qu.:2.000  \n Median :3.000   Median :3.000  \n Mean   :3.211   Mean   :2.737  \n 3rd Qu.:3.000   3rd Qu.:4.000  \n Max.   :4.000   Max.   :4.000  \n------------------------------------------------------------ \nmtcars$am: 1\n      mpg             cyl             disp             hp             drat     \n Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.   :3.54  \n 1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st Qu.:3.85  \n Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median :4.08  \n Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean   :4.05  \n 3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd Qu.:4.22  \n Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.   :4.93  \n       wt             qsec             vs               am         gear      \n Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.   :4.000  \n 1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st Qu.:4.000  \n Median :2.320   Median :17.02   Median :1.0000   Median :1   Median :4.000  \n Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean   :4.385  \n 3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd Qu.:5.000  \n Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.   :5.000  \n      carb      \n Min.   :1.000  \n 1st Qu.:1.000  \n Median :2.000  \n Mean   :2.923  \n 3rd Qu.:4.000  \n Max.   :8.000  \n\n\nPodemos usar a função by inserindo os argumentos na ordem, sem necessidade de explicitar o que é cada um, como feito a seguir:\n\nby(mtcars, mtcars$am, summary)\n\nmtcars$am: 0\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0  \n 1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5  \n Median :17.30   Median :8.000   Median :275.8   Median :175.0  \n Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3  \n 3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5  \n Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0  \n      drat             wt             qsec             vs               am   \n Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.   :0  \n 1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st Qu.:0  \n Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median :0  \n Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean   :0  \n 3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd Qu.:0  \n Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.   :0  \n      gear            carb      \n Min.   :3.000   Min.   :1.000  \n 1st Qu.:3.000   1st Qu.:2.000  \n Median :3.000   Median :3.000  \n Mean   :3.211   Mean   :2.737  \n 3rd Qu.:3.000   3rd Qu.:4.000  \n Max.   :4.000   Max.   :4.000  \n------------------------------------------------------------ \nmtcars$am: 1\n      mpg             cyl             disp             hp             drat     \n Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.   :3.54  \n 1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st Qu.:3.85  \n Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median :4.08  \n Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean   :4.05  \n 3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd Qu.:4.22  \n Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.   :4.93  \n       wt             qsec             vs               am         gear      \n Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.   :4.000  \n 1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st Qu.:4.000  \n Median :2.320   Median :17.02   Median :1.0000   Median :1   Median :4.000  \n Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean   :4.385  \n 3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd Qu.:5.000  \n Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.   :5.000  \n      carb      \n Min.   :1.000  \n 1st Qu.:1.000  \n Median :2.000  \n Mean   :2.923  \n 3rd Qu.:4.000  \n Max.   :8.000  \n\n\nComo os valores dessa am variável são números (0 e 1), o R os interpreta como numéricos. O mesmo acontece nas variáveis cyl, am, vs, gear e carb, que na verdade são categóricas. A tabela abaixo descreve as variáveis desse conjunto de dados.\n\n\n\n\n\nmtcars dictionary\n\n\n\n\nVamos verificar como essas variáveis estão sendo interpretadas no R usando a função str(), que verifica a estrutura dos dados.\n\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\nObserve que cyl, am, vs, gear e carb foram interpretadas como numéricas. Nesse caso, a função summary() irá erroneamente calcular medidas numéricas nas nessas variáveis, que na verdade são categóricas.\n\nsummary(mtcars)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n\nPara resolver esse problema precisamos informar ao R que as variáveis cyl, am, vs, gear e carb são categóricas com a função as.factor() como mostrado a seguir.\n\nmtcars$cyl  <- as.factor(mtcars$cyl)\nmtcars$am   <- as.factor(mtcars$am)\nmtcars$vs   <- as.factor(mtcars$vs)\nmtcars$gear <- as.factor(mtcars$gear)\nmtcars$carb <- as.factor(mtcars$carb)\n\nAgora a função summary() irá corretamente fazer as tabelas, pois já estão configuradas como sendo categóricas. Podemos ver no código abaixo que existem 19 carros com cambio automático (am=0), e 13 carros com cambio manual (am=1).\n\nsummary(mtcars)\n\n      mpg        cyl         disp             hp             drat      \n Min.   :10.40   4:11   Min.   : 71.1   Min.   : 52.0   Min.   :2.760  \n 1st Qu.:15.43   6: 7   1st Qu.:120.8   1st Qu.: 96.5   1st Qu.:3.080  \n Median :19.20   8:14   Median :196.3   Median :123.0   Median :3.695  \n Mean   :20.09          Mean   :230.7   Mean   :146.7   Mean   :3.597  \n 3rd Qu.:22.80          3rd Qu.:326.0   3rd Qu.:180.0   3rd Qu.:3.920  \n Max.   :33.90          Max.   :472.0   Max.   :335.0   Max.   :4.930  \n       wt             qsec       vs     am     gear   carb  \n Min.   :1.513   Min.   :14.50   0:18   0:19   3:15   1: 7  \n 1st Qu.:2.581   1st Qu.:16.89   1:14   1:13   4:12   2:10  \n Median :3.325   Median :17.71                 5: 5   3: 3  \n Mean   :3.217   Mean   :17.85                        4:10  \n 3rd Qu.:3.610   3rd Qu.:18.90                        6: 1  \n Max.   :5.424   Max.   :22.90                        8: 1  \n\n\nVeja que essa função resolve muitas de nossas necessidades no processo de análise de dados, porém, como já dito, é comum que uma variável categórica seja codificada com números, nesse caso, temos de fazer o ajuste antes de usar a função summary(), como fizemos antes de usar a função summary() com o dataset mtcars em seções anteriores.\n\n\n12.5.2.2 Agrupando com group_by()\nVamos usar a função group_by() para separar grupos antes de calcular alguma medida estatística. Como exemplo, vamos comparar de níveis de glicose entre grupos com diferentes hábitos de exercício. Para isso precisaremos agrupar os dados numéricos dos níveis de glicose com base nas categorias de exercício (ex: Sedentário, Moderado, Intenso). Para isso será preciso carregar o pacote dplyr. Iremos também usar uma variável para armazenar os dados para análise e usar o operador pipe para melhorar a estética do código.\n\n# carregando o pacote dplyr e tibble\nlibrary(dplyr)\nlibrary(tibble)\n\n# Criando o data frame com 15 pacientes\ndf <- tibble(paciente = 1:15,\n             exercicio = c(\"Sedentário\", \"Moderado\", \"Intenso\", \n                           \"Moderado\", \"Sedentário\", \"Intenso\", \n                           \"Sedentário\", \"Moderado\", \"Intenso\", \n                           \"Moderado\", \"Sedentário\", \"Intenso\", \n                           \"Sedentário\", \"Moderado\", \"Intenso\"),\n             nivel_glicose = c(150, 130, 110, 140, 160, 100, \n                               155, 135, 115, 145, 165, 105, \n                               158, 138, 112))\n\nprint(df)\n\n# A tibble: 15 × 3\n   paciente exercicio  nivel_glicose\n      <int> <chr>              <dbl>\n 1        1 Sedentário           150\n 2        2 Moderado             130\n 3        3 Intenso              110\n 4        4 Moderado             140\n 5        5 Sedentário           160\n 6        6 Intenso              100\n 7        7 Sedentário           155\n 8        8 Moderado             135\n 9        9 Intenso              115\n10       10 Moderado             145\n11       11 Sedentário           165\n12       12 Intenso              105\n13       13 Sedentário           158\n14       14 Moderado             138\n15       15 Intenso              112\n\n\nAgora vamos usar a função group_by() para calcular a média dos níveis de glicose por grupo de exercício. ::: {.cell}\n# Usando group_by() para calcular a média dos níveis de glicose por grupo de exercício\nresult_exercicio <- df |>\n  group_by(exercicio) |>\n  summarise(mean_glicose = mean(nivel_glicose))\n\nprint(result_exercicio)\n\n# A tibble: 3 × 2\n  exercicio  mean_glicose\n  <chr>             <dbl>\n1 Intenso            108.\n2 Moderado           138.\n3 Sedentário         158.\n\n:::\nVamos tentar analisar novamente o dataset mtcars, mas agora usando a função group_by() do dplyr. ::: {.cell}\n# Carregar o pacote dplyr\nlibrary(dplyr)\n\n# Carregar o dataset mtcars\ndata(mtcars)\n\n# Estratificar os dados segundo a variável \"am\" e calcular estatísticas resumidas\nmtcars_analysis <- mtcars |>\n  group_by(am) |>\n  summarise(mean_mpg = mean(mpg),          # Média de milhas por galão\n            mean_hp = mean(hp),            # Média de potência\n            mean_wt = mean(wt),            # Média de peso\n            mean_qsec = mean(qsec),        # Média de tempo no quarto de milha\n            count = n())                   # Contagem de carros em cada grupo\n\n# Exibir o resultado\nprint(mtcars_analysis)\n\n# A tibble: 2 × 6\n     am mean_mpg mean_hp mean_wt mean_qsec count\n  <dbl>    <dbl>   <dbl>   <dbl>     <dbl> <int>\n1     0     17.1    160.    3.77      18.2    19\n2     1     24.4    127.    2.41      17.4    13\n\n:::\nO código acima agrupou diversos dados segundo o tipo de transmissão (transmissão: 0 = automática, 1 = manual) usando group_by() e em seguida usou a função summarise() para calcular diversas medidas em cada grupo:\n\nmean_mpg: Média de milhas por galão (mpg).\nmean_hp: Média de potência (hp).\nmean_wt: Média de peso (wt).\nmean_qsec: Média de tempo no quarto de milha (qsec).\ncount: Contagem de carros em cada grupo.\n\n\n12.5.2.2.1 Resumindo numericamente os dados:\nAs funções summary() do R base e summarise() ou summarize() do pacote dplyr servem para resumir um conjunto de dados.\nA diferença nas funções summarise() ou summarize() do dplyr precisamos especificar quais medidas estatísticas serão calculadas. Apesar de dar um trabalho a mais escrever o código, você tem muito mais flexibilidade, podendo criar um novo dataframe com qualquer medida de interesse.\nOutro ponto importante é que a função summary() do R retorna um objeto do tipo tabela, enquanto as funções summarise() ou summarize() do pacote dplyr retornam um objeto do tipo data frame, que é muito mais flexivel de usar e extrair dados do que uma tabela.\nPara verificar novamente como usar essa função veja o capítulo sobre o pacote dplyr (?sec-dply).\n\n\n\n\n12.5.3 Categorizando variáveis numéricas\n\n12.5.3.1 Categorizando com a função cut( )\nA função cut() nos permite criar uma variável categórica a partir de uma variável numérica. A forma dessa função é:\n\ncut(variável, breaks=c(-Inf, x1, x2, Inf), labels=c(“label”, “label”, “label”))\n\nVeja que o parâmetro breaks pode usar -Inf como limite inferior e Inf como limite superior. Entre esses limites extremos serão definidos os pontos de corte. Podemos colocar quantos pontos desejarmos, mas é sempre prudente evitar excessos.\nVeja também que com 2 pontos intermediários serão criados 3 categorias. Por padrão os intervalos são do abertos à esquerda e fechados à direita, tal como em (x1, x2]. De tal forma que o intervalo termina no valores indicados, incluindo esse valor.\n\n\n\n\n\nCut\n\n\n\n\nVamos continuar usando o dataset mpg. Para exemplificar o uso da função cut() vamos criar uma variável categórica cty_cat a partir cty (milhas percorridas na estrada com 1 galão de combustível). A variável cty é numérica, com valores variando de 9 milhas a 35 milhas. Vamos definir 3 categorias de carros:\n\n\n\n\n\nCut\n\n\n\n\nComo o limite superior do intervalo é aberto, o valor desse ponto de corte será parte da 1º categoria, portanto, o primeiro ponto de corte deve ser 15, já que definimos o primeiro intervalo como menor ou igual a 15. O segundo ponto de corte será 20, pois será o limite superior da segunda categoria é menor ou igual a 20. O código ficará então:\n\nlibrary(ggplot2) # necessário para usar o dataset mpg\ndata(mpg) # carregando o dataset mpg na memória\nmpg$cty_cat <- cut(mpg$cty,\n                   breaks=c(-Inf, 15, 20, Inf),\n                   labels=c(\"0\",\"1\", \"2\"))\n\nAgora o data frame mpg contém uma nova variável categórica denominada cty_cat com 3 níveis, o que podemos verificar com a função class() e unique().\n\nclass(mpg$cty_cat)\n\n[1] \"factor\"\n\n\nEntretanto, ainda falta um pequeno detalhe. A variável criada deveria ser ordenada, mas foi criada como sendo uma variável nominal. Por padrão o R cria uma variável categórica nominal com a função cut(). Para indicar que desejamos que a nova variável seja ordenada devemos modificar o parâmetro ordered_result para TRUE (ordered_result = TRUE).\n\nmpg$cty_cat <- cut(mpg$cty,                  \n                   breaks=c(-Inf, 15, 20, Inf),                  \n                   labels=c(\"0\",\"1\", \"2\"),                  \n                   ordered_result = TRUE)\n\nVamos verificar agora que a variável cty_cat( ) é ordenada e qual a ordenação.\n\nclass(mpg$cty_cat)\n\n[1] \"ordered\" \"factor\" \n\n\n\nunique(mpg$cty_cat)\n\n[1] 1 2 0\nLevels: 0 < 1 < 2\n\n\nObserve que apesar dos valores da variável cty_cat serem 0, 1 e 2, essa variável é uma variável categórica e esses valores não representam números no R. Poderíamos muito tem ter nomeado essas categorias de A, B e C ou usar a função fct_recode() do pacote forcats para tornar esses dados mais compreensíveis.\n\nlibrary(forcats)\nmpg <- mpg |>\n  mutate(cty_cat = fct_recode(cty_cat,\n                            \"0 a 15 milhas com um galão\" = \"0\",\n                            \"15 a 30 milhas com um galão\" = \"1\",\n                            \"Mais de 30 Milhas com um galão\" = \"2\"))\n\nPodemos agora criar uma tabela mais fácil de compreender com a função table() do R como mostrado abaixo. Observe que usamos como argumento da função table() o dataset mpg seguido do operador $ para selecionar a coluna com a variável cty_cat.\n\ntable(mpg$cty_cat)\n\n\n    0 a 15 milhas com um galão    15 a 30 milhas com um galão \n                            97                             92 \nMais de 30 Milhas com um galão \n                            45 \n\n\nMas podemos melhorar ainda mais esse código usando a função count() do dplyr já tratada em capítulos anteriores (Section 12.2.13) e usando o operador pipe.\nVeja que no código abaixo começamos com o dataset mpg, seguido do operador pipe para passar esse datase para a função count(). E inserimos como argumento da função count() o nome da variável categórica a ser usada.\n\nlibrary(dplyr)\nmpg |> count(cty_cat)\n\n# A tibble: 3 × 2\n  cty_cat                            n\n  <ord>                          <int>\n1 0 a 15 milhas com um galão        97\n2 15 a 30 milhas com um galão       92\n3 Mais de 30 Milhas com um galão    45\n\n\n\n\n12.5.3.2 Categorizando com a função ifelse( )\nÀs vezes precisamos criar uma variável categórica com apenas dois valores a partir de uma variável numérica. Nesse caso, para criar uma variável dicotômica a partir de uma variável numérica a função ifelse() é mais simples de usar.\nPara exemplificar vamos criar uma nova variável categoria denominada de hwy_cat a partir da variável hwy (milhas percorridas com um galão na estrada). Iremos definir como BEBE MUITO os carros que fizerem menos de 20 milhas na estrada e como ECONOMICO os outros.\nA função ifelse tem o seguinte formato: > ifelse(condição, rótulo.da.condição.verdadeira, rótulo.da.condição.falsa)\n\nO código fica então da seguinte maneira Condição: Testa se valor da variável hwy é menor que 20. Quando a condição for verdadeira, - o rótulo será o primeiro (“BEBEMUITO”), - se não o rótulo será o seguinte (“ECONOMICO”).\n\nO código acima na liguagem R é o seguinte:\n\nmpg$hwy_cat <- ifelse(mpg$hwy<20, \"BEBEMUITO\", \"ECONOMICO\")\ntable(mpg$hwy_cat)\n\n\nBEBEMUITO ECONOMICO \n       78       156 \n\n\nEm sua forma mais simples poderíamos ter escrito:\n\nmpg$hwy_cat <- ifelse(mpg$hwy<20, 0, 1)\ntable(mpg$hwy_cat)\n\n\n  0   1 \n 78 156 \n\n\nEntretanto, cuidado, dessa última forma a variável criada será identificada no R como sendo numérica. Para indicar que a variável criada não é numérica coloque os rótulos entre aspas.\n\nmpg$hwy_cat <- ifelse(mpg$hwy<20, \"0\", \"1\")\ntable(mpg$hwy_cat)\n\n\n  0   1 \n 78 156 \n\n\nDe qualquer forma, no R a função ifelse não gera variáveis categóricas, para isso deveremos explicitamente indicar que desejamos que a nova variável seja categórica com a função as.factor().\n\nmpg$hwy_cat <- as.factor(ifelse(mpg$hwy<20, \"BEBEMUITO\", \"ECONOMICO\"))\ntable(mpg$hwy_cat)\n\n\nBEBEMUITO ECONOMICO \n       78       156"
  },
  {
    "objectID": "11-Manipulating_data.html#resumindo-dados",
    "href": "11-Manipulating_data.html#resumindo-dados",
    "title": "12  Manipulando dados",
    "section": "12.6 Resumindo dados",
    "text": "12.6 Resumindo dados\nResumir dados é uma tarefa muito comum em análise de dados. Podemos resumir dados de várias formas, como por exemplo, calculando medidas de tendência central, medidas de dispersão, tabelas de frequência, etc.\nO R possui diversas funções para resumir dados. As funções summarise() ou summarize() do pacote dplyr são sinônimas e servem para criar um novo dataframe com informações resumidas, ou seja, estatísticas de um conjunto de dados. A diferença entre essas funções e a função summary do R é que precisamos especificar quais medidas estatísticas serão calculadas. Apesar de dar um trabalho a mais escrever o código, você tem muito mais flexibilidade, podendo criar um novo dataframe com qualquer medida de interesse.\nO pacote skimr possui também algumas funções interessantes para resumir dados. A função skim() é uma delas. Ela fornece um resumo estatístico de um conjunto de dados, incluindo medidas de tendência central, dispersão, distribuição e muito mais. A função skim() é útil para obter uma visão geral rápida dos dados e identificar possíveis problemas ou padrões. Lembre-se que para usar essa funcção é necessário que você já tenha instalado o pacote skimr. Se ainda não tiver feito isso, use o comando install.packages(\"skimr\") para instalar o pacote. Depois será necessário usar o comando library(skimr) para carregar esse pacote.\ndo pacote psych possui a função describe() que fornece um resumo estatístico de um conjunto de dados, incluindo medidas de tendência central, dispersão, distribuição e muito mais. A função describe() é útil para obter uma visão geral rápida dos dados e identificar possíveis problemas ou padrões. Lembre-se que para usar essa funcção é necessário que você já tenha instalado o pacote psych. Se ainda não tiver feito isso, use o comando install.packages(\"psych\") para instalar o pacote. Depois será necessário usar o comando library(psych) para carregar esse pacote.\n\n12.6.1 Resumindo dados com summary()\nPodemos resumir um conjunto de dados com a função summary(). O argumento dessa função é um data frame.\nEssa função cria tabelas de todas as variáveis categóricas de um conjunto de dados de uma só vez e também calcula as medidas de mínimo, máximo, media, mediana e quartis de medidas numéricas.\nVeja essa função aplicada no dataset esoph do R, que contém dados de um estudo de caso controle de câncer de esôfago na frança.\n\nstr(esoph)\n\n'data.frame':   88 obs. of  5 variables:\n $ agegp    : Ord.factor w/ 6 levels \"25-34\"<\"35-44\"<..: 1 1 1 1 1 1 1 1 1 1 ...\n $ alcgp    : Ord.factor w/ 4 levels \"0-39g/day\"<\"40-79\"<..: 1 1 1 1 2 2 2 2 3 3 ...\n $ tobgp    : Ord.factor w/ 4 levels \"0-9g/day\"<\"10-19\"<..: 1 2 3 4 1 2 3 4 1 2 ...\n $ ncases   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ncontrols: num  40 10 6 5 27 7 4 7 2 1 ...\n\n\nPodemos ver acima que o dataset espoa contém 5 variáveis, 3 delas categóricas ordinais (chamadas no R de Ordered factor) e 2 numéricas.\n\nsummary(esoph)\n\n   agegp          alcgp         tobgp        ncases         ncontrols     \n 25-34:15   0-39g/day:23   0-9g/day:24   Min.   : 0.000   Min.   : 0.000  \n 35-44:15   40-79    :23   10-19   :24   1st Qu.: 0.000   1st Qu.: 1.000  \n 45-54:16   80-119   :21   20-29   :20   Median : 1.000   Median : 4.000  \n 55-64:16   120+     :21   30+     :20   Mean   : 2.273   Mean   : 8.807  \n 65-74:15                                3rd Qu.: 4.000   3rd Qu.:10.000  \n 75+  :11                                Max.   :17.000   Max.   :60.000  \n\n\nVeja que a função summary() cria tabelas para as variáveis categóricas e calcula várias medidas estatísticas para as variáveis numéricas.\nPoderíamos também tabular essas variáveis com a função table() como mostrado abaixo, para cada variável categórica separadamente.\n\ntable(esoph$agegp)\n\n\n25-34 35-44 45-54 55-64 65-74   75+ \n   15    15    16    16    15    11 \n\n\n\ntable(esoph$alcgp)\n\n\n0-39g/day     40-79    80-119      120+ \n       23        23        21        21 \n\n\n\ntable(esoph$tobgp)\n\n\n0-9g/day    10-19    20-29      30+ \n      24       24       20       20 \n\n\nFrequentemente variáveis categóricas são representadas por algum valor numérico. Por exemplo, em muitas pesquisas o sexo masculino pode ser representado por 0 e o feminino por 1. Nesses casos a variável sexo poderá ser erroneamente interpretada no R como numérica, quando na verdade é categórica.\nVeja por exemplo o data frame mtcars no qual a variável am representa a marcha do carro, sendo 0 = câmbio automático, 1 = câmbio manual. Como os valores dessa variável são números (0 e 1), o R os interpreta como numéricos. O mesmo acontece na variável vs.\n\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\nNesse caso, a função summary() irá erroneamente calcular medidas numéricas nas variáveis am e vs, que na verdade são categóricas:\n\nsummary(mtcars)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n\n\nPara resolver esse problema basta informar ao R que essas variáveis são categóricas com a função as.factor() como mostrado a seguir.\n\nmtcars$am <- as.factor(mtcars$am)\nmtcars$vs <- as.factor(mtcars$vs)\n\nAgora a função summary() irá corretamente fazer as tabelas das variáveis vs e am, pois já estão configuradas como sendo categóricas. Podemos ver no código abaixo que existem 19 carros com cambio automático (am=0), e 13 carros com cambio manual (am=1).\n\nsummary(mtcars)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec       vs     am          gear      \n Min.   :2.760   Min.   :1.513   Min.   :14.50   0:18   0:19   Min.   :3.000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1:14   1:13   1st Qu.:3.000  \n Median :3.695   Median :3.325   Median :17.71                 Median :4.000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85                 Mean   :3.688  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90                 3rd Qu.:4.000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90                 Max.   :5.000  \n      carb      \n Min.   :1.000  \n 1st Qu.:2.000  \n Median :2.000  \n Mean   :2.812  \n 3rd Qu.:4.000  \n Max.   :8.000  \n\n\nVejamos alguns outros exemplos dessa funcão aplicada a alguns outros data frames.\n\nsummary(USArrests)\n\n     Murder          Assault         UrbanPop          Rape      \n Min.   : 0.800   Min.   : 45.0   Min.   :32.00   Min.   : 7.30  \n 1st Qu.: 4.075   1st Qu.:109.0   1st Qu.:54.50   1st Qu.:15.07  \n Median : 7.250   Median :159.0   Median :66.00   Median :20.10  \n Mean   : 7.788   Mean   :170.8   Mean   :65.54   Mean   :21.23  \n 3rd Qu.:11.250   3rd Qu.:249.0   3rd Qu.:77.75   3rd Qu.:26.18  \n Max.   :17.400   Max.   :337.0   Max.   :91.00   Max.   :46.00  \n\n\n\nsummary(mpg)\n\n manufacturer          model               displ            year     \n Length:234         Length:234         Min.   :1.600   Min.   :1999  \n Class :character   Class :character   1st Qu.:2.400   1st Qu.:1999  \n Mode  :character   Mode  :character   Median :3.300   Median :2004  \n                                       Mean   :3.472   Mean   :2004  \n                                       3rd Qu.:4.600   3rd Qu.:2008  \n                                       Max.   :7.000   Max.   :2008  \n      cyl           trans               drv                 cty       \n Min.   :4.000   Length:234         Length:234         Min.   : 9.00  \n 1st Qu.:4.000   Class :character   Class :character   1st Qu.:14.00  \n Median :6.000   Mode  :character   Mode  :character   Median :17.00  \n Mean   :5.889                                         Mean   :16.86  \n 3rd Qu.:8.000                                         3rd Qu.:19.00  \n Max.   :8.000                                         Max.   :35.00  \n      hwy             fl               class          \n Min.   :12.00   Length:234         Length:234        \n 1st Qu.:18.00   Class :character   Class :character  \n Median :24.00   Mode  :character   Mode  :character  \n Mean   :23.44                                        \n 3rd Qu.:27.00                                        \n Max.   :44.00                                        \n                           cty_cat        hwy_cat   \n 0 a 15 milhas com um galão    :97   BEBEMUITO: 78  \n 15 a 30 milhas com um galão   :92   ECONOMICO:156  \n Mais de 30 Milhas com um galão:45                  \n                                                    \n                                                    \n                                                    \n\n\nVeja que essa função resolve muitas de nossas necessidades no processo de análise de dados, porém, como já dito, é comum que uma variável categórica seja codificada com números, nesse caso, temos de fazer o ajuste antes de usar a função summary(), como fizemos antes de usar a função summary com o dataset mtcars em seções anteriores.\n\n\n12.6.2 Resumindo dados com summarise() do pacote dplyr\nVamos usar como exemplo o dataset diabetes disponível no site da Vanderbilt University School of Medicine:\nhttps://hbiostat.org/data/repo/diabetes.csv\nEsse dataset contém dados de 403 pacientes e 19 variáveis num estudo sobre diabetes, obesidade e outros fatores de risco para doenças coronarianas. O data frame contém então 403 linhasa e 19 colunas. O dicionário de variáveis desse datase pode ser obtido no link a seguir: https://hbiostat.org/data/repo/Cdiabetes.html\n\n\n\n\n\ndiabetes dictionary\n\n\n\n\nPara usar esse dataset é necessário fazer o download desse arquivo e depois carregar esse arquivo no R ou então podemos criar um código para ler os dados diretamente do site, como abaixo\n\nlibrary(readr)\ndiabetes <- read_csv(\"https://hbiostat.org/data/repo/diabetes.csv\")\n\nRows: 403 Columns: 19\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): location, gender, frame\ndbl (16): id, chol, stab.glu, hdl, ratio, glyhb, age, height, weight, bp.1s,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nstr(diabetes)\n\nspc_tbl_ [403 × 19] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id      : num [1:403] 1000 1001 1002 1003 1005 ...\n $ chol    : num [1:403] 203 165 228 78 249 248 195 227 177 263 ...\n $ stab.glu: num [1:403] 82 97 92 93 90 94 92 75 87 89 ...\n $ hdl     : num [1:403] 56 24 37 12 28 69 41 44 49 40 ...\n $ ratio   : num [1:403] 3.6 6.9 6.2 6.5 8.9 ...\n $ glyhb   : num [1:403] 4.31 4.44 4.64 4.63 7.72 ...\n $ location: chr [1:403] \"Buckingham\" \"Buckingham\" \"Buckingham\" \"Buckingham\" ...\n $ age     : num [1:403] 46 29 58 67 64 34 30 37 45 55 ...\n $ gender  : chr [1:403] \"female\" \"female\" \"female\" \"male\" ...\n $ height  : num [1:403] 62 64 61 67 68 71 69 59 69 63 ...\n $ weight  : num [1:403] 121 218 256 119 183 190 191 170 166 202 ...\n $ frame   : chr [1:403] \"medium\" \"large\" \"large\" \"large\" ...\n $ bp.1s   : num [1:403] 118 112 190 110 138 132 161 NA 160 108 ...\n $ bp.1d   : num [1:403] 59 68 92 50 80 86 112 NA 80 72 ...\n $ bp.2s   : num [1:403] NA NA 185 NA NA NA 161 NA 128 NA ...\n $ bp.2d   : num [1:403] NA NA 92 NA NA NA 112 NA 86 NA ...\n $ waist   : num [1:403] 29 46 49 33 44 36 46 34 34 45 ...\n $ hip     : num [1:403] 38 48 57 38 41 42 49 39 40 50 ...\n $ time.ppn: num [1:403] 720 360 180 480 300 195 720 1020 300 240 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_double(),\n  ..   chol = col_double(),\n  ..   stab.glu = col_double(),\n  ..   hdl = col_double(),\n  ..   ratio = col_double(),\n  ..   glyhb = col_double(),\n  ..   location = col_character(),\n  ..   age = col_double(),\n  ..   gender = col_character(),\n  ..   height = col_double(),\n  ..   weight = col_double(),\n  ..   frame = col_character(),\n  ..   bp.1s = col_double(),\n  ..   bp.1d = col_double(),\n  ..   bp.2s = col_double(),\n  ..   bp.2d = col_double(),\n  ..   waist = col_double(),\n  ..   hip = col_double(),\n  ..   time.ppn = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\nLembre-se que será sempre util recodificar as variáveis categóricas como factor usando as.factor()\n\ndiabetes$gender   <- as.factor(diabetes$gender)\ndiabetes$frame    <- as.factor(diabetes$frame)\ndiabetes$location <- as.factor(diabetes$location)\n\nCom os dados lidos, podemos agora verificar as primeiras linhas com a função head():\n\nhead(diabetes)\n\n# A tibble: 6 × 19\n     id  chol stab.glu   hdl ratio glyhb location     age gender height weight\n  <dbl> <dbl>    <dbl> <dbl> <dbl> <dbl> <fct>      <dbl> <fct>   <dbl>  <dbl>\n1  1000   203       82    56  3.60  4.31 Buckingham    46 female     62    121\n2  1001   165       97    24  6.90  4.44 Buckingham    29 female     64    218\n3  1002   228       92    37  6.20  4.64 Buckingham    58 female     61    256\n4  1003    78       93    12  6.5   4.63 Buckingham    67 male       67    119\n5  1005   249       90    28  8.90  7.72 Buckingham    64 male       68    183\n6  1008   248       94    69  3.60  4.81 Buckingham    34 male       71    190\n# ℹ 8 more variables: frame <fct>, bp.1s <dbl>, bp.1d <dbl>, bp.2s <dbl>,\n#   bp.2d <dbl>, waist <dbl>, hip <dbl>, time.ppn <dbl>\n\n\nAgora sim, estamos prontos para usar a função summarise() do dplyr. Vamos usar a função summarise() para calcular a média e o desvio padrão da glicose, que está na variável denominada stab.glu. Vou precisar usar as funções mean(stab.glu)) e sd(stab.glu)). Essas funções serão os argumentos da função summarise().\n1º - Indicar o data frame a ser usado (diabetes);\n2º - usar o operador pipe para passar esse data frame adiante;\n3º - agrupar os dados de acordo com o sexo (gender);\n3º - chamar a função summarise();\n4º - definir os argumentos da função summarise(): a média (usando a função mean()) e o desvio padrão (usando a função sd())\n\ndiabetes |> \n  group_by(gender) |> \n  summarise(media_da_glicose = mean(stab.glu), desvio_padrao_da_glicose = sd(stab.glu))\n\n# A tibble: 2 × 3\n  gender media_da_glicose desvio_padrao_da_glicose\n  <fct>             <dbl>                    <dbl>\n1 female             103.                     43.6\n2 male               112.                     63.6\n\n\nPodemos incluir as medidas que desejarmos como argumentos da função summarise(). Vamos acrescentar a medida da média e desvio padrão da idade, altura e peso, e dessa vez, estratificando pelo biotipo (variável frame), incluindo o número de participantes em cada grupo:\n\ndiabetes |> \n  group_by(frame) |> \n  summarise(media_glicose = mean(stab.glu), \n            dp_glicose    = sd(stab.glu),\n            media_altura  = mean(height),\n            dp_altura     = sd(height),\n            media_peso    = mean(weight),\n            dp_peso       = sd(weight), \n            n             = n())\n\n# A tibble: 4 × 8\n  frame media_glicose dp_glicose media_altura dp_altura media_peso dp_peso     n\n  <fct>         <dbl>      <dbl>        <dbl>     <dbl>      <dbl>   <dbl> <int>\n1 large         121.        63.7         NA       NA          204.    43.2   103\n2 medi…         104.        49.9         65.7      4.00        NA     NA     184\n3 small          96.0       44.4         NA       NA          151.    30.0   104\n4 <NA>          111.        48.4         NA       NA          172.    38.3    12\n\n\nComo várias das estatísticas retornaram com valores NA, é preciso incluir o argumento na.rm=TRUE, como faremos a seguir. Podemos também ordenar o data frame criado conforme desajarmos. Por exemplo, vou colocar a quantidade de participantes como a primeira coluna.\n\ndiabetes |> \n  group_by(frame) |> \n  summarise(n             = n(),\n            media_glicose = mean(stab.glu), \n            dp_glicose    = sd(stab.glu),\n            media_altura  = mean(height, na.rm = TRUE),\n            dp_altura     = sd(height,  na.rm = TRUE),\n            media_peso    = mean(weight, na.rm = TRUE),\n            dp_peso       = sd(weight,   na.rm = TRUE))\n\n# A tibble: 4 × 8\n  frame     n media_glicose dp_glicose media_altura dp_altura media_peso dp_peso\n  <fct> <int>         <dbl>      <dbl>        <dbl>     <dbl>      <dbl>   <dbl>\n1 large   103         121.        63.7         66.6      3.42       204.    43.2\n2 medi…   184         104.        49.9         65.7      4.00       178.    33.9\n3 small   104          96.0       44.4         66.1      4.06       151.    30.0\n4 <NA>     12         111.        48.4         65        5.06       172.    38.3\n\n\nVeja que esse data frame novo não foi armazenado em nenhum objeto ainda, se desejarmos fazer isso basta criar um nome para o objeto e usar o operador de atribuição <-. No código abaixo coloquei o data frame criado num objeto chamado resumo.\n\nresumo <- diabetes |> \n          group_by(frame) |> \n          summarise(n             = n(),\n                    media_glicose = mean(stab.glu), \n                    dp_glicose    = sd(stab.glu),\n                    media_altura  = mean(height, na.rm = TRUE),\n                    dp_altura     = sd(height,  na.rm = TRUE),\n                    media_peso    = mean(weight, na.rm = TRUE),\n                    dp_peso       = sd(weight,   na.rm = TRUE))\n\nresumo\n\n# A tibble: 4 × 8\n  frame     n media_glicose dp_glicose media_altura dp_altura media_peso dp_peso\n  <fct> <int>         <dbl>      <dbl>        <dbl>     <dbl>      <dbl>   <dbl>\n1 large   103         121.        63.7         66.6      3.42       204.    43.2\n2 medi…   184         104.        49.9         65.7      4.00       178.    33.9\n3 small   104          96.0       44.4         66.1      4.06       151.    30.0\n4 <NA>     12         111.        48.4         65        5.06       172.    38.3\n\n\n\n\n12.6.3 Resumindo dados com skim() do pacote skimr\nVamos usar agora a função skim do pacote skimr para resumir os dados. Veja como essa função resolve de forma simples e rápida o problema de resumir os dados.\n\nlibrary(skimr)\nskim(diabetes)\n\n\nData summary\n\n\nName\ndiabetes\n\n\nNumber of rows\n403\n\n\nNumber of columns\n19\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n16\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nlocation\n0\n1.00\nFALSE\n2\nLou: 203, Buc: 200\n\n\ngender\n0\n1.00\nFALSE\n2\nfem: 234, mal: 169\n\n\nframe\n12\n0.97\nFALSE\n3\nmed: 184, sma: 104, lar: 103\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nid\n0\n1.00\n15978.31\n11881.12\n1000.00\n4792.50\n15766.00\n20336.00\n41756.00\n▇▇▇▁▃\n\n\nchol\n1\n1.00\n207.85\n44.45\n78.00\n179.00\n204.00\n230.00\n443.00\n▁▇▃▁▁\n\n\nstab.glu\n0\n1.00\n106.67\n53.08\n48.00\n81.00\n89.00\n106.00\n385.00\n▇▁▁▁▁\n\n\nhdl\n1\n1.00\n50.45\n17.26\n12.00\n38.00\n46.00\n59.00\n120.00\n▂▇▃▁▁\n\n\nratio\n1\n1.00\n4.52\n1.73\n1.50\n3.20\n4.20\n5.40\n19.30\n▇▃▁▁▁\n\n\nglyhb\n13\n0.97\n5.59\n2.24\n2.68\n4.38\n4.84\n5.60\n16.11\n▇▂▁▁▁\n\n\nage\n0\n1.00\n46.85\n16.31\n19.00\n34.00\n45.00\n60.00\n92.00\n▆▇▆▃▁\n\n\nheight\n5\n0.99\n66.02\n3.92\n52.00\n63.00\n66.00\n69.00\n76.00\n▁▂▇▆▂\n\n\nweight\n1\n1.00\n177.59\n40.34\n99.00\n151.00\n172.50\n200.00\n325.00\n▃▇▃▁▁\n\n\nbp.1s\n5\n0.99\n136.90\n22.74\n90.00\n121.25\n136.00\n146.75\n250.00\n▅▇▂▁▁\n\n\nbp.1d\n5\n0.99\n83.32\n13.59\n48.00\n75.00\n82.00\n90.00\n124.00\n▁▆▇▃▁\n\n\nbp.2s\n262\n0.35\n152.38\n21.71\n110.00\n138.00\n149.00\n161.00\n238.00\n▂▇▂▁▁\n\n\nbp.2d\n262\n0.35\n92.52\n11.56\n60.00\n84.00\n92.00\n100.00\n124.00\n▁▅▇▅▁\n\n\nwaist\n2\n1.00\n37.90\n5.73\n26.00\n33.00\n37.00\n41.00\n56.00\n▃▇▆▂▁\n\n\nhip\n2\n1.00\n43.04\n5.66\n30.00\n39.00\n42.00\n46.00\n64.00\n▁▇▅▁▁\n\n\ntime.ppn\n3\n0.99\n341.25\n309.54\n5.00\n90.00\n240.00\n517.50\n1560.00\n▇▂▂▁▁\n\n\n\n\n\nObserve que a função skim() reconheceu corretamente as variáveis location, gender e frame como categóricas, e as variáveis age, height, weight, bmi, waist, hip, time.ppn, and stab.glu como numéricas. A função skim() fornece um resumo estatístico de um conjunto de dados, incluindo medidas de tendência central, dispersão, distribuição e muito mais, sendo útil para obter uma visão geral rápida dos dados e identificar possíveis problemas ou padrões.\n\n\n12.6.4 Resumindo dados com describe() do pacote psych\nVamos usar agora a função describe() do pacote psych para resumir os dados. Veja como essa função também resolve de forma simples e rápida o problema de resumir os dados.\n\nlibrary(psych)\ndescribe(diabetes)\n\n          vars   n     mean       sd   median  trimmed     mad     min      max\nid           1 403 15978.31 11881.12 15766.00 14704.79 8176.54 1000.00 41756.00\nchol         2 402   207.85    44.45   204.00   204.93   37.06   78.00   443.00\nstab.glu     3 403   106.67    53.08    89.00    94.54   17.79   48.00   385.00\nhdl          4 402    50.45    17.26    46.00    48.52   14.83   12.00   120.00\nratio        5 402     4.52     1.73     4.20     4.36    1.63    1.50    19.30\nglyhb        6 390     5.59     2.24     4.84     5.11    0.83    2.68    16.11\nlocation*    7 403     1.50     0.50     2.00     1.50    0.00    1.00     2.00\nage          8 403    46.85    16.31    45.00    46.22   19.27   19.00    92.00\ngender*      9 403     1.42     0.49     1.00     1.40    0.00    1.00     2.00\nheight      10 398    66.02     3.92    66.00    65.98    4.45   52.00    76.00\nweight      11 402   177.59    40.34   172.50   174.81   37.81   99.00   325.00\nframe*      12 391     2.00     0.73     2.00     2.00    1.48    1.00     3.00\nbp.1s       13 398   136.90    22.74   136.00   134.87   20.76   90.00   250.00\nbp.1d       14 398    83.32    13.59    82.00    82.97   11.86   48.00   124.00\nbp.2s       15 141   152.38    21.71   149.00   150.26   16.31  110.00   238.00\nbp.2d       16 141    92.52    11.56    92.00    92.19   11.86   60.00   124.00\nwaist       17 401    37.90     5.73    37.00    37.58    5.93   26.00    56.00\nhip         18 401    43.04     5.66    42.00    42.61    4.45   30.00    64.00\ntime.ppn    19 400   341.25   309.54   240.00   301.02  266.87    5.00  1560.00\n             range  skew kurtosis     se\nid        40756.00  0.81     0.06 591.84\nchol        365.00  0.92     2.54   2.22\nstab.glu    337.00  2.75     8.10   2.64\nhdl         108.00  1.19     1.93   0.86\nratio        17.80  2.20    13.17   0.09\nglyhb        13.43  2.23     4.98   0.11\nlocation*     1.00 -0.01    -2.00   0.02\nage          73.00  0.32    -0.67   0.81\ngender*       1.00  0.33    -1.90   0.02\nheight       24.00  0.03    -0.21   0.20\nweight      226.00  0.72     0.67   2.01\nframe*        2.00  0.00    -1.12   0.04\nbp.1s       160.00  1.10     2.38   1.14\nbp.1d        76.00  0.27     0.04   0.68\nbp.2s       128.00  1.17     2.34   1.83\nbp.2d        64.00  0.18    -0.12   0.97\nwaist        30.00  0.47    -0.17   0.29\nhip          34.00  0.80     0.83   0.28\ntime.ppn   1555.00  1.20     1.02  15.48\n\n\nObserve que a função describe() não foi capaz de interpretar corretamente as variáveis location, gender e frame como categóricas, tendo calculado diversas estatísticas inadequadas para esse tipo de variável, como por exemplo, média e desvio padrão."
  },
  {
    "objectID": "12-Ploting_graphics.html#gráficos-fom-ggplot",
    "href": "12-Ploting_graphics.html#gráficos-fom-ggplot",
    "title": "13  Gráficos",
    "section": "13.1 Gráficos fom ggplot",
    "text": "13.1 Gráficos fom ggplot\n\n13.1.1 Etapas da construção de um gráfico no ggplot2\nA primeira etapa da criação e um gráfico com o ggplot2 é a definição do conjunto de dados. Em seguida são definidas as formas geométricas a serem plotadas (linhas, pontos, barras, etc.). Cada forma geométrica é plotada por uma função específica, cujo nome se inicia sempre com geom_xxx, onde xxx será o tipo de geometria usada (barras: geom_bar; pontos: geom_point; boxplot: geom_boxplot, etc). Em seguida podemos ajustar o sistema de coordenadas, os eixos, as legendas, as paletas de cores, e muitos outros ajustes. Finalmente, podemos também escolher temas pre-definidos para a estética de apresentação dos gráficos. Existem temas para tornar os gráficos no estilo de diversos jornais.\nUma observação importante: o ggplot2 só cria gráficos a partir de dados armazenados em data frames ou tibbles. Portanto, se seus dados não estão num data frame ou tibbles, será necessário primeiro transformá-los nesse tipo de objeto, usando a função data.frame() ou tibble(). Os exemplos a seguir irão usar o dataset mpg, que já é um objeto do tipo data frame e faz parte do conjunto de datasets do próprio ggplot2.\nAntes de usar o conjunto de dados do mpg, vamos ver primeiro lembrar o que existe nesse data frame. Podemos fazer isso usando o comando ?mpg no console, o resultado será mostrado na aba Help, no canto inferior direito do RStudio.\n\n# carregando o pacote ggplot2, necessário para usar o dataset mpg\nlibrary(ggplot2)\n?mpg\n\nDescription This dataset contains a subset of the fuel economy data that the EPA makes available on https://fueleconomy.gov/. It contains only models which had a new release every year between 1999 and 2008 - this was used as a proxy for the popularity of the car.\nUsage mpg - A data frame with 234 rows and 11 variables:\nVariables manufacturer - manufacturer name\nmodel - model name\ndispl - engine displacement, in litres\nyear - year of manufacture\ncyl - number of cylinders\ntrans - type of transmission\ndrv - the type of drive train,\nwhere f = front-wheel drive, r = rear wheel drive, 4 = 4wd\ncty - city miles per gallon\nhwy - highway miles per gallon\nfl - fuel type, r=regular, p=premium, d=diesel, e=ethanol, c=CNG (gas)\nclass - “type” of car\n\n\n\n\n\nmpg dictionary\n\n\n\n\n\n13.1.1.1 Definindo os dados\nPara isso definir qual data frame ou tibble vamos usar, basta usar a função ggplot(), inserindo como argumento o data frame ou tibble com os dados, como mostrado nos exemplos a seguir, usando o data frame mpg.\n\n# carregando o pacote ggplot2\nlibrary(ggplot2)\n\n# começando a criar um gráfico\nggplot(data = mpg)\n\n\n\n\nO resultado do código acima foi a geração de um plano em branco. O ggplot já sabe que queremos usar o data frame mpg, mas ainda não informamos quais variáveis queremos plotar, nem os eixos de cada variável e nem qual o tipo de gráfico desejamos.\n\n\n13.1.1.2 Definindo o tipo de gráfico (mapeamento)\nJá informamos ao ggplot que iremos trabalhar com o data frame mpg na primeira linha do código. As próximas linhas vão acrescentar as outras camadas. Vamos incluir aos poucos outras camada nesse plano. A primeira camada será a forma geométrica que queremos usar. O ggplot2 denomina de geom as formas geométricas que podem ser usadas. Essas geometrias, ou geoms, são funções específicas para cada tipo de gráfico.\nPor exemplo, para um gráfico de barras usamos a função geom_bar(), para um gráfico de pontos (scatter plot) usamos a função geom_point(), para um histograma usamos a função geom_histogram(), para um gráfico de densidade usamos a função geom_density(), para um boxplot usamos a função geom_boxplot(), para um gráfico de linhas usamos a função geom_line() e assim por diante.\nEssas geometrias, todas bidimensionais, necessitam de dataframe ou tibble de onde os dados serão obtidos e um mapeamento estético (aesthetics) para indicar quais variáveis desse dataframe ou tibgle serão usadas para mapear as coordenadas x e y, que é feito com o argumento aes().\nVamos construir um gráfico de barras com a função geom_bar(). O ggplot usa o sistema de acrescentar gradualmente camadas com o operador +. Se você se esquecer do mapeamento estético o RStudio irá gerar um erro.\n\n\n\n\n\n\n\n\nggplot-error\n\n\n\n\nO RStudio indicou um erro, faltou indicar qual a variável no eixo x. Vamos incluir essa variável com o argumento aes(x=nome.da.variável). Lembre-se que um gráfico de barras exige que a variável seja categórica, pois irá plotar as frequencias absolutas de cada um dos elementos dessa categoria. Então, teremos de usar algumas das variáveis categóricas do data frame mpg.\nVamos informar ao R que a variável a ser plotada será drv, que é uma variável categórica, que indica o tipo de tração do carro.\nf = front-wheel drive - tração dianteira\nr = rear wheel drive - tração traseira\n4 = 4wd - tração 4x4.\nVeja que essa informação tem que vir dentro do argumento aes (aesthetics). É interessante inserir esse argumento logo na primeira linha do código, como mostrado abaixo, dentro da função ggplot, logo depois do nome do dataset a ser usado.\n\nggplot(mpg, aes(x=drv)) + \n  geom_bar()\n\n\n\n\nSe deserjamos plotar as frequencias de cada tipo de combustivel usado, basta usar a variável fl (r=regular, p=premium, d=diesel, e=ethanol, c=CNG (gas)).\n\nggplot(mpg, aes(x=fl)) + \n  geom_bar()\n\n\n\n\n\n\n13.1.1.3 Título, subtítulo e notas de rodapé\nPodemos incluir título, subtitulo, notas de rodapé no gráfico do ggplot simplesmente adicionando uma camada a mais com o operador +. A função para incluir esses elementos é labs().\n\nggplot(mpg, aes(x=drv, fill=fl)) +\n  geom_bar() +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\")\n\n\n\n\n\n\n13.1.1.4 Legendas(nomes) dos eixos\nA função labs permite também incluir no gráfico os nomes dos eixos. O argumento para isso deve ser inserido dentro da função labs, como mostrado abaixo.\n\nggplot(mpg, aes(x=drv, fill=fl)) +\n  geom_bar() +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Número de carros\") \n\n\n\n\n\n\n13.1.1.5 Temas\nCom a função theme do ggplot é possível ajustar a fonte, o tamanho das fontes, as cores do fundo do gráfico. Todos esses elementos podem ser precisamente ajustados para adequar o gráfico ao estilo da revista onde será feita a publicação. Os detalhes precisos desses ajustes são um pouco mais complexos mas podem ser facilmente aprendidos na internet. O site do ggplot explica cada uma das diversas possibilidades. Para maiores detalhes consulte esse site: https://ggplot2.tidyverse.org/reference/theme.html\nPara facilitar nos ajustes, existem uma série de temas pré-definidos que podem ser usados bastando incluir no código mais uma linha com o nome do tema desejado.\nTemas disponíveis:\n\ntheme_grey()\ntheme_gray()\ntheme_bw()\ntheme_linedraw()\ntheme_light()\ntheme_dark()\ntheme_minimal()\ntheme_classic()\ntheme_void()\ntheme_test()\n\nEu gosto muito do tema clássico: theme_classic(). Para usar esse tema, basta incluir essa linha no código, como mostrado abaixo:\n\nggplot(mpg, aes(x=drv, fill=fl)) +\n  geom_bar() +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Número de carros\") +\n  theme_classic()\n\n\n\n\nO theme_minimal() inclui algumas linhas horizontais e verticais para facilitar a visualização.\n\nggplot(mpg, aes(x=drv, fill=fl)) +\n  geom_bar() +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Número de carros\") +\n  theme_minimal()\n\n\n\n\nO theme_linedraw() incluir linhas dentro do gráfico e uma caixa ao redor do gráfico.\n\nggplot(mpg, aes(x=drv, fill=fl)) +\n  geom_bar() +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Número de carros\") +\n  theme_linedraw()\n\n\n\n\nO theme_void() retira os eixos e os nomes dos eixos.\n\nggplot(mpg, aes(x=drv, fill=fl)) +\n  geom_bar() +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Número de carros\") +\n  theme_void()\n\n\n\n\nExistem pacotes com mais temas, por exemplo, o pacote ggthemes disponibiliza temas pre-definidos para gráficos do tipo do Wall Street Journal, The Economist, etc. Há pacotes também para deixar os gráficos no estilo do New York Times e vários outros jornais.\nAgora que já estudamos as etapas genéricas de construção de gráficos com o ggplot, vamos ver os detalhes específicos de como construir cada um dos gráficos mais comuns: gráfico de barras, histograma, gráficos de densidade, box plot e diagrama de dispersão (scatter plot).\n\n\n13.1.1.6 Rotacionando o gráfico\nCom o ggplot é fácil rotacionar o gráfico, bastando para isso incluir uma linha no código: coord_flip(). Vejamos como rotacionar o gráfico de barras acima:\n\nggplot(mpg, aes(x=drv, fill=fl)) +\n  geom_bar() +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Número de carros\") +\n  theme_classic()+ \n  coord_flip()\n\n\n\n\n\n\n13.1.1.7 Agrupando os gráficos\nUma técnica para facilitar a visualização de dados é criar gráficos separados para cada subgrupo. Isso é facilmente implementado no ggplot com uma linha a mais no código, através dos comandos facet_wrap() ou facet_grid().\nComo exemplo, vamos criar diversos desses gráficos de barras, de acordo com o número de cilindros dos carros, informação que está na variável cyl. Serão criados gráficos para os carros com 4 cilindros, 5 cilindros, 6 cilindros e 8 cilindros. Observe que o argumento da função facet_wrap() e facet_grid() é precedido pelo operador ~.\n\nggplot(mpg, aes(x=drv, fill=fl)) +\n  geom_bar() +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Número de carros\") +\n  theme_classic() + \n  facet_wrap(~cyl)\n\n\n\n\nÉ possível também criar uma grade, estratificando o gráfico com duas variáveis. Nesse caso as variáveis serão inseridas com o operador ~ entre elas nos argumentos dessas funções. por exemplo: facet_grid(cyl~yearl).\n\nggplot(mpg, aes(x=drv, fill=fl)) +\n  geom_bar() +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 e 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Número de carros\") +\n  theme_classic() + \n  facet_grid(cyl~year)\n\n\n\n\n\n\n13.1.1.8 Estratificando os dados\nO ggplot permite também incluir duas variáveis categóricas num mesmo gráfico de barras. Podemos pedir ao ggplot que use cores diferentes para distinguir os elementos de uma variável dentro da barra.\nPodemos por exemplo, fazer barras com a variável drv e usar cores para distinguir os tipos de combustível dentro de cada barra.\nVeja como é simples incluir isso no código do ggplot, basta usar o argumento fill, que indica como preencher as barras, e indicar que esse preenchimento deve ser feito com base numa outra variável categórica, por exemplo, o tipo de combustível, que está na variável fl. As cores serão automaticamente escolhidas pelo R.\nUm detalhe importante aqui: o argumento fill funciona de forma diferente quando está dentro ou fora da estética (aes). Nesse caso, precisamos que o argumento fill esteja dentro da estética, ou seja, dentro do parenteses do argumento aes.\n\nggplot(mpg, aes(x=drv, fill=fl)) +\n  geom_bar()\n\n\n\n\nSe você não estiver satisfeito com as cores escolhidas, é possível ajustar isso. O R tem diversas paletas de cores e você pode indicar que deseja usar alguma outra. Além disso, há também vários pacotes com outras paletas de cores que podem ser carregados e usados. Uma rápida busca na internet será suficiente para conhecer sobre todas as possibilidades de cores no R. O R tem algumas paletas pré-definidas (rainbow, heat.colors, cm.colors). Alguns dos pacotes mais famosos com paletas de cores são:\n\nViridis color scales [viridis package].\nColorbrewer palettes [RColorBrewer package]\nGrey color palettes [ggplot2 package]\nScientific journal color palettes [ggsci package]\nWes Anderson color palettes [wesanderson package]\n\n\n\n13.1.1.9 Transparência\nPodemos ajustar a transparência das cores usadas com o argumento alpha. Preste atenção no fato que esse argumento deve ficar fora da estética do gráfico, ou seja fora do parênteses do aes().\n\nggplot(mpg, aes(x=drv, fill=fl)) +\n  geom_bar(alpha = 0.5)\n\n\n\n\nNos gráficos nos quais há uma superposição de elementos essa transparência pode ser muito útil para facilitar a visualização.\nVeja no gráfico abaixo que há uma superposição entre as tres distribuições de densidade, o que atrapalha a análise. Podemos ajustar a transparência com o argumento alpha. Preste atenção no fato que esse argumento deve ficar fora da estética do gráfico, ou seja fora do parênteses do aes().\n\nggplot(mpg, aes(x=hwy)) +\n  geom_density(aes(fill=drv), alpha = 0.5) +\n  labs(title = \"Milhas percorridas na estrada com um galão de combustível\",\n       subtitle = \"de acordo com o tipo de tração do carro\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Milhas\", \n       y = \"Número de carros\") +\n  theme_classic()\n\n\n\n\n\n\n\n13.1.2 Gráfico de Barras\nJá vimos comos construir um gráfico de barras nas seções anteriores. Vamos ver agora apenas alguns ajustes que podem ser feitos nesse tipo de gráfico.\n\n13.1.2.1 Alterando a ordenação das barras\nLembre-se, como discutido na seção dobre variáveis categóricas, que os gráficos ggplot por padrão usam uma sequencia alfabética para dispor os elementos. Se desejarmos mudar isso, basta usar a função fct_infreq() do pacote forcats. Depois basta plotar novamente o gráfico.\n\n# carregando os pacotes\nlibrary(ggplot2) # necessário para usar o dataset mpg\nlibrary(forcats) # necessário para usar a função fct_infreq\nlibrary(dplyr) # necessário para usar mutate\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# indicando que a variável drv deverá ser plotada com de acordo com a frequencia\nmpg <- mpg |> \n  mutate(drv = fct_infreq(drv))\n\n# plotando novamente o gráfico\nggplot(mpg, aes(x=drv)) +\n  geom_bar() +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Número de carros\") +\n  theme_classic()\n\n\n\n\nE, se desejar que as frequencias seja mostradas de forma crescente, basta incluir a função fct_rev.\n\n# indicando que a variável drv deverá ser plotada com de acordo com a frequencia crescente\nmpg <- mpg |> \n  mutate(drv = fct_rev(fct_infreq(drv)))\n\n# plotando novamente o gráfico\nggplot(mpg, aes(x=drv)) +\n  geom_bar() +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Número de carros\") +\n  theme_classic()\n\n\n\n\n\n\n13.1.2.2 Alterando a largura das barras\nO argumento width da função geom_bar() permite alterar a largura das barras do gráfico. Os valores desse argumento podem variar de 0 a 1.\n\nggplot(mpg, aes(x=drv)) +\n  geom_bar(width = 0.2) +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Número de carros\") +\n  theme_classic()\n\n\n\n\n\n\n13.1.2.3 Criando um eixo de percentual\nPodemos também mudar o eixo vertical para percentual ao inves de números absolutos.\nPara que o gráfico de barras use percentuais é preciso:\n1. calcular os percentuais.\n2. colocar esses percentuais num novo dataset. 3. usar esse dataset como argumento da função ggplot 4. incluir a variável com os percentuais nos argumentos do ggplot.\n5. finalmente, será preciso incluir o argumento stat = \"identity\" dentro da função geom_bar(), como mostrado abaixo:\n\n# criando uma dataset com os dados percentuais:\nnewdataset <-  mpg %>% \n                 count(drv) %>% \n                 mutate(perc = n / nrow(mpg)) \nnewdataset\n\n# A tibble: 3 × 3\n  drv       n  perc\n  <fct> <int> <dbl>\n1 r        25 0.107\n2 4       103 0.440\n3 f       106 0.453\n\n\nVeja que o novo dataset (newdataset) tem apenas 3 variáveis agora, drv, n e perc.\n\n# observe que os resultados foram colocados num outro dataset, chamado newdataset, para não alterar o dataset original.\n# no código abaixo foi usado o novo dataset, newdataset, que contém a nova variável \"perc\".\n\nggplot(newdataset, aes(x=drv, y=perc)) +\n  geom_bar(width = 0.5, stat = \"identity\") +\n  labs(title = \"Tipo de tração e Tipo de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Tipo de tração\", \n       y = \"Percentual de carros\") +\n  theme_classic()\n\n\n\n\n\n\n\n13.1.3 Histograma\nVamos agora ver como criar um histograma, um gráfico comum para analisar visualmente a distribuição de uma variável numérica, útil para visualizar a forma, centro e dispersão dos dados, além de identificar quaisquer valores discrepantes ou lacunas.\nUm histograma representa a distribuição dos valores de dados dividindo a faixa de valores em intervalos ou bins de tamanho igual, exibindo a frequência ou contagem em cada intervalo, geralmente representada pela altura ou comprimento das barras. A largura dos bins pode afetar a aparência do histograma e a interpretação dos dados. Bins estreitos podem criar uma visão mais detalhada, enquanto bins mais largos podem suavizar a distribuição.\nA função do ggplot para plotar um histograma é o geom_histogram().\nComo exemplo, vamos continuar usando o dataset mpg, analisando agora as variáveis hwy (quantidade de milhas percorridas com 1 galão de combustível quando rodando em estradas) e cty (quantidade de milhas percorridas com 1 galão de combustível quando rodando na cidade).\n\nlibrary(ggplot2)\nggplot(mpg, aes(x=hwy)) +\n  geom_histogram() \n\n\n\n\nO R mostrou um aviso indicando que usou 30 barras (bins=30) e que você pode ajustar isso conforme achar melhor.\n\n13.1.3.1 Número de barras\nPodemos melhorar esse gráfico ajustando para 15 barras, e também inserindo o título, subtítulo, notas de rodapé e usando o tema clássico, como já discutimos anteriormente.\n\nggplot(mpg, aes(x=hwy)) +\n  geom_histogram(bins = 15) +\n  labs(title = \"Milhas percorridas na estrada com um galão de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Milhas\", \n       y = \"Número de carros\") +\n  theme_classic()\n\n\n\n\n\n\n13.1.3.2 Cores das barras\nPodemos mudar as cores usadas com os argumentos col e fill. O argumento col indica a cor do contorno das barras e o argumento fill indica a cor interna das barras. Vamos refazer o gráfico com barras azul escuras e contornos azul claros. Observe também que os nomes das cores vem entre aspas.\n\nggplot(mpg, aes(x=hwy)) +\n  geom_histogram(bins = 15, col=\"darkblue\", fill=\"lightblue\") +\n  labs(title = \"Milhas percorridas na estrada com um galão de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Milhas\", \n       y = \"Número de carros\") +\n  theme_classic()\n\n\n\n\n\n\n13.1.3.3 Agrupando histogramas\nPodemos, assim como fizemos com gráficos de barras, plotar diversos histogramas, um para cada grupo de carros, conforme desejarmos. Por exemplo, se desejarmos plotar histogramas separados para cada tipo de tração (variável drv) basta usarmos uma linha no código.\n\nggplot(mpg, aes(x=hwy)) +\n  geom_histogram(bins = 15, col=\"darkblue\", fill=\"lightblue\") +\n  labs(title = \"Milhas percorridas na estrada com um galão de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Milhas\", \n       y = \"Número de carros\") +\n  theme_classic() + \n  facet_grid(~drv)\n\n\n\n\n\n\n\n13.1.4 Gráfico de densidade\nVamos agora ver como criar um gráfico de densidade, um gráfico também comum para analisar visualmente a distribuição de uma variável numérica, útil para visualizar a forma, centro e dispersão dos dados, além de identificar quaisquer valores discrepantes ou lacunas.\nUm gráfico de densidade, também conhecido como gráfico de densidade de kernel, representa a distribuição dos valores de dados criando uma curva suave que aproxima a função de densidade de probabilidade subjacente, mostrando a concentração ou densidade de pontos de dados em diferentes valores, em vez da frequência ou contagem como num histograma. Gráficos de densidade não utilizam bins fixos como os histogramas, mas estimam a densidade usando técnicas matemáticas, como a estimativa de densidade do kernel. Sua vantagem é que fornecem uma visualização contínua da distribuição, permitindo uma compreensão mais detalhada da forma, picos e vales dos dados.\nEles são especialmente úteis para visualizar padrões em dados contínuos, identificar modas ou agrupamentos e comparar distribuições entre diferentes grupos.\nA função do ggplot para plotar um gráfico de densidade é o geom_density().\nComo exemplo, vamos continuar usando o dataset mpg, analisando agora as variáveis hwy (quantidade de galões o carro consome quando rodando em estradas) e cty (quantidade de galões o carro consome quando rodando na cidade).\n\nlibrary(ggplot2)\nggplot(mpg, aes(x=hwy)) +\n  geom_density() \n\n\n\n\n\n13.1.4.1 Estratificando com col e fill\nPodemos estratificar o gráfico através do argumento col e fill. O argumento col indica a cor do contorno das linhas e o argumento fill indica a cor interna das linhas. Preste atenção que esses argumentos estão dentro da estética do geom_density, ou seja, dentro do argumento aes().\nUsando o argumento col=drv, para colorir as linhas de acordo com o tipo de tração.\n\nggplot(mpg, aes(x=hwy)) +\n  geom_density(aes(col=drv)) +\n  labs(title = \"Milhas percorridas na estrada com um galão de combustível\",\n       subtitle = \"de acordo com o tipo de tração do carro\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Milhas\", \n       y = \"Número de carros\") +\n  theme_classic()\n\n\n\n\nUsando o argumento fill=drv, para colorir preencher a densidade de acordo com o tipo de tração.\n\nggplot(mpg, aes(x=hwy)) +\n  geom_density(aes(fill=drv), alpha=0.5) +\n  labs(title = \"Milhas percorridas na estrada com um galão de combustível\",\n       subtitle = \"de acordo com o tipo de tração do carro\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Milhas\", \n       y = \"Número de carros\") +\n  theme_classic()\n\n\n\n\n\n\n13.1.4.2 Agrupando gráficos de densidade\nPodemos, assim como fizemos com gráficos de barras e histogramas, plotar diversos gráficos de densidade um para cada grupo de carros, conforme desejarmos. Por exemplo, se desejarmos plotar separados para cada tipo de tração (variável drv) basta usarmos uma linha no código.\n\nggplot(mpg, aes(x=c(hwy))) +\n  geom_density(aes(fill=drv), alpha = 0.5) +\n  labs(title = \"Milhas percorridas na estrada com um galão de combustível\",\n       subtitle = \"de acordo com o tipo de tração do carro\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Milhas\", \n       y = \"Número de carros\") +\n  theme_classic() + \n  facet_grid(~drv)\n\n\n\n\n\n\n\n13.1.5 Boxplot ou diagrama de caixas\nUm boxplot, também conhecido como diagrama de caixa, é uma maneira de visualizar a distribuição de dados numéricos e identificar medidas estatísticas importantes, numa representação gráfica simples e compacta (Massart et al. 2005).\nUm boxplot é composto por um retângulo, conhecido como “caixa”, dividido em três partes: a mediana (valor que divide o conjunto de dados em duas partes iguais), o primeiro quartil (Q1) e o terceiro quartil (Q3). Além disso, o boxplot possui “hastes” que se estendem a partir da caixa. Essas hastes mostram a dispersão dos dados fora da faixa interquartil (Q1 a Q3). Elas são representadas por segmentos de linha que terminam em “pontos” ou “outliers”, que são valores que estão significativamente distantes dos demais.\nO boxplot permite identificar rapidamente informações estatísticas como a mediana, a amplitude interquartil, os valores mínimo e máximo e a presença de valores discrepantes. Ele também ajuda a entender a simetria ou assimetria da distribuição dos dados e se existem valores discrepantes que podem afetar a interpretação geral.\nUm Boxplot também facilita a comparação entre diferentes conjuntos numéricos dada a simplicidade do gráfico.\nA função do ggplot para construir um boxplot é o geom_boxplot().\nComo exemplo, vamos continuar usando o dataset mpg, analisando agora as variáveis hwy (quantidade de galões o carro consome quando rodando em estradas) e, em seguida, cty (quantidade de galões o carro consome quando rodando na cidade).\n\nlibrary(ggplot2)\nggplot(mpg, aes(x=hwy)) +\n  geom_boxplot() \n\n\n\n\nDa mesma forma que fizemos antes, podemos incluir facilmente o título, subtítulo, notas de rodapé e legendas dos eixos e indicar o tema clássico para o gráfico.\n\nggplot(mpg, aes(x=hwy)) +\n  geom_boxplot() +\n   labs(title = \"Milhas percorridas na estrada com um galão de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Milhas\") +\n  theme_classic() \n\n\n\n\n\n13.1.5.1 Colorindo um boxplot\nPodemos definir a cor de um boxplot com os argumentos col e fill, como mostrado abaixo. Observe que os argumentos col e fill no exemplo abaixo não estão dentro da estética do boxplot, ou seja, não estão dentro do parenteses do aes(). Observe também que os nomes das cores vem entre aspas.\n\nggplot(mpg, aes(x=hwy)) +\n  geom_boxplot(col=\"darkblue\", fill=\"lightblue\") +\n   labs(title = \"Milhas percorridas na estrada com um galão de combustível\",\n       subtitle = \"234 Carros populares de 1998 a 2008\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Milhas\") +\n  theme_classic() \n\n\n\n\n\n\n13.1.5.2 Estratificando um boxplot\nPodemos estratificar o boxplot através de duas formas:\n\nIndicando uma variável categórica para o eixo y.\nCom os argumentos col e fill dentro da estética do boxplot.\n\nNo exemplo abaixo, foi acrescentado o eixo y sendo o tipo de tração do carro: y=drv. Veja o código e o resultado.\n\nggplot(mpg, aes(x=hwy, y=drv)) +\n  geom_boxplot() +\n   labs(title = \"Milhas percorridas na estrada com um galão de combustível\",\n       subtitle = \"de acordo com o tipo de tração do carro\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Milhas\") +\n  theme_classic() \n\n\n\n\nPodemos estratificar o boxplot através do argumento col e fill dentro da estética do boxplot. O argumento col indica a cor do contorno das linhas e o argumento fill indica a cor interna das linhas. Preste atenção que esses argumentos estão dentro da estética do geom_boxplot, ou seja, dentro do argumento aes().\n\nggplot(mpg, aes(x=hwy)) +\n  geom_boxplot(aes(fill=drv)) +\n   labs(title = \"Milhas percorridas na estrada com um galão de combustível\",\n       subtitle = \"de acordo com o tipo de tração do carro\",\n       caption = \"fonte: dataset mgp do ggplot2\",\n       x = \"Milhas\") +\n  theme_classic() \n\n\n\n\n\n\n\n13.1.6 Gráfico de dispersão ou Scatter Plot\nUm scatter plot, também conhecido como gráfico de dispersão ou gráfico de pontos, é uma representação visual que mostra a relação entre duas variáveis numéricas, plotando pontos em um gráfico cartesiano, onde cada ponto representa uma observação das duas variáveis.\nNo eixo horizontal do scatter plot, geralmente é representada a variável independente, também chamada de variável explicativa ou preditora. No eixo vertical, é representada a variável dependente, também conhecida como variável resposta ou resultado.\nCada ponto no scatter plot representa um par de valores das duas variáveis. A posição do ponto no gráfico é determinada pelos valores correspondentes das variáveis nos eixos horizontal e vertical. Dessa forma, é possível visualizar a relação entre as variáveis e identificar padrões ou tendências.\nÉ possível também acrescentar uma linha que melhor se ajusta aos pontos, para facilitar a leitura da tendência dos dados.\na função para esse tipo de gráfico e geom_point().\nVamos mudar um pouco o conjunto de dados e analisar o dataset diamonds do ggplot.\nO dataset diamonds é um conjunto de dados da biblioteca ggplot2, contendo informações sobre características e preços de quase 54.000 diamantes. Esse dataset é frequentemente utilizado para demonstrar e exemplificar técnicas de visualização de dados, como a criação de scatter plots, boxplots e outras representações gráficas. Ele permite explorar relações entre as características dos diamantes, como seu peso, qualidade do corte, cor, clareza e preço.\nAs variáveis desse dataset são:\ncarat: Peso do diamante em quilates.\ncut: Qualidade do corte do diamante, representada por categorias como:\n“Fair” (ruim), “Good” (bom), “Very Good” (muito bom), “Premium” (premium) e “Ideal” (ideal).\ncolor: Cor do diamante, representada por letras de “D” (incolor) a “J” (ligeiramente amarelado).\nclarity: Clareza do diamante, representada por categorias como:\n“I1” (inclusões visíveis)\n“SI2” (inclusões pequenas visíveis)\n“SI1” (inclusões pequenas)\n“VS2” (inclusões muito pequenas)\n“VS1” (inclusões muito pequenas difíceis de ver)\n“VVS2” (inclusões muito, muito pequenas difíceis de ver) e\n“VVS1” (inclusões muito, muito pequenas quase impossíveis de ver)\n“IF” (sem inclusões visíveis).\ndepth: Profundidade total do diamante, calculada como a divisão da altura pelo diâmetro médio.\ntable: Largura da parte superior do diamante em relação à parte mais larga.\nprice: Preço do diamante em dólares.\nx, y, z: Dimensões do diamante em milímetros.\nVamos criar um gráfico de dispersão para analisar as relação entre o peso do diamante (variável carat) e seu preço (variável price).\n\nlibrary(ggplot2)\nggplot(diamonds, aes(x=price, y=carat)) +\n  geom_point()\n\n\n\n\nPodemos inserir a reta de regressão num scatter plot com o seguinte comando\n\nlibrary(ggplot2)\nggplot(diamonds, aes(x=price, y=carat)) +\n  geom_point() +\n  geom_smooth(method='lm', formula= y~x)\n\n\n\n\n\n\n13.1.7 Conclusão\nNeste capítulo, exploramos a poderosa funcionalidade do pacote ggplot2 para a criação de gráficos no R. Aprendemos sobre a gramática dos gráficos proposta por Leland Wilkinson e como essa gramática é implementada no ggplot2 para permitir a construção de visualizações complexas e customizáveis.\nVimos como definir um conjunto de dados, mapear variáveis estéticas e adicionar diferentes camadas geométricas para criar uma variedade de gráficos, incluindo gráficos de barras, histogramas, gráficos de densidade, boxplots e scatter plots. Também abordamos como personalizar esses gráficos, ajustando cores, títulos, legendas e temas, para que eles possam ser adaptados às necessidades específicas de análise e apresentação.\nA flexibilidade do ggplot2 e sua integração com o tidyverse tornam-no uma ferramenta indispensável para qualquer cientista de dados ou estatístico que trabalhe com o R. Espero que os exemplos e explicações fornecidos aqui tenham proporcionado uma base sólida para você explorar ainda mais as capacidades deste pacote e criar visualizações informativas e visualmente agradáveis para os seus dados.\nCom a compreensão dos conceitos e práticas abordadas, você estará bem equipado para utilizar o ggplot2 em suas análises e comunicações de dados, contribuindo para uma interpretação mais clara e eficaz dos seus resultados."
  },
  {
    "objectID": "12-Ploting_graphics.html#gráficos-do-r-base",
    "href": "12-Ploting_graphics.html#gráficos-do-r-base",
    "title": "13  Gráficos",
    "section": "13.2 Gráficos do R Base",
    "text": "13.2 Gráficos do R Base\nO R base é um sistema de gráficos mais simples com diversas funções para criar visualizações de forma simples e rápida, sendo uma alternativa ao ggplot2 para a criação de gráficos, especialmente para usuários que preferem uma abordagem mais direta e menos detalhada.\nAs principais funções do R base para a criação de gráficos são:\n- plot() - uma função genérica e versátil para criar uma variedade de gráficos, incluindo scatter plots, line plots, bar plots, box plots e outros tipos de gráficos.\n- hist() - para criar histogramas.\n- boxplot() - para criar boxplots.\n- barplot() - para criar gráficos de barras.\n- pie() - para criar gráficos de pizza (também chamado de gráfico de setores ou de torta).\n\nVamos ver como criar gráficos com essas funções.\n\n13.2.1 Gráficos com plot()\nA função plot() é uma função genérica que pode ser usada para criar uma variedade de gráficos, dependendo dos argumentos fornecidos. Ela é uma das funções mais versáteis do R base e pode ser usada para criar bar plots, density plots, scatter plots, boxplots e line plots. Vamos ver como plot funciona dependendo do tipo de argumentos fornecidos. Para exemplificar o uso de plot() vamos usar o dataset diamonds do pacote ggplot2.\nDigite ?diamonds no console para ter informações sobrbe esse dataset\n\n13.2.1.1 Gráfico de barras com plot()\nPara construir um gráfico de barras com a função plot(), basta fornecer um vetor categórico como argumento. Por exemplo, vamos criar um gráfico de barras para analisar a distribuição das cores dos diamantes (variável color). As cores dos diamentes variam de D (melhores) to J (piores).\n\n# Carrregando o pacote ggplot2\nlibrary(ggplot2)\n# Criando um gráfico de barras\nplot(diamonds$color)\n\n\n\n\n\n\n13.2.1.2 Gráfico de Densidade com plot()\nPara criar um gráfico de densidade com a função plot(), precisamos primeiro calcular a densidade dos dados usando a função density(). Em seguida, podemos plotar a densidade dos dados usando a função plot(). Ao fornecer como argumento a densidade dos pontos, a função plot automaticamente irá gerar um gráfico de densidade. Por exemplo, vamos criar um gráfico de densidade para analisar a distribuição dos preços dos diamantes (variável price).\n\n# Carrregando o pacote ggplot2\nlibrary(ggplot2)\n\n# Calculando a densidade dos preços dos diamantes\nd <- density(diamonds$price)\n\n# Criando um gráfico de densidade\nplot(d)\n\n\n\n\n\n\n13.2.1.3 Scatter plot com plot()\nPara criar um scatter plot com a função plot(), basta fornecer duas variáveis numéricas como argumentos para os eixos x e y. Por exemplo, vamos criar um scatter plot para analisar a relação entre o preço do diamante (variável price) e seu peso em quilates (variável carat).\n\n# Carrregando o pacote ggplot2\nlibrary(ggplot2)\n# Criando um scatter plot\nplot(diamonds$price, diamonds$carat)\n\n\n\n\n\n\n13.2.1.4 Boxplot com plot()\nPara criar um boxplot com a função plot(), basta fornecer uma variável numérica e uma categórica como argumento. Podemos usar o operador de fórmula ~ ou então inserir as duas variáveis separadamente. Por exemplo, vamos criar um boxplot para analisar a distribuição dos preços dos diamantes (variável price) em cada grupo tipo de corte do diamante (variável cut).\n\n# boxplot usando inserindo os argumentos separadamente para cada eixo.\n# eixo x com variáveis categórica cut\n# eixo y com variável numérica price\nplot(y=diamonds$price,x=diamonds$cut)\n\n\n\n\n\n# boxplot usando plot() usando a notação de formula ~\n# pode ser lido como \"price\" em função de \"cut\"\nplot(price ~ cut, data = diamonds)\n\n\n\n\n\n\n13.2.1.5 Line plot com plot()\nPara criar um line plot com a função plot(), basta fornecer dois vetores numéricos como argumentos para os eixos x e y. Para exemplo, vamos criar uma função \\(y=x^2\\) e criar um conjunto de valores numéricos para x e y. Podemos então criar um line plot para visualizar a relação entre x e y usando o operador de função ~ com a sintaxe y ~ x, ou seja, y em função de x.\n\n# Criando um vetor de valores para x\nx <- seq(1, 100, by = 0.1)\n# Criando um vetor de valores para y\ny <- x^2\n# Criando um line plot\nplot(y ~ x, type = \"l\")\n\n\n\n\n\n\n\n13.2.2 Histograma com hist()\nA função hist() é usada para criar histogramas no R, que são gráficos que mostram a distribuição de uma variável numérica em intervalos ou bins. A função hist() divide os valores da variável em intervalos e conta o número de observações em cada intervalo, criando barras que representam a frequência ou contagem de observações em cada intervalo.\nVamos ver como criar um histograma para analisar a distribuição dos preços dos diamantes (variável price).\n\n# Carrregando o pacote ggplot2\nlibrary(ggplot2)\n# Criando um histograma\nhist(diamonds$price)\n\n\n\n\n\n\n13.2.3 Boxplot com boxplot()\nA função boxplot() é usada para criar boxplots no R, que são gráficos que mostram a distribuição de uma variável numérica em relação a uma variável categórica. Os boxplots são úteis para visualizar a mediana, quartis, valores mínimos e máximos, e identificar valores discrepantes ou outliers.\nVamos ver como criar um boxplot para analisar a distribuição dos preços dos diamantes (variável price) em cada grupo tipo de corte do diamante (variável cut). Vamos usar a mesma notação de fórmula ~ para indicar a relação entre as variáveis.\n\n# Carrregando o pacote ggplot2\nlibrary(ggplot2)\n# Criando um boxplot\nboxplot(price ~ cut, data = diamonds)\n\n\n\n\n\n\n13.2.4 Gráfico de barras com barplot()\nA função barplot() é usada para criar gráficos de barras no R, que são gráficos que mostram a distribuição de uma variável categórica em relação a uma variável numérica. Os gráficos de barras são úteis para visualizar a frequência ou contagem de observações em cada categoria da variável categórica. Vamos ver como estão distribuídas os diamantes de acoerd com a cor. Lembre-se que as cores dos diamentes variam de D (melhores) to J (piores). Observe que ao usar barplot() e necessário inserir como argumento a função table() para contar a frequência de cada cor, o R automaticamente ordena as cores em ordem alfabética. Compare com o gráfico de barras criado com plot() e veja como foi mais simples usar plot(), pois nõa foi preciso usar a função table().\n\n# Carrregando o pacote ggplot2\nlibrary(ggplot2)\n# Criando um gráfico de barras\nbarplot(table(diamonds$color))\n\n\n\n\n\n\n13.2.5 Gráfico de pizza com pie()\nA função pie() é usada para criar gráficos de pizza no R, que são gráficos circulares que mostram a distribuição de uma variável categórica em relação ao todo. Os gráficos de pizza são úteis para visualizar a proporção de cada categoria em relação ao total. Vamos ver como criar um gráfico de pizza para analisar a distribuição das cores dos diamantes (variável color). Lembre-se que as cores dos diamentes variam de D (melhores) to J (piores).\n\n# Carrregando o pacote ggplot2\nlibrary(ggplot2)\n\n# Criando um gráfico de pizza\npie(table(diamonds$color))\n\n\n\n\n\n\n13.2.6 Customizando Gráficos do R Base\nOs gráficos do R base são altamente customizáveis e permitem ajustar diversos aspectos visuais, como cores, títulos, legendas, eixos, margens, fontes e muito mais. Para ajustar um gráfico do R base, é necessário usar uma combinação de funções para alterar diferentes aspectos do gráfico. Isso geralmente é realizado de forma muito mais intuitiva com o ggplot2. Ou seja, se você pretende customizar seus gráfico, sugiro usar o pacote ggplot2.\nEntretanto, se você desejar usar o R base, é possível customizar os gráficos de várias maneiras, como mostrado abaixo.\n\n13.2.6.1 Cores\nPara alterar as cores de um gráfico do R base, você pode usar o argumento col ou col.axis para alterar a cor dos pontos, linhas, eixos, rótulos e outros elementos do gráfico. Por exemplo, vamos alterar a cor dos pontos de um scatter plot para vermelho. Digite colors() no console para ver a lista das 667 cores disponíveis no R.\n\n# Criando um scatter plot\nplot(diamonds$price, diamonds$carat, col = \"red\")\n\n\n\n\nAlém dessas cores, é possível instalar pacotes de paletas de cores no R. Existem vários pacotes disponíveis no CRAN que fornecem paletas de cores adicionais para uso em gráficos. Alguns exemplos populares incluem os pacotes RColorBrewer, viridis, ggsci e ggthemes. Para instalar um pacote de paletas de cores, você pode usar a função install.packages() e depois carregar o pacote com a função library().\n\n\n13.2.6.2 Títulos e rótulos dos eixos\nPara adicionar títulos e legendas a um gráfico do R base, usamos as funções main(), sub(), xlab() e ylab() para adicionar títulos, subtítulos e rótulos aos eixos x e y. Por exemplo, vamos adicionar um título e rótulos aos eixos x e y de um scatter plot.\n\n# Criando um scatter plot\nplot(diamonds$price, diamonds$carat, \n     main = \"Relação entre preço e peso do diamante\", # adiciona um título\n     sub = \"usando dataset diamond do ggpplot2\",      # adiciona um subtítulo\n     xlab=\"Preço do diamante\",                        # adiciona um nome ao eixo x\n     ylab=\"Peso do diamante\")                         # adiciona um nome ao eixo y\n\n\n\n\n\n\n13.2.6.3 Tamanho, forma e cores dos pontos\nPara ajustar o tamanho, forma e cores dos pontos de um gráfico do R base, podemos usar os argumentos cex, pch e col. Por exemplo, vamos alterar o tipo de ponto para um círculo preenchido (pch=20), reduzir o tamanho dos pontos para 50% (cex = 0.5) e definir a cor dos pontos para azul (col = \"blue\") em um scatter plot.\n\n# Criando um scatter plot\nplot(diamonds$price, diamonds$carat, \n     pch=6,                                           # altera o tipo de ponto\n     cex = 0.5,                                       # ajusta o tamanho dos pontos\n     col = \"blue\",                                    # altera a cor dos pontos para azul\n     main = \"Relação entre preço e peso do diamante\", # adiciona um título\n     sub = \"usando dataset diamond do ggpplot2\",      # adiciona um subtítulo\n     xlab=\"Preço do diamante\",                        # adiciona um nome ao eixo x\n     ylab=\"Peso do diamante\")                         # adiciona um nome ao eixo y\n\n\n\n\nO argumento pch é usado para alterar o tipo de ponto, onde pch=20 representa um círculo preenchido. A tabela abaixo mostra os tipos possíveis e os valores correspondentes para pch. Experimente alterar os valores entre 1 e 25 para ver os diferentes tipos de pontos.\n\n\n13.2.6.4 Espessura e tipo de linha\nPara alterar a espessura e o tipo de linha de um gráfico do R base, podemos usar os argumentos lwd e lty. O argumento lwd é usado para alterar a largura da linha, enquanto o argumento lty é usado para alterar o tipo de linha. Por exemplo, vamos alterar a espessura da linha para 2 e o tipo de linha para tracejado (lty=2). VAmos usar o gráfico de linhas que tínhamos feito anteriormente. Experimente alterar os valores de lwd e lty para ver os diferentes tipos de linhas.\n\n# Criando um vetor de valores para x\nx <- seq(1, 100, by = 0.1)\n# Criando um vetor de valores para y\ny <- x^2\n# Criando um line plot\nplot(y ~ x, \n     type = \"l\",    # cria um gráfico de linhas   \n     col = \"blue\",  # altera a cor da linha para azul\n     lwd = 2,       # altera a espessura da linha\n     lty = 2)       # altera o tipo de linha para tracejado)\n\n\n\n\n\n\n13.2.6.5 Legendas e margens\nPara adicionar legendas e ajustar as margens de um gráfico do R base, podemos usar as funções legend() e par(). A função legend() é usada para adicionar uma legenda ao gráfico, enquanto a função par() é usada para ajustar os parâmetros gráficos, como as margens internas e externas do gráfico. Por exemplo, vamos adicionar uma legenda ao canto superior direito de um scatter plot e ajustar as margens do gráfico.\n\n# Criando um scatter plot\nplot(diamonds$price, diamonds$carat, \n     pch=20,                                           # altera o tipo de ponto\n     cex = 0.5,                                       # ajusta o tamanho dos pontos\n     col = \"blue\",                                    # altera a cor dos pontos para azul\n     main = \"Relação entre preço e peso do diamante\", # adiciona um título\n     sub = \"usando dataset diamond do ggpplot2\",      # adiciona um subtítulo\n     xlab=\"Preço do diamante\",                        # adiciona um nome ao eixo x\n     ylab=\"Peso do diamante\")                         # adiciona um nome ao eixo y\n\n# Adicionando uma legenda ao canto superior direito\nlegend(\"topright\", legend = \"Diamantes\", col = \"black\", pch = 20)\n\n\n\n# Ajustando as margens do gráfico\npar(mar = c(5, 5, 4, 2) + 0.1)\n\n\n\n13.2.6.6 Estratificando os dados de acordo com uma variável categórica\nPara estratificar os dados de acordo com uma variável categórica em um gráfico do R base, podemos especificar as cores ou tipos de pontos de acordo com a variável categórica. Por exemplo, vamos criar um scatter plot para analisar a relação entre o preço do diamante (variável price) e seu peso em quilates (variável carat), estratificando os dados de acordo com a qualidade do corte do diamante (variável cut). Para isso precisamos definir o argumento col como a variável cut. Será preciso usar diamonds$cut para que o R entenda que cut é uma variável do dataset diamonds.\n\nplot(diamonds$price, diamonds$carat, \n     pch=20,                                          # altera o tipo de ponto\n     cex = 0.5,                                       # ajusta o tamanho dos pontos\n     col = diamonds$cut,                              # altera a cor dos pontos para azul\n     main = \"Relação entre preço e peso do diamante\", # adiciona um título\n     sub = \"usando dataset diamond do ggpplot2\",      # adiciona um subtítulo\n     xlab=\"Preço do diamante\",                        # adiciona um nome ao eixo x\n     ylab=\"Peso do diamante\")                         # adiciona um nome ao eixo y\n\n\n\n\n\n\n13.2.6.7 Agrupando gráficos\nO R permite agrupar diversos gráficos numa única janela, facilitando a comparação entre diferentes visualizações. O comando par() define parâmetros gerais do agrupamento. O argumento mfrow=c(2,2) define como serão exibidos os gráficos. Nesse caso, serão 2 linhas e 2 colunas. Vamos criar um boxplot, um histograma, um scatter plot e um gráfico de pizza para analisar diferentes aspectos dos dados dos diamantes e agrupá-los em um único gráfico emparelhado numa matrix 2x2.\n\n# Carrregando o pacote ggplot2\nlibrary(ggplot2)\n# usado par para que os gráficos sejam exibidos emparelhados, 2 linhas, 2 colunas\npar(mfrow=c(2,2))\n# Criando um boxplot\nboxplot(price ~ cut, data = diamonds)\n# Criando um histograma\nhist(diamonds$price)\n# Criando um scatter plot\nplot(diamonds$price, diamonds$carat)  \n# Criando um gráfico de pizza\npie(table(diamonds$color))\n\n\n\n\n\n\n\n13.2.7 Conclusão\nComo vimos o R possui dois grandes sistemas de gráficos: o R base e o ggplot2. O R base é um sistema de gráficos mais simples e direto, com funções simples para gerar gráficos de forma rápida com o R base. Entretanto, essas as funções básicas são menos customizáveis e menos flexíveis do que os gráficos gerados com o pacote ggplot2. O ggplot2 é um sistema bastante sofisticado, possibilitando a criação de gráficos complexos e customizáveis, sendo baseado numa gramática de gráficos que permite a construção de camadas de visualizações, detalhadas e informativas.\nA forma de construir gráficos com o ggplot2 é bastante intuitiva e, com pouco de prática, você certamente irá preferir o ggplot2 para a criação de seus gráficos.\n\n\n\n\nMassart, Desire, Johanna Verbeke, Xavier Capron, and Karin Schlesier. 2005. “Visual Presentation of Data by Means of Box Plots.” Journal Article. Lc-Gc Europe 18: 2–5."
  },
  {
    "objectID": "13-Statistical_Analysis.html#testes-de-normalidade",
    "href": "13-Statistical_Analysis.html#testes-de-normalidade",
    "title": "14  Análises Estatísticas",
    "section": "14.1 Testes de Normalidade",
    "text": "14.1 Testes de Normalidade\nA normalidade dos dados é uma das premissas dos testes estatísticos paramétricos. A normalidade dos dados pode ser avaliada visualmente através de gráficos de densidade e de histograma, através de gráficos como o QQ plot (quantile–quantile plot), ou através de testes estatísticos. Neste capítulo vamos apresentar como fazer os gráficos Q-Q plot e como implementar no R os testes de normalidade de Shapiro-Wilk e Kolmogorov-Smirnov.\n\n14.1.1 QQ plot\nUm QQ plot, abreviação de “quantile-quantile plot”, é geralmente usado para avaliar se um conjunto de dados segue ou não uma distribuição normal. Um QQ plot é um gráfico de dispersão (scatter plot) criado plotando dois conjuntos de quantis um contra o outro. Os gráficos QQ classificam os dados da amostra em ordem crescente e, em seguida, plotam esses pontos contra quantis calculados a partir de uma distribuição teórica. Embora os gráficos QQ normais sejam os mais usados na prática devido a tantos métodos estatísticos que assumem normalidade, os gráficos QQ podem ser usados para qualquer distribuição. Se ambos os conjuntos de quantis vieram da mesma distribuição, devemos ver os pontos formando uma linha que é aproximadamente reta.\nNum gráfico QQ plot normal os pontos fornecem uma indicação da normalidade do conjunto de dados. Se os dados forem normalmente distribuídos, os pontos cairão na linha de diagonal de 45 graus. Por outro lado, quanto mais os pontos se desviam dessa diagonal, menor a probabilidade de o conjunto de dados seguir uma distribuição normal.\nO código abaixo mostra como fazer um gráfico Q-Q plot no R. Primeiro, geramos um conjunto de dados que segue uma distribuição normal e, em seguida, fazemos o gráfico QQ plot normal. Observe como os pontos se aproximam da linha de referência.\n\n# Definindo a semente para reprodutibilidade\nset.seed(1)\n\n# Gerando os dados distribuidos de forma normal \ndados <- rnorm(100)\n\n# Gráfico Q-Q plot  \nqqnorm(dados) # Gráfico Q-Q plot\nqqline(dados) # Adiciona a linha de referência\n\n\n\n\nVamos criar agora um conjunto de dados que não segue uma distribuição normal e fazer o gráfico Q-Q plot. Veja como os pontos se desviam da linha de referência.\n\n# Definindo a semente para reprodutibilidade\nset.seed(1)\n\n# Gerando os dados distribuidos de forma não normal\ndados_nao_normais <- rexp(100, rate = 1)\n\n# Gráfico Q-Q plot\nqqnorm(dados_nao_normais) # Gráfico Q-Q plot\nqqline(dados_nao_normais) # Adiciona a linha de referência\n\n\n\n\n\n\n14.1.2 Teste de Shapiro-Wilk\nO teste de Shapiro-Wilk é um teste estatístico utilizado para avaliar a normalidade dos dados. A hipótese nula do teste é que os dados seguem uma distribuição normal. Ou sejam, se o valor-p do teste for menor que o nível de significância, a hipótese nula é rejeitada, indicando que os dados não seguem uma distribuição normal. Por outro lado, se o valor-p for maior que o nível de significância, a hipótese nula não é rejeitada, indicando que os dados seguem uma distribuição normal.\nO argumento principal do teste de Shapiro-Wilk é o conjunto de dados que queremos testar. O resultado do teste é a estatística \\(W\\) e o valor-p. \\(W\\) indica o quão bem os dados se ajustam a uma distribuição normal. O valor \\(W\\) próximo a 1 indica que os dados provavelmente serão distribuídos normalmente, enquanto um valor significativamente menor que 1 sugere afastamento da normalidade. O valor-p é a probabilidade de obter um valor de W tão extremo quanto o observado, sob a hipótese nula de que os dados seguem uma distribuição normal.\nO código abaixo mostra como implementar o teste de Shapiro-Wilk no R. Primeiro, geramos um conjunto de dados que segue uma distribuição normal e, em seguida, fazemos o teste de Shapiro-Wilk. Como já sabemos que nossos dados tem uma distribuição normal, o valor-p desse teste deve ser maior que o nível de significância.\n\n# Definindo a semente para reprodutibilidade\nset.seed(1)\n\n# Gerando os dados distribuidos de forma normal\ndados <- rnorm(100)\n\n# Teste de Shapiro-Wilk\nshapiro.test(dados)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados\nW = 0.9956, p-value = 0.9876\n\n\nObserve que o valor-p foi realmente maior que o nível de significância, indicando que os dados seguem uma distribuição normal.\nVamos criar agora um conjunto de dados que não segue uma distribuição normal e fazer o teste de Shapiro-Wilk. Observe que o valor-p desse teste deve ser menor que o nível de significância.\n\n# Definindo a semente para reprodutibilidade\nset.seed(1)\n\n# Gerando os dados distribuidos de forma não normal\ndados_nao_normais <- rexp(100, rate = 1)\n\n# Teste de Shapiro-Wilk\n# note que o valor de p do teste de shapiro é mostrado em notação científica\nshapiro.test(dados_nao_normais)\n\n\n    Shapiro-Wilk normality test\n\ndata:  dados_nao_normais\nW = 0.82218, p-value = 1.263e-09\n\n# extraindo o valor de p do teste de shapiro\npvalue=shapiro.test(dados_nao_normais)$p.value\n\n# Imprimindo o valor de p por extenso\nprint(paste(\"p-value =\", format(pvalue, scientific = FALSE)))\n\n[1] \"p-value = 0.000000001262599\"\n\n\nComo previsto, o valor-p foi menor que o nível de significância, indicando que os dados não seguem uma distribuição normal.\n\n\n14.1.3 Teste de Kolmogorov-Smirnov\nO teste de Kolmogorov-Smirnov é um outro teste estatístico utilizado para avaliar a normalidade dos dados. Da mesma forma que o teste de Shapiro-Wilki, a hipótese nula do teste de de Kolmogorov-Smirnov é que os dados seguem uma distribuição normal. Ou sejam, se o valor-p do teste for menor que o nível de significância, a hipótese nula é rejeitada, indicando que os dados não seguem uma distribuição normal. Por outro lado, se o valor-p for maior que o nível de significância, a hipótese nula não é rejeitada, indicando que os dados seguem uma distribuição normal.\nO teste te Kolmorov-Smirnov também pode ser usado para testar se os dados vem de outras distribuições, pois o teste na verdade verifica se duas distribuições são iguais, ou seja, se uma amostra vem de uma distribuição em particular. Quando desejamos saber se a amostra tem uma distribuiçao normal, o teste de Kolmogorov-Smirnov compara a distribuição empírica dos dados com a distribuição teórica normal.\nO argumento principal do teste de Kolmogorov-Smirnov também é o conjunto de dados que queremos testar. Mas também precisamos especificar a distribuição teórica que queremos testar. No nosso caso isso será feito com a string “pnorm”, que indica que queremos testar se os dados seguem uma distribuição normal. Além disso precisamos também especificar os parâmetros da distribuição teórica, que no caso da distribuição normal são a média e o desvio padrão. O mais indicado é usar a média e o desvio padrão dos dados, como fizemos no exemplo abaixo.\nO resultado do teste é a estatística \\(D\\) e o valor-p. \\(D\\) é a maior diferença entre a função de distribuição acumulada empírica dos dados e a função de distribuição acumulada teórica. O valor-p é a probabilidade de obter um valor de \\(D\\) tão extremo quanto o observado, sob a hipótese nula de que os dados seguem uma distribuição normal.\nO código abaixo mostra como implementar o teste de Kolmogorov-Smirnov no R. Primeiro, geramos um conjunto de dados que segue uma distribuição normal e, em seguida, fazemos o teste de Kolmogorov-Smirnov. Como já sabemos que nossos dados tem uma distribuição normal, o valor-p desse teste deve ser maior que o nível de significância.\n\n# Definindo a semente para reprodutibilidade\nset.seed(1)\n\n# Gerando os dados distribuidos de forma normal\ndados <- rnorm(100)\n\n# Teste de Kolmogorov-Smirnov\nks.test(dados, \"pnorm\", mean = mean(dados), sd = sd(dados))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  dados\nD = 0.047014, p-value = 0.9799\nalternative hypothesis: two-sided\n\n\nObserve que o valor de p foi realmente maior que o nível de significância, indicando que os dados seguem uma distribuição normal.\nVamos criar agora um conjunto de dados que não segue uma distribuição normal e fazer o teste de Kolmogorov-Smirnov. Observe que o valor-p desse teste deve ser menor que o nível de significância.\n\n# Definindo a semente para reprodutibilidade\nset.seed(1)\n\n# Gerando os dados distribuidos de forma não normal\ndados_nao_normais <- rexp(100, rate = 1)\n\n# Teste de Kolmogorov-Smirnov\nks.test(dados_nao_normais, \"pnorm\", mean = mean(dados_nao_normais), sd = sd(dados_nao_normais))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  dados_nao_normais\nD = 0.15964, p-value = 0.01223\nalternative hypothesis: two-sided\n\n\nObserve que o valor-p foi menor que o nível de significância, indicando que os dados não seguem uma distribuição normal."
  },
  {
    "objectID": "13-Statistical_Analysis.html#correlação-linear",
    "href": "13-Statistical_Analysis.html#correlação-linear",
    "title": "14  Análises Estatísticas",
    "section": "14.2 Correlação Linear",
    "text": "14.2 Correlação Linear\nFrequentemente precisamos calcular numericamente a força e a direção da correlação entre duas variáveis. A medida estatística mais comum para mensurar a força e a direção da correlação entre duas variáveis numéricas é o Coeficiente de Correlação Linear de Pearson - denotado por r. Vale ressaltar que esse coeficiente só serve para analisar correlações lineares.\n\n14.2.1 cor() e cor.test()\nA linguagem R tem uma função específica para calcular o coeficiente de correlação linear de Pearson (r) entre duas variáveis numéricas: a função cor(). Para usar essa função basta inserir como argumentos as duas variáveis numéricas para as quais se deseja calcular o coeficiente. A ordem em que as variáveis são inseridas não faz diferença nesse cálculo.\nVamos testar essas funções no dataset mpg que já foi discutido em capítulos anteriores (Chapter 10). O código abaixo calcula o coeficiente de correlação linear de Pearson entre as cilindradas (displ) e o número de milhas percorridas com um galão na cidade (cty). A ordem da inserção desses argumentos não importa.\n\nlibrary(ggplot2) # necessário para usar o dataset mpg\ncor(mpg$displ, mpg$cty)\n\n[1] -0.798524\n\n\n\ncor(mpg$cty,mpg$displ)\n\n[1] -0.798524\n\n\nO valor encontrado cor(mpg$cty,mpg$displ) indica que essa é uma correlação negativa e forte. A mensagem é clara, quanto maior as cilindradas, menor a distância percorrida com 1 galão de gasolina, ou seja, carros 1.0 são mais econômicos mesmo.\nO valor coeficiente de determinação \\(r^2\\) pode ser obtido elevando-se a função cor() ao quadrado.\n\nr2 <- cor(mpg$displ, mpg$cty)^2\nr2\n\n[1] 0.6376405\n\n\nO intervalo de confiança e o valor de p associado ao coeficiente de correlação podem ser obtidos com a função cor.test().\n\ncor.test(mpg$cty,mpg$displ)\n\n\n    Pearson's product-moment correlation\n\ndata:  mpg$cty and mpg$displ\nt = -20.205, df = 232, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.8406782 -0.7467508\nsample estimates:\n      cor \n-0.798524 \n\n\nFrequentemente existem valores NA no conjunto de dados. Nesses casos a função cor() não conseguirá computar o valor do coeficiente de correlação, pois, por padrão, essa função só faz os cálculos se todos os pares de dados estiverem completos. Para calcular a correlação omitindo os pares incompletos é necessário ajustar o parâmetro use =, incluindo use = complete.obs.\nPara ilustrar essa situação, usaremos o dataset airquality do R, que contém dados NA em algumas de suas medições. Esse dataset contém dados de medições diárias da qualidade do ar em Nova Iorque de maio a setembro de 1973. São cerca de 154 observações e 6 variáveis numéricas: - Ozone (quantidade de ozônio)\n- Solar.R (radiação solar)\n- Wind (velocidade do vento)\n- Temp (temperatura - F)\n- Month (mês) - Day (dia)\nPodemos verificar a existência de valores NA com o comando summary()\n\nsummary(airquality)\n\n     Ozone           Solar.R           Wind             Temp      \n Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  \n 1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  \n Median : 31.50   Median :205.0   Median : 9.700   Median :79.00  \n Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88  \n 3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  \n Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  \n NA's   :37       NA's   :7                                       \n     Month            Day      \n Min.   :5.000   Min.   : 1.0  \n 1st Qu.:6.000   1st Qu.: 8.0  \n Median :7.000   Median :16.0  \n Mean   :6.993   Mean   :15.8  \n 3rd Qu.:8.000   3rd Qu.:23.0  \n Max.   :9.000   Max.   :31.0  \n                               \n\n\nDevido as valores NA nas variáveis Ozone e Solar.R, a função cor() não calcula o coeficiente de correlação:\n\ncor(airquality$Ozone, airquality$Solar.R)\n\n[1] NA\n\n\nPara obter o resultado desejado, precisamos incluir o argumento use = \"complete.obs\"\n\ncor(airquality$Ozone, airquality$Solar.R, use = \"complete.obs\")\n\n[1] 0.3483417\n\n\nA inclusão desse argumento faz com que a função cor() exclua dos cálculos os valores NA. O mesmo resultado pode ser obtido se excluirmos esses valores antes de usar a função.\nPara demonstrar isso, vamos excluir esses valores com a função drop_na()do pacote tidyr, parte do tidyverse. Criaremos um novo data frame com o nome air2.\n\nlibrary(tidyr)\nair2 <- airquality |> \n        drop_na()\n\ncor(air2$Ozone, air2$Solar.R)\n\n[1] 0.3483417\n\n\nA função cor.test() já faz essa exclusão dos dados NA por padrão, não sendo necessária sua exclusão nem o uso do argumento use = \"complete.obs\".\n\ncor.test(airquality$Ozone, airquality$Solar.R)\n\n\n    Pearson's product-moment correlation\n\ndata:  airquality$Ozone and airquality$Solar.R\nt = 3.8798, df = 109, p-value = 0.0001793\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.173194 0.502132\nsample estimates:\n      cor \n0.3483417 \n\n\n\n\n14.2.2 pairs() e ggpairs()\nPodemos usar a função pairs() para visualizar rapidamente todas as correlações entre as variáveis de um dataset. Vamos testar essa função no dataset iris do ggplot.\nEste conjunto de dados fornece as medidas em centímetros das variáveis comprimento e largura da sépala e comprimento e largura da pétala, respectivamente, para 50 flores de cada uma das 3 espécies de íris. As espécies são Iris setosa, versicolor e virginica.\n\n\n\n\n\nFlores de Iris, Por Diego Marianom}\n\n\n\n\n\npairs(iris)\n\n\n\n\nO pacote GGally possui uma função similar à função pairs() do R, mas com muito mais funcionalidades. Para usá-la, é necessário instalar o pacote GGally através do comando install.packages(\"GGally\") no console.\n\nlibrary(GGally)\n\n\nggpairs(iris)\n\n\n\n\nPodemos também pedir à função ggpairs() que use cores diferentes para cada espécie.\n\nggpairs(iris, mapping = aes(color = Species))\n\n\n\n\nPodemos obter o mesmo resultado usando o operador pipe:\n\niris |> \n  ggpairs(aes(color = Species))\n\n\n\n\n\n\n14.2.3 Scatter plot (gráficos de dispersão)\nA forma mais simples de visualizar a correlação entre duas variáveis é através de um gráfico de scatter plot. Essa relação pode ser mostrada de forma ainda mais explícita quando inserimos no gráfico uma reta que representa a correlação linear entre essas variáveis. Essa reta, chamada de reta de regressão linear, representa o modelo matemático de correlação entre essas duas variáveis.\nA função básica do R para criar um scatterplot e simplesmente plot() e a inserção da linha de regressão é feita com a função abline() e lm(), de linear model. Vejamos como plotar um gráfico de correlação entre os níveis de ozônio e a radiação solar com esses comandos, usando o dataset airquality do R.\n\nplot(Solar.R ~ Ozone, data = airquality)\nabline(lm(Solar.R ~ Ozone, data = airquality))\n\n\n\n\nApesar dos comandos do R base serem simples, não são nada elegantes. Os gráficos com o ggplot são muito mais profissionais e bem mais flexíveis para ajustes dos detalhes. Vamos plotar esse mesmo gráfico com o ggplot, usando o geom_point() para plotar o scatter plot.\n\nggplot(airquality)  + \n  geom_point(aes(x=Ozone, y=Solar.R)) \n\nWarning: Removed 42 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nPara plotar a reta de regressão basta incluir uma nova camada, uma nova geometria, nesse caso geom_smooth(), indicando como argumentos os mesmos dados e o método linear model lm.\n\nggplot(airquality)  + \n  geom_point(aes(x=Ozone, y=Solar.R)) + \n  geom_smooth(aes(x=Ozone, y=Solar.R), method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 42 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 42 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nObserve entretanto que o código acima repete duas vezes a expressão aes(x=Solar.R, y=Ozone). Podemos reduzir esse código, inserindo essa expressão na primeira linha, o que deixa o código mais limpo, como feito abaixo:\n\nggplot(airquality, aes(x=Ozone, y=Solar.R))  + \n  geom_point() + \n  geom_smooth(method = lm)\n\n\n\n\nO ggplot tem também inúmeras outras possibilidades de ajustes. No código a seguir irei inserir um título, subtítulo, nota de rodapé, mudar os nomes dos eixos e usar um tema pré-definido para estilização do gráfico.\n\nggplot(airquality, aes(x=Ozone, y=Solar.R))  + \n  geom_point() + \n  geom_smooth(method = lm) +\n  labs(title = \"Correlação entre níveis de Ozônio e Radiaçao solar\",\n       subtitle = \"Nova Iorque de maio a setembro de 1973\",\n       caption = \"fonte: dataset airquality\") +\n  ylab(\"Radiação Solar\") +\n  xlab(\"Niveis de Ozônio\") +\n  theme_classic()"
  },
  {
    "objectID": "13-Statistical_Analysis.html#teste-t-de-student",
    "href": "13-Statistical_Analysis.html#teste-t-de-student",
    "title": "14  Análises Estatísticas",
    "section": "14.3 Teste t de Student",
    "text": "14.3 Teste t de Student\nO test t de Student foi criado em 1908 por William Sealy Gosset (Student 1908), matemático e estatístico que trabalhava na cervejaria Guinness, em Dublin, na Irlanda. A Guinness considerava de grande importância recrutar os melhores graduados de Oxford e Cambridge para os cargos de bioquímico e estatístico de testes de sua cerveja para monitorar a qualidade da bebida. O teste t, desenvolvido por Gosset, para monitorar a qualidade da cerveja tipo stout tinha como grande diferencial o fato de poder ser aplicado em amostras de pequeno tamanho pequeno, permitindo fazer inferências com um menor número de elementos, reduzindo os custos da pesquisa.\nA importância dada ao departamento científico da Guinness era tamanha que o uso de métodos estatísticos na fabricação da cerveja era considerado um segredo industrial. Alguns autores argumentam que foi esse o motivo pelo qual Gosset publicou o artigo sobre o teste t em 1908 sob o pseudônimo “Student” e o teste t passou a ser conhecido como teste t de Student.\nO teste t de Student (ou simplesmente teste t) compara as médias de dois conjuntos numéricos e avalia se as diferenças entre essas médias são significativas. Quando existem mais de 3 grupos o test t não pode ser usado e nesse caso podemos usar o Anova, discutido no capítulo seguinte.\nA necessidade de determinar se duas médias de amostras são diferentes entre si é uma situação extremamente frequente em pesquisas científicas. Por exemplo se um grupo experimental difere de um grupo controle, se uma amostra difere da população, se um grupo difere antes de depois de um procedimento. Nessas diversas situações, um método bastante comum é a comparação das médias da medida de interesse. Por exemplo, a média de peso de dois grupos submetidos a diferentes dietas.\n\n14.3.1 Os 3 tipos de teste t de Student\nExistem 3 tipos comuns de teste t:\n- Teste t para duas amostras independentes (ou não pareadas), para comparar as médias de duas amostras independentes.\n- Teste t para duas amostras dependentes (ou pareadas), para comparar as médias de duas amostras pareadas.\n- Teste t para uma amostra, para comparar a média de uma amostra com a média de uma população.\n\n14.3.1.1 Teste t para amostras independentes\nO Teste t para amostras independentes é o teste padrão, ou default do test t do R.\nO R tem uma função muito simples de usar para realizar o teste t: t.test(). Para usar essa função basta incluir como argumentos os valores obtidos de cada grupo da pesquisa e essa função do R já calcula a média de cada grupo e faz a comparação estatística.\nVeja o exemplo a seguir, no qual existem dois grupos diferentes de pacientes (controle e experimental), com os valores de uma medida fictícia. Vamos primeiro criar dois conjuntos de dados numéricos, representando os valores individuais de alguma medida de um Ensaio Clínico Randomizado.\n\n# criando os vetores com os dados:\ncontrole     <- c(21, 28, 24, 23, 23, 19, 28, 20, 22, 20, 26, 26)\nexperimental <- c(26, 27, 23, 25, 25, 29, 30, 31, 36, 23, 32, 22)\n\n# criando uma tibble para armazenar os vetores.\nresult <- tibble(controle, experimental)\nresult\n\n# A tibble: 12 × 2\n   controle experimental\n      <dbl>        <dbl>\n 1       21           26\n 2       28           27\n 3       24           23\n 4       23           25\n 5       23           25\n 6       19           29\n 7       28           30\n 8       20           31\n 9       22           36\n10       20           23\n11       26           32\n12       26           22\n\n\nMuitas vezes antes de algumas análises, teremos de fazer uma transformação em nosso data frame (ou tibble), transformando o data frame do tipo wide em long como explicado no capítulo do pacote tidyr @ref(tidyr).\n\n# carregando o pacote tidyr\nlibrary(tidyr)\n\n# criando um data frame do tipo long\nresult.long <- pivot_longer(data = result,\n                            cols = c(\"controle\", \"experimental\"),\n                            names_to = \"grupo\", \n                            values_to = \"scores\")\nresult.long\n\n# A tibble: 24 × 2\n   grupo        scores\n   <chr>         <dbl>\n 1 controle         21\n 2 experimental     26\n 3 controle         28\n 4 experimental     27\n 5 controle         24\n 6 experimental     23\n 7 controle         23\n 8 experimental     25\n 9 controle         23\n10 experimental     25\n# ℹ 14 more rows\n\n\nUm gráfico de boxplot pode nos mostrar que o grupo experimental tem uma média maior.\n\nggplot(result.long) +\n  geom_boxplot(aes(x=grupo, y=scores, fill=grupo)) +\n  theme_classic()\n\n\n\n\nMas um gráfico não é suficiente.\nPara comparar a média de cada um desses dois grupos, usamos a função t.test() como mostrado a seguir. Podemos fazer o test t de várias formas.\n\nPodemos usar os vetores numéricos comom argumentos.\n\nPodemos usar o data frame wide (ou tibble), selecionando as colunas como argumentos usando o operador $.\n\npodemos usar o data frame (ou tibble) no formato long.\n\n1. Teste t com vetores numéricos\n\n# Teste t de Student para amostras independentes, padrão do R\n# usando os vetores com os dados como argumentos.\nt.test(controle, experimental)\n\n\n    Welch Two Sample t-test\n\ndata:  controle and experimental\nt = -2.6837, df = 20.163, p-value = 0.01421\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -7.2555305 -0.9111362\nsample estimates:\nmean of x mean of y \n 23.33333  27.41667 \n\n\n2. Teste t com data frame wide\nSe o data frame com os dados está no formaro wide (tidy format), ou seja, se há uma coluna para cada amostra, para realizar o test t, basta usar o operador $ para acessar as variáveis do data frame a serem comparadas.\n\nt.test(result$controle, result$experimental)\n\n\n    Welch Two Sample t-test\n\ndata:  result$controle and result$experimental\nt = -2.6837, df = 20.163, p-value = 0.01421\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -7.2555305 -0.9111362\nsample estimates:\nmean of x mean of y \n 23.33333  27.41667 \n\n\nPodemos também informar o dataset primeiro e depois incluir os nomes das colunas/variáveis.\n\nt.test(data=result, controle,experimental)\n\n\n    Welch Two Sample t-test\n\ndata:  controle and experimental\nt = -2.6837, df = 20.163, p-value = 0.01421\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -7.2555305 -0.9111362\nsample estimates:\nmean of x mean of y \n 23.33333  27.41667 \n\n\n3. Teste t com data frame long\nSe os dados das duas amostras estão numa mesma coluna (long format), e se há uma outra coluna para identificar os grupos, o argumento para o teste t é um pouco diferente. Nesse caso, precisamos usar o operador ~ para informar ao teste que desejamos usar os dados de uma coluna (ex: scores), estratificados em dois grupos segundo os dados de uma outra coluna (ex. grupos)\n\n# teste t com data frame do tipo long\n# explicação: os dados numéricos estão na coluna \"score\", a informação sobre os grupos está na variável \"grupos\".\nt.test(scores~grupo, data=result.long)\n\n\n    Welch Two Sample t-test\n\ndata:  scores by grupo\nt = -2.6837, df = 20.163, p-value = 0.01421\nalternative hypothesis: true difference in means between group controle and group experimental is not equal to 0\n95 percent confidence interval:\n -7.2555305 -0.9111362\nsample estimates:\n    mean in group controle mean in group experimental \n                  23.33333                   27.41667 \n\n\n\n\n14.3.1.2 Teste t para amostras dependentes ou pareadas\nSe as amostras são dependentes, ou pareadas, precisamos incluir essa informação nos argumentos no teste. Vamos usar o mesmo data frame criado anteriormente, supondo que as medidas numéricas fossem de uma mesma amostra em dois momentos do tempo. Nesse caso o teste t deve ser um test pareado. Basta inserir o argumento paired = TRUE.\n\nt.test(controle, experimental, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  controle and experimental\nt = -2.6353, df = 11, p-value = 0.02319\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -7.493713 -0.672954\nsample estimates:\nmean difference \n      -4.083333 \n\n\n\nt.test(result$controle, result$experimental, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  result$controle and result$experimental\nt = -2.6353, df = 11, p-value = 0.02319\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -7.493713 -0.672954\nsample estimates:\nmean difference \n      -4.083333 \n\n\nEntretanto, quando usamos a sintaxe do teste com o operador ~ não podemos inserir o argumento paired = TRUE, senão teremos um erro. Esse Parece ser um bug de algumas versões do R, que talvez seja corrigido no futuro.\n\n\n14.3.1.3 Teste t para uma amostra.\nNo caso de uma amostras, para comparar a média de uma amostra com uma média já conhecida, basta inserir nos argumentos do teste t a amostras e o valor da média a ser comparada, como mostrado abaixo.\nPara esse exemplo, vamos usar o dataset wide, chamado result, criado acima, e usar o conjunto de dados chamdo experimental como se fosse nossa única amostra. E vamos inserir um valor arbitrário da média a ser comparada (mu = 30).\n\nt.test(result$experimental, mu= 30)\n\n\n    One Sample t-test\n\ndata:  result$experimental\nt = -2.1044, df = 11, p-value = 0.05915\nalternative hypothesis: true mean is not equal to 30\n95 percent confidence interval:\n 24.71479 30.11854\nsample estimates:\nmean of x \n 27.41667 \n\n\nPodemos também informar o dataset primeiro e depois incluir o nome da coluna/variável.\n\nt.test(data = result, experimental, mu= 30)\n\n\n    One Sample t-test\n\ndata:  experimental\nt = -2.1044, df = 11, p-value = 0.05915\nalternative hypothesis: true mean is not equal to 30\n95 percent confidence interval:\n 24.71479 30.11854\nsample estimates:\nmean of x \n 27.41667 \n\n\n\n\n\n14.3.2 Extraindo os resultados do teste t\nO output dos testes estatísticos no R é uma lista com diversos resultados, que podem ser acessados com o operador $, tal como elementos de um data frame. Podemos verificar a estrutura dessa lista com o comando str(). Mas para isso é preciso armazenar o resultado do test num objeto. Chamaremos aqui esse objeto de test.results.\n\n# armazemando os resultados do test num objeto chamado test.results\ntest.results <- t.test(scores~grupo, data=result.long)\n\n\n# verificando o objeto test.results com str\nstr(test.results)\n\nList of 10\n $ statistic  : Named num -2.68\n  ..- attr(*, \"names\")= chr \"t\"\n $ parameter  : Named num 20.2\n  ..- attr(*, \"names\")= chr \"df\"\n $ p.value    : num 0.0142\n $ conf.int   : num [1:2] -7.256 -0.911\n  ..- attr(*, \"conf.level\")= num 0.95\n $ estimate   : Named num [1:2] 23.3 27.4\n  ..- attr(*, \"names\")= chr [1:2] \"mean in group controle\" \"mean in group experimental\"\n $ null.value : Named num 0\n  ..- attr(*, \"names\")= chr \"difference in means between group controle and group experimental\"\n $ stderr     : num 1.52\n $ alternative: chr \"two.sided\"\n $ method     : chr \"Welch Two Sample t-test\"\n $ data.name  : chr \"scores by grupo\"\n - attr(*, \"class\")= chr \"htest\"\n\n\npodemos extrair o valor de p, ou qualquer outro valor usando o operador $.\n\np_value <- test.results$p.value\np_value\n\n[1] 0.01421353\n\n\nVeja que cada informação do teste está armazenada numa variável que podemos agora acessar. Isso é útil para escrevermos relatórios dinâmicos. Veja a seguinte frase abaixo:\n\nA diferença entre as médias foi estatisticamente significativa (p=0.0142135).\n\nNessa frase eu não digitei o valor de p, mas inseri a variável p_value. Isso é o que torna os relatórios dinâmicos, pois se houver alguma mudança nos dados, basta rodar novamente o código e o valor de p no texto vai ser automaticamente corrigido.\nEssa foi a frase que eu digitei:\n\nA diferença entre as médias foi estatisticamente significativa (p= `r p_value`).\n\nO backtick (backquote ou acento grave) informa o início e o fim de um código, a letra r logo no início informa que o código a seguir é um código da linguagem R e p_value vai ser então interpretado como a variável p_value e seu valor é que será mostrado no texto.\nAtente-se para o detalhe de que as médias estão numa mesma variável estimate:\n\ntest.results$estimate\n\n    mean in group controle mean in group experimental \n                  23.33333                   27.41667 \n\n\nPara acessar cada um desses valores individualmente é necessário indicar isso explicitamente usando o operador [].\n\ntest.results$estimate[1]\n\nmean in group controle \n              23.33333 \n\n\nVeja que da forma como fizemos acima o resultado foi a média do grupo controle, mas o texto veio junto. Para extrair apenas o valor numérico devemos incluir mais um elemento no código, a função as.mumeric().\n\nas.numeric(test.results$estimate[1])\n\n[1] 23.33333"
  },
  {
    "objectID": "13-Statistical_Analysis.html#anova",
    "href": "13-Statistical_Analysis.html#anova",
    "title": "14  Análises Estatísticas",
    "section": "14.4 ANOVA",
    "text": "14.4 ANOVA\nO teste Anova (Análise de Variância) foi criado pelo estatístico britânico Ronald Fisher no início do século XX, para comparar as médias de três ou mais grupos independentes, para determinar se há diferenças estatisticamente significativas entre eles.\nA ideia central do teste Anova é decompor a variabilidade total dos dados em duas partes: a variabilidade entre os grupos e a variabilidade dentro dos grupos. Se as médias dos grupos forem estatisticamente diferentes, espera-se que a variabilidade entre os grupos seja maior do que a variabilidade dentro dos grupos.\nPara exemplificarmos o uso do teste ANOVA vamo usar o dataset PlantGrowth do R. Esse dataset contém o peso das plantas cultivadas sob duas condições de tratamento diferentes e um grupo controle. São, portanto, 3 grupos diferentes de tratamento. Para ter mais informações sobre esse dataset basta digitar ?PlantGrowth no console.\n\n# armazenando o dataset num objeto chamado mydata.\nmydata <- PlantGrowth\n\n\n# verificando o dataset\nhead(mydata)\n\n  weight group\n1   4.17  ctrl\n2   5.58  ctrl\n3   5.18  ctrl\n4   6.11  ctrl\n5   4.50  ctrl\n6   4.61  ctrl\n\n\n\n# verificando o dataset\nstr(mydata)\n\n'data.frame':   30 obs. of  2 variables:\n $ weight: num  4.17 5.58 5.18 6.11 4.5 4.61 5.17 4.53 5.33 5.14 ...\n $ group : Factor w/ 3 levels \"ctrl\",\"trt1\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nObserve que esse dataset já está no formato long, conforme explicado no capítulo sobre data frames @ref(Dataframes).\nPodemos inicialmente computar as estatísticas básicas com a função summarise() do pacote dplyr, conforme explicado no capítulo sobre esse pacote @ref(dplyr).\n\nlibrary(dplyr)\ngroup_by(mydata, group) %>%\n  summarise(count = n(),\n            mean = mean(weight, na.rm = TRUE),\n            sd = sd(weight, na.rm = TRUE))\n\n# A tibble: 3 × 4\n  group count  mean    sd\n  <fct> <int> <dbl> <dbl>\n1 ctrl     10  5.03 0.583\n2 trt1     10  4.66 0.794\n3 trt2     10  5.53 0.443\n\n\nPodemos também visualizar esses conjuntos com um boxplot, conforme explicado no capítulo sobre ggplot @ref(ggplot).\n\nlibrary(ggplot2)\nggplot(mydata, aes(x=group, y=weight, fill=group)) +\n  geom_boxplot() +\n  ylab(\"peso\") + \n  xlab(\"grupo\") + \n  theme_classic()\n\n\n\n\nFinalmente, para realizar o teste ANOVA usamos a função aov(). A função summary() será usada em seguida para resumir os dados do modelo de variância. Vamos ver como isso é feito.\nInicialmente precisamos colocar o modelo ANOVA num objeto e indicar nos argumentos da função anova que o peso das plantas será uma função do tratamento. Lembre-se que o peso está na variável weight e o tipo de tratamento na variável group.\n\nmodelo_ANOVA <- aov(weight ~ group, data = mydata)\n\nDepois de armazenar o modelo ANOVA na variável que denominamos modelo_ANOVA, podemos então usar a função summary(). Essa função tem como argumento justamente o objeto criado anteriormente para armazenar o modelo ANOVA.\n\nsummary(modelo_ANOVA)\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \ngroup        2  3.766  1.8832   4.846 0.0159 *\nResiduals   27 10.492  0.3886                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA coluna Pr(>F) indica o valor de p do teste ANOVA. Como o valor foi menor que 0.05 podemos interpretar que algumas das média dos grupo são estatisticamente diferentes, mas não sabemos que pares são estatisticamente diferentes.\nComo o teste ANOVA é significativo, podemos calcular Tukey HSD (Tukey Honest Significant Differences, para realizar comparações múltiplas de pares entre as médias dos grupos.\nA função TukeyHD() usa o modelo ANOVA que já criamos como argumento.\n\nTukeyHSD(modelo_ANOVA)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = weight ~ group, data = mydata)\n\n$group\n            diff        lwr       upr     p adj\ntrt1-ctrl -0.371 -1.0622161 0.3202161 0.3908711\ntrt2-ctrl  0.494 -0.1972161 1.1852161 0.1979960\ntrt2-trt1  0.865  0.1737839 1.5562161 0.0120064\n\n\nExplicando o resultado:\ndiff: mostra a diferença entre as médias dos dois grupos.\nlwr: o ponto final inferior do intervalo de confiança em 95% (padrão).\nupr: o ponto final superior do intervalo de confiança em 95% (padrão).\np adj: p-valor após ajuste para as comparações múltiplas.\nPode ser visto no resultado acima que apenas a diferença entre trt2 e trt1 é significativa com um valor p ajustado de 0,012."
  },
  {
    "objectID": "13-Statistical_Analysis.html#wilcoxon-rank-sum-test-man-whitney-test",
    "href": "13-Statistical_Analysis.html#wilcoxon-rank-sum-test-man-whitney-test",
    "title": "14  Análises Estatísticas",
    "section": "14.5 Wilcoxon rank sum test (Man-Whitney test)",
    "text": "14.5 Wilcoxon rank sum test (Man-Whitney test)\nNem sempre os dados numéricos seguem um padrão normal. Nesses casos a comparação das médias não pode ser feita com o teste t. Existem vários testes para uso nesses casos, chamados de testes não paramétricos. Os testes Wilcoxon rank sum test (Mann-Whitney test) é o equivalentes não paramétricos do teste t.\nO padrão no R é que esses testes sejam realizados para amostras não pareadas. Caso as amostras sejam pareadas será necessário incluir o argumento PAIRED=TRUE.\nVeja como realizar os Wilcoxon rank sum test no R, para amostras independentes, tomando como exemplo os mesmos dados usados no test t realizado anteriormente.\n\n# criando os vetores com os dados:\ncontrole     <- c(21, 28, 24, 23, 23, 19, 28, 20, 22, 20, 26, 26)\nexperimental <- c(26, 27, 23, 25, 25, 29, 30, 31, 36, 23, 32, 22)\nresult <- tibble(controle, experimental)\nresult.long <- pivot_longer(data = result,\n                            cols = c(\"controle\", \"experimental\"),\n                            names_to = \"grupo\", \n                            values_to = \"scores\")\n\nFazendo o teste de Wilcoxon rank sum test quando os dados estão em colunas distintas, ou seja, um data frame no formato wide:\n\nwilcox.test(result$controle, result$experimental)\n\nWarning in wilcox.test.default(result$controle, result$experimental): cannot\ncompute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  result$controle and result$experimental\nW = 32.5, p-value = 0.02379\nalternative hypothesis: true location shift is not equal to 0\n\n\nFazendo o Wilcoxon rank sum test quando os dados estão em uma única coluna, ou seja, um data frame no formato long. Nesse caso, assim como fizemos no teste t, indicamos a variável numérica e a variável dos grupos separadas pelo operador ~.\n\nwilcox.test(data=result.long, scores~grupo)\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  scores by grupo\nW = 32.5, p-value = 0.02379\nalternative hypothesis: true location shift is not equal to 0\n\n\nNa mensagem de aviso acima o termo “ties” significa que há valores repetidos na amostra. Se você tiver dois valores idênticos em seus dados, eles são chamados de “empates” ou ties”. Nesse caso, os ranks não são mais únicos e, portanto, os valores de p não podem ser calculados com exatidão."
  },
  {
    "objectID": "13-Statistical_Analysis.html#teste-do-chi-quadrado",
    "href": "13-Statistical_Analysis.html#teste-do-chi-quadrado",
    "title": "14  Análises Estatísticas",
    "section": "14.6 Teste do Chi Quadrado",
    "text": "14.6 Teste do Chi Quadrado\nO teste do chi-quadrado compara as frequências observadas em tabelas de contingência com as frequências esperadas se a hipótese nula fosse verdadeira.\nO argumento para a realização desse teste no R é, portanto, uma tabela de contingência.\nVamos usar os dados de uma pesquisa sobre a efetividade dos capacetes de bicicleta na prevenção de trauma crânio-encefálico (TCE), tal como exemplificado por Pagano e Gauvreau (Pagano, Gauvreau, and Mattie 2022). O objetivo aqui é avaliar, num estudo de caso controle, se o uso de capacetes reduz o risco de Trauma Crânio Encefálico.\n\n\n\n\n\nmtabela chi quadrado\n\n\n\n\nO testo do chi-quadrado pode ser usado para avaliar se o uso do capacete reduziu o nº de casos de TCE entre os ciclistas. Precisamos apenas construir uma tabela com esses dados no R, o que pode ser feito através da função matrix(), ou com as funções data.frame() ou tibble(). Veremos como fazer das duas formas.\nUsando a função matrix():\n\ntab1 <- matrix(c(17,218,130,428), \n               nrow=2, \n               byrow = TRUE)\ntab1\n\n     [,1] [,2]\n[1,]   17  218\n[2,]  130  428\n\n\nO argumento nrow=2 indica que a tabela terá 2 linhas e o argumento byrow = TRUE indica que as células da tabela serão preenchidas linha a linha.\nUsando a função data.frame() ou tibble()\nDe forma simples, sem legendas. Observe que a função data.frame() cria colunas com cada vetor. Assim a primeira coluna conterá os valores 17 e 130, e a segunda coluna os valores 218 e 428.\n\ndat1 <- data.frame(c(17,130), c(218,428))\ndat1\n\n  c.17..130. c.218..428.\n1         17         218\n2        130         428\n\n\nPodemos melhorar o data frame dicionando legendas:\n\ndat2 <- data.frame(comCapacete  = c(17,130), \n                   semCapacete  = c(218,428), \n                   row.names = c(\"comTCE\", \"semTCE\"))\ndat2\n\n       comCapacete semCapacete\ncomTCE          17         218\nsemTCE         130         428\n\n\nVamos agora fazer os testes usando essas tabelas criadas, para verificarmos que o resultado é o mesmo.\n\nchisq.test(tab1)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tab1\nX-squared = 27.202, df = 1, p-value = 1.833e-07\n\n\n\nchisq.test(dat1)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  dat1\nX-squared = 27.202, df = 1, p-value = 1.833e-07\n\n\n\nchisq.test(dat2)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  dat2\nX-squared = 27.202, df = 1, p-value = 1.833e-07\n\n\nObserve que em todos os casos o resultado foi idêntico. Observe também que o teste fez a correção de Yates automaticamente. É possível alterar esse comportamento padrão com o argumento correct = FALSE.\n\nchisq.test(dat2, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  dat2\nX-squared = 28.255, df = 1, p-value = 1.063e-07\n\n\nPara aplicar o teste do chi quadrado em dados armazenados em data frames precisamos, da mesma forma, primeiro tabular os dados para depois fazer o teste.\nComo exemplo vamos usar o dataset “Arthritis” disponível no pacote vcd (visualizing categorical data). Esse dataset contém informações de 84 pacientes, 41 dos quais usaram um medicamento e 43 usaram um placebo. O uso do medicamento ou placebo está registrado numa variável categórica (Treatment) de dois níveis (treated, placebo). O resultado está registrado em uma variável categórica ordinal (Improved) de 3 níveis (None < Some < Marked).\nPara instalar o pacote vcd use o comando install.packages no console.\n\ninstall.packages(“vcd”)\n\nPara usar esse pacote é necessário carregá-lo com o comando library() no início do código:\n\nlibrary(vcd)\n\nLoading required package: grid\n\n\nCarregando o dataset Arthritis\n\ndata(\"Arthritis\")\n\nVerificando o dataset Arthritis com o comando str().\n\nstr(Arthritis)\n\n'data.frame':   84 obs. of  5 variables:\n $ ID       : int  57 46 77 17 36 23 75 39 33 55 ...\n $ Treatment: Factor w/ 2 levels \"Placebo\",\"Treated\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Sex      : Factor w/ 2 levels \"Female\",\"Male\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Age      : int  27 29 30 32 46 58 59 59 63 63 ...\n $ Improved : Ord.factor w/ 3 levels \"None\"<\"Some\"<..: 2 1 1 3 3 3 1 3 1 1 ...\n\n\nA primeira etapa para verificar a associação entre o tratamento e a melhora é criar uma tabela com as variáveis (categóricas) de interesse: Treatment e Improved.\n\ntab5 <- table(Arthritis$Treatment, Arthritis$Improved)\ntab5\n\n         \n          None Some Marked\n  Placebo   29    7      7\n  Treated   13    7     21\n\n\nAgora que já construímos a tabela a partir das duas variáveis de interesse do data frame, podemos então usar o teste do chi quadrado para verificar a associação entre o tratamento e o resultado. Basta aplicar o teste na tabela criada.\n\nchisq.test(tab5)\n\n\n    Pearson's Chi-squared test\n\ndata:  tab5\nX-squared = 13.055, df = 2, p-value = 0.001463\n\n\nO resultado indica haver uma associação entre o tipo de tratamento realizado e o resultado, ou seja, o uso do medicamento parece ter sido melhor que o placebo.\nPodemos também inserir as variáveis de interesse diretamente na função chisq.test(), tal como no exemplo abaixo:\n\nchisq.test(Arthritis$Treatment, Arthritis$Improved)\n\n\n    Pearson's Chi-squared test\n\ndata:  Arthritis$Treatment and Arthritis$Improved\nX-squared = 13.055, df = 2, p-value = 0.001463\n\n\nPodemos da mesma forma extrair os resultados do teste armazenando os resultado do teste num objeto.\n\nresult_chi <- chisq.test(tab5)\nstr(result_chi)\n\nList of 9\n $ statistic: Named num 13.1\n  ..- attr(*, \"names\")= chr \"X-squared\"\n $ parameter: Named int 2\n  ..- attr(*, \"names\")= chr \"df\"\n $ p.value  : num 0.00146\n $ method   : chr \"Pearson's Chi-squared test\"\n $ data.name: chr \"tab5\"\n $ observed : 'table' int [1:2, 1:3] 29 13 7 7 7 21\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2] \"Placebo\" \"Treated\"\n  .. ..$ : chr [1:3] \"None\" \"Some\" \"Marked\"\n $ expected : num [1:2, 1:3] 21.5 20.5 7.17 6.83 14.33 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2] \"Placebo\" \"Treated\"\n  .. ..$ : chr [1:3] \"None\" \"Some\" \"Marked\"\n $ residuals: 'table' num [1:2, 1:3] 1.6175 -1.6565 -0.0623 0.0638 -1.937 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2] \"Placebo\" \"Treated\"\n  .. ..$ : chr [1:3] \"None\" \"Some\" \"Marked\"\n $ stdres   : 'table' num [1:2, 1:3] 3.2742 -3.2742 -0.0976 0.0976 -3.3956 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2] \"Placebo\" \"Treated\"\n  .. ..$ : chr [1:3] \"None\" \"Some\" \"Marked\"\n - attr(*, \"class\")= chr \"htest\"\n\n\nO valor de p pode ser extraido com o comando result_chi$pvalue, como feito abaixo:\n\nresult_chi$p.value\n\n[1] 0.001462643"
  },
  {
    "objectID": "13-Statistical_Analysis.html#teste-exato-de-fisher",
    "href": "13-Statistical_Analysis.html#teste-exato-de-fisher",
    "title": "14  Análises Estatísticas",
    "section": "14.7 Teste exato de Fisher",
    "text": "14.7 Teste exato de Fisher\nO teste exato de Fisher é utilizado na análise de tabelas de contingência quando a amostra é pequena, embora seja válido para todo tamanho de amostra. Foi desenvolvido por Ronald Fisher. Fisher disse ter concebido o teste depois de um comentário da Dra. Muriel Bristol, que afirmou ser capaz de detectar se o chá ou o leite foi adicionado primeiro em sua xícara. Ele testou seu pedido no experimento “dama apreciadora de chá”, contado em diversos livros de história da estatística, inclusive num livro com esse mesmo título: “The Lady Tasting Tea” de David Salsburg (Salsburg 2001).\nFisher projetou um experimento em que a senhora recebia 8 xícaras de chá, 4 com leite primeiro, 4 com chá primeiro, em ordem aleatória. Ela então provou cada xícara e relatou quais quatro ela achava que tinham leite adicionado primeiro. Ela acertou todas as 8 chícaras.\nA pergunta que Fisher fez foi: “como testamos se ela realmente é habilidosa nisso ou se está apenas adivinhando?”\nVamos construir uma tabela de contingência, com os valores VERDADEIROS nas colunas e as resultados nas linhas.\n\ntea_tasting <- data.frame(Leite_Primeiro  = c(4,0), \n                          Cha_Primeiro    = c(0,4), \n                          row.names = c(\"Respondeu que era Leite Primeiro\", \"Respondeu que era Chá Primeiro\"))\ntea_tasting\n\n                                 Leite_Primeiro Cha_Primeiro\nRespondeu que era Leite Primeiro              4            0\nRespondeu que era Chá Primeiro                0            4\n\n\nPara usar o teste de Fisher no R basta inserirmos a tabela de contingência como argumento da função fisher.test().\nEntretanto, há mais um detalhe a ser analisado. Um dos parâmetros do teste é se ele é bicaudal ou unicaldal. O padrão é que o R realize um teste bicaudal (two.sided). Entretanto, Fisher testou se a senhora Muriel era melhor do que o acaso e não se sua habilidade era diferente do acaso e, portanto, ele usou um teste unilateral.\nPara encontrarmos o mesmo resultado, precisamos ajustar esse argumento, inserindo alternative = \"greater\".\n\nfisher.test(tea_tasting, alternative = \"greater\")\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tea_tasting\np-value = 0.01429\nalternative hypothesis: true odds ratio is greater than 1\n95 percent confidence interval:\n 2.003768      Inf\nsample estimates:\nodds ratio \n       Inf \n\n\nÉ possível fazer o teste de Fisher diretamente com os dados de um data frame, sem necessidade de tabulação previa dos dados. Vamos usar novamente o data frame Arthritis, do pacote vcd.\n\nfisher.test(tab5)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tab5\np-value = 0.001393\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "13-Statistical_Analysis.html#analise-de-regressão",
    "href": "13-Statistical_Analysis.html#analise-de-regressão",
    "title": "14  Análises Estatísticas",
    "section": "14.8 Analise de Regressão",
    "text": "14.8 Analise de Regressão\nA análise de regressão é um conjunto de processos estatísticos usados para estimar relações entre variáveis. Mais especificamente, para modelar e analisar relações entre uma variável dependente (de desfecho ou de resposta) e uma ou mais variáveis independentes (preditoras). A análise de regressão quantifica a mudança da variável dependente de acordo com a mudança de de cada uma das variáveis independentes.\nA regressão linear é usada quando a variável de resposta é numérica. Através da regressão linear podemos quantificar quanto uma variável (de desfecho) se modifica quando outra ou outras (preditoras) se modificam. Por exemplo, podemos criar um modelo linear simples para predizer o quanto a glicemia aumenta de acordo com a quantidade calórica ingerida, ou podemos criar modelos lineares complexos, com mais de uma variável preditora, tal como para analisar o quanto a pressão arterial depende do peso, do sexo e da idade.\nA regressão logística (também conhecida como regressão logit ou modelo logit) é usada quando a variável de resposta é categórica, mais especificamente, categórica e binária (dicotômica). Por exemplo para predizer o óbito (sim ou não), ou um diagnóstico (diabético ou não diabético), ou qualquer evento dicotômico a partir de uma um mais variáveis preditoras (independentes).\n\n14.8.1 Regressão linear (modelos Lineares)\nA correlação linear informa se você tem uma associação forte, moderada ou fraca entre duas variáveis numéricas, mas não descreve as relações de causalidade. A análise de regressão vai um pouco mais além disso, pois o interesse é não apenas na intensidade ou direção da correlação, mas também na natureza dessa relação. Isto é, na análise de regressão o pesquisador estabelece qual ou quais são as variáveis independentes (preditoras) e qual a variável de dependente (de desfecho). A análise de regressão busca construir um modelo matemático que possa servir para predizer o desfecho a partir das variáveis preditoras. Na regressão linear o modelo criado é simplesmente uma reta. A equação da reta que mais se ajusta aos dados é o modelo gerado pela regressão linear.\nA etapa fundamental é a definição de qual ou quais são as variáveis preditoras (as causas) e qual é o desfecho (a consequência). Após essas definições é que podemos então começar a tentar criar esse modelo no R.\nNunca é demais ressaltar que a análise de regressão não garante que as variáveis preditoras sejam realmente a causa das mudanças da variável de desfecho. Mas não se esqueça de que, para que seu modelo seja válido, existem três principais suposições que precisam ser satisfeitas: _ Linearidade entre as variáveis de desfecho e as preditoras; - A variável de resultado é distribuída de forma normal ao longo dos valores das variáveis preditoras; - A variação do resultado é a mesma ao longo dos valores das preditoras.\n\n14.8.1.1 Modelo linear simples\nComo exemplo vamos usar o dataset mpg do R. Iniciamos com a hipótese de que a distância percorrida por um carro com um galão (cty) dependa das cilindradas do carro(displ). Para fins de ilustração, o gráfico abaixo mostra a relação entre a distância percorrida na cidade com um galão de combustível (variável de desfecho) e as cilindradas do carro. Pode-se ver que quanto maior as cilindradas menor a distância percorrida com um galão. A faixa cinza ao redor da linha de regressão representa o intervalo de confiança.\n\n\n\n\n\nVejamos então como criar um modelo linear entre as variáveis distância percorrida na cidade (cty) como desfecho e cilindradas (displ) como preditora. O primeiro passo é criar um objeto para armazenar o modelo (ex. modelo1), depois atribuir (<-) um modelo linear a esse objeto usando a função lm(). As letras lm significam simplesmente “linear model”.\nPara criar a relação entre as variáveis iremos usar também o operador ~ (til), já descrito anteriormente. Esse operador irá servir para indicar a relação entre variável de desfecho e preditora e é usado na seguinte sequencia:\n\\(\\text{variável de desfecho} \\text{ ~ } \\text{variável preditora}\\)\nO que no nosso caso será: cty~displ. E que se lê da seguinte forma: cty depende de displ ou distância percorrida depende das cilindradas. O formato final do código será:\n\nmodelo1 <- lm(cty~displ, data = mpg)\n\nPara visualizar os valores das estatísticas calculas, usamos a função summary().\n\nsummary(modelo1)\n\n\nCall:\nlm(formula = cty ~ displ, data = mpg)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.3109 -1.4695 -0.2566  1.1087 14.0064 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  25.9915     0.4821   53.91   <2e-16 ***\ndispl        -2.6305     0.1302  -20.20   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.567 on 232 degrees of freedom\nMultiple R-squared:  0.6376,    Adjusted R-squared:  0.6361 \nF-statistic: 408.2 on 1 and 232 DF,  p-value: < 2.2e-16\n\n\nPara poder obter individualmente cada estatística calculada pela função lm() é conveniente atribuir o resumo - summary() - do modelo a um outro objeto, que irei chamar de ms.\n\nms <- summary(modelo1)\n\nObserve a estrutura desse objeto:\n\nstr(ms)\n\nList of 11\n $ call         : language lm(formula = cty ~ displ, data = mpg)\n $ terms        :Classes 'terms', 'formula'  language cty ~ displ\n  .. ..- attr(*, \"variables\")= language list(cty, displ)\n  .. ..- attr(*, \"factors\")= int [1:2, 1] 0 1\n  .. .. ..- attr(*, \"dimnames\")=List of 2\n  .. .. .. ..$ : chr [1:2] \"cty\" \"displ\"\n  .. .. .. ..$ : chr \"displ\"\n  .. ..- attr(*, \"term.labels\")= chr \"displ\"\n  .. ..- attr(*, \"order\")= int 1\n  .. ..- attr(*, \"intercept\")= int 1\n  .. ..- attr(*, \"response\")= int 1\n  .. ..- attr(*, \".Environment\")=<environment: R_GlobalEnv> \n  .. ..- attr(*, \"predvars\")= language list(cty, displ)\n  .. ..- attr(*, \"dataClasses\")= Named chr [1:2] \"numeric\" \"numeric\"\n  .. .. ..- attr(*, \"names\")= chr [1:2] \"cty\" \"displ\"\n $ residuals    : Named num [1:234] -3.257 -0.257 -0.731 0.269 -2.626 ...\n  ..- attr(*, \"names\")= chr [1:234] \"1\" \"2\" \"3\" \"4\" ...\n $ coefficients : num [1:2, 1:4] 25.991 -2.63 0.482 0.13 53.908 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2] \"(Intercept)\" \"displ\"\n  .. ..$ : chr [1:4] \"Estimate\" \"Std. Error\" \"t value\" \"Pr(>|t|)\"\n $ aliased      : Named logi [1:2] FALSE FALSE\n  ..- attr(*, \"names\")= chr [1:2] \"(Intercept)\" \"displ\"\n $ sigma        : num 2.57\n $ df           : int [1:3] 2 232 2\n $ r.squared    : num 0.638\n $ adj.r.squared: num 0.636\n $ fstatistic   : Named num [1:3] 408 1 232\n  ..- attr(*, \"names\")= chr [1:3] \"value\" \"numdf\" \"dendf\"\n $ cov.unscaled : num [1:2, 1:2] 0.03527 -0.00893 -0.00893 0.00257\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:2] \"(Intercept)\" \"displ\"\n  .. ..$ : chr [1:2] \"(Intercept)\" \"displ\"\n - attr(*, \"class\")= chr \"summary.lm\"\n\n\nPodemos utilizar o operador $, tal como usamos num data frame, para obter os valores individuais de cada estatística. Obtendo o valor do coeficiente de determinação (r2)\n\nms$r.squared\n\n[1] 0.6376405\n\n\nObtendo o valor do coeficiente de determinação (r2) ajustado\n\nms$adj.r.squared\n\n[1] 0.6360786\n\n\nOs principais gráficos de uma modelo linear podem ser facilmente plotados com o comando plot(modelo1) como demonstrado abaixo. Esse comando plot automaticamente os gráficos Residuals vs Fitted, Q-Q Residuals, Scale Location e Residuals vs Leverage. O comando par(mfrow = c(2, 2)) serve apenas para colocar os gráficos num grid 2x2.\n\npar(mfrow = c(2, 2))\nplot(modelo1)\n\n\n\n\n\n\n14.8.1.2 Regressão Linear com o pacote broom\nComo vimos acima, as informações de um modelo estatístico criado com a função lm() podem ser acessadas criando um objeto com a função summary(). Entretanto, essas informações não estão organizadas num data frame e é difícil manipular e comparar resultados de diversos modelos. É também muito difícil combinar resultados de diversos modelos. O pacote broom resume as principais informações sobre estatísticas de objetos em data frames organizados facilitando sua análise, comparação e visualização.\nEste pacote fornece três métodos que organizam as informações de um modelo estatístico.\ntidy(): constrói um quadro de dados que resume as estatísticas do modelo. Isso inclui coeficientes e valores p para cada termo em uma regressão, informações por cluster em aplicativos de armazenamento em cluster ou informações por teste para funções de teste múltiplo.\nglance(): constrói um resumo conciso de uma linha do modelo. Isso normalmente contém valores como R ^ 2, R ^ 2 ajustado e erro padrão residual que são computados uma vez para o modelo inteiro.\naugment(): adiciona colunas aos dados originais que foram modelados. Isso inclui previsões, resíduos e atribuições de cluster.\nComo veremos adiante, A função tidy() também pode ser aplicada a objetos htest, como aqueles produzidos por funções internas populares como t.test(), cor.test() e wilcox.test().\n\nlibrary(broom)\ntidy(modelo1)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)    26.0      0.482      53.9 3.30e-133\n2 displ          -2.63     0.130     -20.2 4.74e- 53\n\n\nNote que os dados estatísticos do modelo agora são variáveis (colunas)\nA função glance() computa as estatísticas do modelo, tais como r^2, sigma, p-values, AIC e BIC.\n\nglance(modelo1)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.638         0.636  2.57      408. 4.74e-53     1  -552. 1109. 1120.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\n\nCom a função augment(), adicionamos colunas aos dados originais que foram modelados. Isso inclui previsões, resíduos e atribuições de cluster.\n\naugment(modelo1, data=mpg)\n\n# A tibble: 234 × 17\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows\n# ℹ 6 more variables: .fitted <dbl>, .resid <dbl>, .hat <dbl>, .sigma <dbl>,\n#   .cooksd <dbl>, .std.resid <dbl>\n\n\n\n\n14.8.1.3 Modelo Linear múltiplo\nFrequentemente uma única variável preditora não será capaz de explicar toda variação da variável de desfecho. Na verdade, na medicina é raro que uma resposta dependa de apenas uma única variável. Com o R podemos facilmente inserir mais de uma variável preditora em nosso modelo de regressão linear.\nCom duas variáveis nossa reta de regressão se transforma num plano, e nosso modelo que antes era uma simples equação da reta se transforma numa equação de um plano. Com mais de 2 variáveis preditoras não há mais uma visualização possível, mas isso não impede que sejam usadas mais de duas variáveis.\nO formato básico do modelo é bastante simples, tal como no modelo simples, usando o operador ~ para separar a variável de desfecho das preditoras e usando o operador + para somar as variáveis preditoras:\nPodemos expandir nosso modelo anterior inserindo como variáveis preditoras tanto as cilindradas do motor (displ) como também a quantidade de cilindros (cyl).\nE que se lê da seguinte forma: cty depende de displ e de cyl, ou distância percorrida depende das cilindradas e do número de cilindros. O formato final do código será:\n\nmodelo2 <- lm(cty~displ + cyl, data = mpg)\n\nPara visualizar os valores das estatísticas calculas, usamos mais uma vez função summary(), dessa vez atribuindo o resultado a um objeto que nomeamos de ms2.\n\nms2 <- summary(modelo2)\nms2\n\n\nCall:\nlm(formula = cty ~ displ + cyl, data = mpg)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.9276 -1.4750 -0.0891  1.0686 13.9261 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  28.2885     0.6876  41.139  < 2e-16 ***\ndispl        -1.1979     0.3408  -3.515 0.000529 ***\ncyl          -1.2347     0.2732  -4.519 9.91e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.466 on 231 degrees of freedom\nMultiple R-squared:  0.6671,    Adjusted R-squared:  0.6642 \nF-statistic: 231.4 on 2 and 231 DF,  p-value: < 2.2e-16\n\n\n\n\n\n14.8.2 Regressão Logística\nA ser escrito\n\n\n\n\nPagano, Marcello, Kimberlee Gauvreau, and Heather Mattie. 2022. Principles of Biostatistics. Book. CRC Press.\n\n\nSalsburg, David. 2001. The Lady Tasting Tea. How Statistics Revolutionized Science in the Twentieth Century. Book. 1º ed. New York: Holt Paperbacks.\n\n\nStudent. 1908. “The Probable Error of a Mean.” Journal Article. Biometrika 6 (1): 1–25. https://doi.org/10.2307/2331554."
  },
  {
    "objectID": "14-Distributions.html#definindo-o-ponto-de-partida-para-a-geração-de-números-aleatórios",
    "href": "14-Distributions.html#definindo-o-ponto-de-partida-para-a-geração-de-números-aleatórios",
    "title": "15  Distribuições de Probabilidade",
    "section": "15.1 Definindo o ponto de partida para a geração de números aleatórios",
    "text": "15.1 Definindo o ponto de partida para a geração de números aleatórios\nA função set.seed() do R é utilizada para definir a semente (ou seed, em inglês) de geração de números aleatórios, ou seja, o ponto de partida para a geração de números aleatórios. Isso é particularmente útil quando você precisa garantir que seus resultados sejam reprodutíveis. Ao definir uma semente específica, qualquer operação subsequente que envolva a geração de números aleatórios produzirá os mesmos resultados em diferentes execuções, desde que a mesma semente seja usada.\nSem definir uma semente, os resultados da simulação mudarão a cada execução. No entanto, ao usar set.seed(), você pode garantir que os resultados sejam consistentes.\n\n# Cada execução desse código resultará em uma sequência diferente de 5 números.\nrnorm(5)\n\n[1]  0.7819179 -1.1387334 -0.1326681  0.7352568 -1.3003365\n\n\n\n# Cada execução desse código resultará sempre em na mesma sequencia de 5 números.\n# Alterar o argumento da função set.seed irá mudar a sequencia de números.\nset.seed(1)\nrnorm(5)\n\n[1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078\n\n\nA semente deve ser sempre um número inteiro. Diferentes números de sementes levarão a diferentes sequências de números aleatórios. Observe que set.seed() não altera os números gerados globalmente para toda a sessão R, mas garante que a sequência de números aleatórios gerados após definir a semente seja a mesma."
  },
  {
    "objectID": "14-Distributions.html#distribuição-uniforme",
    "href": "14-Distributions.html#distribuição-uniforme",
    "title": "15  Distribuições de Probabilidade",
    "section": "15.2 Distribuição Uniforme",
    "text": "15.2 Distribuição Uniforme\n\n15.2.1 runif\nA função runif() gera um conjunto randomizado de números a partir de um distribuição uniforme. Os argumentos dessa função são: a quantidade de números, o valor mínimo e o valor máximo.\nVeja abaixo como criar um conjunto randomizado de 20 números distribuídos de forma uniforme entre 0 e 1.\n\nru1 <- runif(n = 20, min = 0, max = 1)\nru1\n\n [1] 0.20597457 0.17655675 0.68702285 0.38410372 0.76984142 0.49769924\n [7] 0.71761851 0.99190609 0.38003518 0.77744522 0.93470523 0.21214252\n[13] 0.65167377 0.12555510 0.26722067 0.38611409 0.01339033 0.38238796\n[19] 0.86969085 0.34034900\n\n\npodemos arrendondar esses valores com a função round().\n\n# arredondando para 2 casas decimais\nround(ru1, 2)\n\n [1] 0.21 0.18 0.69 0.38 0.77 0.50 0.72 0.99 0.38 0.78 0.93 0.21 0.65 0.13 0.27\n[16] 0.39 0.01 0.38 0.87 0.34\n\n\nPodemos visualizar um histograma dessa distribuição com a função hist(). Veja que com poucos elementos a distribuição ainda não parece uniforme.\n\nhist(ru1)\n\n\n\n\nEntretanto, a medida que aumentando o número de elementos, a forma da distribuição se parece cada vez mais com uma distribuição uniforme. Veja no código abaixo um conjunto randomizado de 10, 100, 1000 e 10.000 elementos criados com a função runif() e os histogramas dessas distribuições.\n\nru1 <- runif(n = 10, min = 0, max = 1)\nru2 <- runif(n = 100, min = 0, max = 1)\nru3 <- runif(n = 1000, min = 0, max = 1)\nru4 <- runif(n = 10000, min = 0, max = 1)\npar(mfrow = c(2, 2)) # cria uma matrix 2x2 para plotar os gráficos\nhist(ru1)\nhist(ru2)\nhist(ru3)\nhist(ru4)\n\n\n\n\n\n\n15.2.2 dunif\nA função dunif() calcula a função de densidade de probabilidade (PDF) da distribuição uniforme, ou seja, a probabilidade de que uma variável aleatória seja igual a um determinado valor. A função dunif() tem três argumentos:\n\nx: o valor no qual calcular o PDF\nmin: o limite inferior da distribuição\nmax: o limite superior da distribuição\n\nVeja como usar a função dunif() para calcular o PDF de uma distribuição uniforme entre 0 e 100 no valor 2:\n\ndunif(x=5, min=0, max=100)\n\n[1] 0.01\n\n\nIsso significa que a probabilidade de uma variável aleatória dessa distribuição ser igual a 5 é 0.01.\n\n\n15.2.3 punif\nA função punif() calcula a função de densidade de probabilidade cumulativa (CDF) da distribuição uniforme, ou seja, a probabilidade de que uma variável aleatória seja menor ou igual a um determinado valor.\nA função punif() requer três argumentos:\n\nx: o valor no qual calcular o CDF\n\nmin: o limite inferior da distribuição\n\nmax: o limite superior da distribuição\n\nVeja um exemplo de como usar a função punif() para calcular o CDF de uma distribuição uniforme entre 0 e 100 no valor 5:\n\npunif(5, min = 0, max = 100)\n\n[1] 0.05\n\n\n\n\n15.2.4 qunif\nA função quinf() calcula a função quantil da distribuição uniforme. A função quantil é o inverso do CDF. Dada um probabilidade como entrada, a função retorna o valor que tem essa probabilidade.\nA função quinf() requer três argumentos:\n\np: a probabilidade\n\nmin: o limite inferior da distribuição\n\nmax: o limite superior da distribuição\n\nVeja exemplo de como usar a função quinf() para calcular o quantil de uma distribuição uniforme entre 0 e 100 na probabilidade de 0.05:\n\nqunif(0.05, min = 0, max = 100)\n\n[1] 5"
  },
  {
    "objectID": "14-Distributions.html#distribuição-normal",
    "href": "14-Distributions.html#distribuição-normal",
    "title": "15  Distribuições de Probabilidade",
    "section": "15.3 Distribuição Normal",
    "text": "15.3 Distribuição Normal\nA mais importante das distribuições de probabilidade teóricas é a distribuição normal. Diversos fenômenos na natureza seguem um padrão de distribuição simétrico e em forma de sino. Devido a essa forma, essa distribuição de frequências ficou conhecida como distribuição em sino (bell shaped). Como tantos fenômenos são distribuídos dessa forma, a busca por um modelo matemático para modelar essa distribuição tem uma longa e interessante trajetória na ciência, envolvendo diversos grandes matemáticos. O modelo matemático dessa curva se começou a ser construído por volta do ano de 1733 com o trabalho do matemático Abraham Demoivre, quando buscava modelos para prever resultados de jogos de azar e em 1786 por Pierre Laplace, um astrônomo e matemático. No entanto, a curva normal como modelo para a distribuição de erros na teoria científica é mais comumente associada a um astrônomo e matemático alemão, Karl Friedrich Gauss, que encontrou uma nova derivação da fórmula para a curva em 1809 (Gordon 2006). Por esse motivo, a curva normal às vezes é referida como a curva “Gaussiana”. Em 1835, outro matemático e astrônomo, Lambert Quetelet, usou o modelo para descrever características fisiológicas e sociais humanas. Quetelet acreditava que “normal” significava média e que os desvios da média eram os erros da natureza. Apesar da visão distorcida de Quetelet, ele foi o primeiro matemático a estender o uso da curva de distribuição normal para os campos das ciências sociais e biomédicas (Stahl 2006).\n\n15.3.1 rnorm\nA função rnorm() gera um conjunto de números randomizados a partir de um distribuição normal. Os argumentos dessa função são: a quantidade de números, a média e o desvio padrão. Se introduzirmos apenas a quantidade de números, a função rnorm() utiliza a distribuição normal padrão, com média = 0 e desvio padrão = 1.\nGerando um conjunto randomizado de 1000 números distribuídos de forma normal com média = 0 e desvio padrão = 1.\n\nset.seed(100)\nrn1 <- rnorm(n = 1000, mean = 0, sd = 1)\nplot(density(rn1)) \n\n\n\n\nPoderíamos também escrever a função acima com os argumentos pela ordem:\n\nset.seed(100)\nrn1 <- rnorm(1000, 0, 1)\nplot(density(rn1)) \n\n\n\n\n\n# Inserindo apenas o número de valores a serem gerados\n# Nesse caso a função rnorm usa os valores default para media e desvio padrão\n# media = 0 e desvio padrão = 1 (curva normal padrão)\nset.seed(100)\nrn1 <- rnorm(1000)\nplot(density(rn1)) \n\n\n\n\n\n\n15.3.2 dnorm\nA função dnorm() é a função de densidade de probabilidade (PDF) de uma distribuição normal e retorna o valor da densidade de probabilidade de um valor x, ou seja, a altura da curva normal naquele ponto. Tem como argumentos o valor x e a média e o desvio padrão da curva. O primeiro argumento é o ponto no eixo x do qual se pretende saber o valor da densidade de probabilidade, o segundo argumento é a média e o terceiro argumento é o desvio padrão.\nPor exemplo, para saber o valor da densidade de probabilidade de x=2, numa curva normal padrão (média =0 e desvio padrão =1), o código seria:\n\ndnorm(2, mean = 0, sd = 1)\n\n[1] 0.05399097\n\n\nNuma curva normal padrão não precisamos informar os valores da média e do desvio padrão, bastando inserir o ponto do eixo x.\n\ndnorm(2)\n\n[1] 0.05399097\n\n\n\n\n\n\n\nA função dnorm(x) pode ser usada também para gerar todos os pontos da curva normal. Isso pode ser útil para desenhar gráficos da curva normal com códigos bem curtos, quando a associamos à função curve(), como mostrado nos códigos abaixo.\n\ncurve(dnorm(x), -3, 3)\n\n\n\n\n\ncurve(dnorm(x, mean = 10, sd = 2), 4, 16)\n\n\n\n\n\ncurve(dnorm(x, mean= 100, sd= 10), 50, 150)\n\n\n\n\nPodemos inserir várias curvas num mesmo gráfico com o argumento add=TRUE.\n\ncurve(dnorm(x, sd=1), col=\"black\", xlim=c(-10,10), ylim=c(0,0.4), ylab=\"Densidade\")\ncurve(dnorm(x, sd=2), col=\"brown\", xlim=c(-10,10), ylim=c(0,0.4), ylab=\"Densidade\", add=TRUE)\ncurve(dnorm(x, sd=3), col=\"blue\",  xlim=c(-10,10), ylim=c(0,0.4), ylab=\"Densidade\", add=TRUE)\ncurve(dnorm(x, sd=4), col=\"red\",   xlim=c(-10,10), ylim=c(0,0.4), ylab=\"Densidade\", add=TRUE)\ncurve(dnorm(x, sd=5), col=\"green\", xlim=c(-10,10), ylim=c(0,0.4), ylab=\"Densidade\", add=TRUE)\nlegend(x = 2.4, y = 0.41, lty=1, \nlegend = c(\"σ = 1\",   \"σ = 2\",   \"σ = 3\",  \"σ = 4\",  \"σ = 5\"),\ncol =    c(\"black\",   \"brown\",   \"blue\",   \"red\",    \"green\"))\n\n\n\n\n\n\n15.3.3 pnorm\nA função pnorm(x) é utilizada para calcular a função de distribuição acumulada (CDF) de uma distribuição normal. Em outras palavras, ela fornece a probabilidade de que uma variável aleatória com distribuição normal padrão seja menor ou igual a um determinado valor x. Do ponto de vista gráfico, essa função calcula área abaixo da curva normal, à esquerda de x, ou seja, a probabilidade de dados menores que x. O gráfico abaixo mostra a interpretação visual da função pnorm(x).\n\n# calculando pnorm de x=2 na curva normal padrão\npnorm(2)\n\n[1] 0.9772499\n\n\n\n\n\n\n\nObserve que a função pnorm(x) usou os valores padrões de media = 0 e desvio padrão = 1. Caso seja necessário usar outros valores, basta inserir esses argumentos na função pnorm().\nVamos usar um estudo da ANAC (Agência Nacional de Aviação Civil) (Silva and Monteiro 2009) como exemplo. Nesse estudo foi a média da altura dos homens brasileiros usuários do sistema de aviação foi estimada em 173,1 cm com um desvio padrão de 7,3cm. Usando esses dados como exemplo, podemos calcular qual o percentual de homens dessa amostra com altura inferior a 190cm.\n\npnorm(190, mean=173.1, sd=7.3)\n\n[1] 0.9896954\n\n\nA função pnorm(x) calcula a área abaixo da curva À ESQUERDA do ponto x. Como a área total abaixo de uma curva normal é 1, Para saber a área à direita basta subtrair o resultado de 1, como feito abaixo:\n\n1 - pnorm(190, mean=173.1, sd=7.3)\n\n[1] 0.01030459\n\n\nOu seja, aproximadamente 1% dos homens brasileiros dessa amostra tem altura superior a 190cm.\f\n\n\n\n\n\n\n\n15.3.4 qnorm\nA função qnorm() faz o calculo inverso da função pnorm(). é utilizada para calcular o quantil (ou percentil) de uma distribuição normal. Isso significa que ela fornece o valor x tal que a área sob a curva normal à esquerda de x é igual a uma probabilidade especificada p. O argumento da função qnorm(p) é extamente essa probabilidade, o percentual abaixo da curva à esquerda do ponto x. O resultado dessa função é o valor no eixo x que delimita essa área.\nCom essa função podemos nos perguntar qual deve ser a altura das portas de um avião para que 99% dos brasileiros usuários dos aeroportos possam passar pela porta de um avião sem ter de se abaixar? Ou seja, qual a medida da estatura abaixo do qual estão 99% dos brasileiros dessa amostra? Lembrando que a média da altura dos homens brasileiros usuários do sistema de aviação foi estimada em 173,1 cm com um desvio padrão de 7,3cm, o código fica assim:\n\nqnorm(0.99, mean=173.1, sd=7.3)\n\n[1] 190.0823\n\n\nEssa análise pode ser visualizada no gráfico abaixo:"
  },
  {
    "objectID": "14-Distributions.html#distribuiçao-t-de-student",
    "href": "14-Distributions.html#distribuiçao-t-de-student",
    "title": "15  Distribuições de Probabilidade",
    "section": "15.4 Distribuiçao t de Student",
    "text": "15.4 Distribuiçao t de Student\nA distribuição t de Student (também conhecida como distribuição t) foi introduzida por William Sealy Gosset em 1908, sento usada para estimar a média de variáveis aleatórias normalmente distribuídas para as quais o tamanho da amostra é pequeno e o desvio padrão é desconhecido. A distribuição t parece muito semelhante à distribuição normal, e converge para a curva normal à medida que o tamanho da amostra aumenta.\n\n15.4.1 rt()\nA função rt() cria conjunto randomizado de números a partir de um distribuição t de Student. Os argumentos dessa função são: a quantidade de números e os graus de liberdade (degrees of freedom - df).\n\nset.seed(1)\nx <- rt(n = 1000, df = 10)\nplot(density(x))\n\n\n\n\n\n\n15.4.2 dt()\nAs funções dt(), pt(), qt() funcionam da mesma forma que suas correspondentes na distribuição normal, como já discutido anteriormente, com a diferença de que o parâmetro da distribuição t são os graus de liberdade (degrees of freedom - df) e não a média e o desvio padrão.\nA função dt() é a função de densidade de probabilidade (PDF) na curva de distribuição t. Tem como argumento o ponto no eixo x e os graus de liberdade e seu resultado é o valor da densidade de probabilidade, ou a altura da curva t nesse ponto.\nPor exemplo, para saber o valor da densidade de probabilidade de x=2, numa curva de distribuição t com 5 graus de liberdade (df = 5), o código seria:\n\ndt(x=2, df=5)\n\n[1] 0.06509031\n\n\n\n\n\n\n\nA função dt() pode ser usada também para gerar todos os pontos da curva, o que pode ser útil para desenhar gráficos da curva normal com códigos bem curtos, quando a associamos à função curve(), como mostrado nos códigos abaixo.\n\ncurve(dt(x, df = 5), \n      xlim = c(-4,4) )\n\n\n\n\nPodemos inserir várias curvas num mesmo gráfico, usando o argumento add=TRUE.\n\ncurve(dnorm(x),   col=\"black\", xlim=c(-5,5), ylim=c(0,0.4), ylab=\"Densidade\")\ncurve(dt(x,df=20),col=\"brown\", add=TRUE)\ncurve(dt(x,df=5), col=\"blue\",  add=TRUE)\ncurve(dt(x,df=2), col=\"red\",   add=TRUE)\ncurve(dt(x,df=1), col=\"green\", add=TRUE)\nlegend(x = 2.4, y = 0.41, lty=1, \nlegend = c(\"normal curve\",\"t, df=20\",\"t, df=5\",\"t, df=2\",\"t, df=1\"),\ncol =    c(       \"black\",   \"brown\",   \"blue\",    \"red\",  \"green\"))\n\n\n\n\n\n\n15.4.3 pt()\nA função pt(q) é utilizada para calcular a função de distribuição acumulada (CDF) da distribuição t de Student. Ela fornece a probabilidade de que uma variável aleatória com uma distribuição t de Student seja menor ou igual a um determinado valor x. Ou seja, calcula área abaixo da curva de distribuição t, à esquerda de q (quantile).\nOs argumentos dessa função são o quantile (q) e os graus de liberdade da curva t (df). O código e o gráfico abaixo mostram o resultado da função pt() e a a interpretação visual da função.\n\npt(q = 2, df = 5)\n\n[1] 0.9490303\n\n\n\n\n\n\n\n\n\n15.4.4 qt()\nA função qt(), faz o inverso da função pt(): dada uma área abaixo da curva de distribuição t, a função retorna o quantile (q) que delimita essa área à esquerda. Os argumentos dessa função são a área em decimais (p) e os graus de liberdade da curva t (df). O resultado da função é o quantile.\n\nqt(p = 0.9490303, df = 5)\n\n[1] 2.000001"
  },
  {
    "objectID": "14-Distributions.html#distribuição-chi-quadrado",
    "href": "14-Distributions.html#distribuição-chi-quadrado",
    "title": "15  Distribuições de Probabilidade",
    "section": "15.5 Distribuição Chi-quadrado",
    "text": "15.5 Distribuição Chi-quadrado\nA distribuição qui-quadrado é frequentemente usada em testes estatísticos, como o teste de independência em tabelas de contingência ou o teste de ajuste (goodness-of-fit).\n\n15.5.1 rchisq()\nA função rchisq() cria conjunto randomizado de números a partir de um distribuição Chi quadrado. Os argumentos dessa função são: a quantidade de números e os graus de liberdade (degrees of freedom - df).\n\nset.seed(1)\ny <- rchisq(n = 1000, df = 3)\nplot(density(y))\n\n\n\n\n\n\n15.5.2 dchisq()\nA função dchisq() é utilizada para calcular a função densidade de probabilidade (PDF) de uma distribuição qui-quadrado (\\(\\chi^2\\)). Ela retorna a densidade da função qui-quadrado para um dado valor x, ou seja, a altura da curva de densidade qui-quadrado naquele ponto específico.\nPodemos usar a função dchisq() para construir gráficos da distribuição chi-quadrado, da mesma forma como fizemos com a curva normal.\n\ncurve(dchisq(x, df=3), \n      col=\"black\",\n      xlim=c(0,30), \n      ylim=c(0,0.6),\n      ylab=\"Chi Square Density\")\n\n\n\n\nE também podemos usar a o argumento add=TRUE para inserir várias curvas no mesmo gráfico.\n\ncurve(dchisq(x, df=1 ),col=\"black\", xlim=c(0,30), ylim=c(0,0.6), ylab=\"Chi Square Density\")\ncurve(dchisq(x, df=2 ),col=\"red\",         add=TRUE)\ncurve(dchisq(x, df=3 ),col=\"blue\",        add=TRUE)\ncurve(dchisq(x, df=5 ),col=\"dark green\",  add=TRUE)\ncurve(dchisq(x, df=10),col=\"brown\",       add=TRUE)\nlegend(x = 25, y = 0.55, \n       legend = c(\"df=1\",\"df=2\",\"df=3\",\"df=5\",\"df=10\"),\n       col    = c(\"black\",\"red\",\"blue\",\"dark green\",\"brown\"),\n       lty=1)\n\n\n\n\nAs funções pchisq(), qchisq() funcionam da mesma forma que suas correspondentes na distribuição normal e t de Student, como já discutido anteriormente, lembrando que o parâmetro da distribuição chi-quadrado são os graus de liberdade (degrees of freedom - df).\n\n\n15.5.3 pchisq()\nA função pchisq em R é usada para calcular a distribuição acumulada (CDF) da distribuição qui-quadrado (\\(\\chi^2\\)). Os principais argumentos da função pchisq() são:\n\nq é o valor da estatística qui-quadrado para o qual você deseja calcular a probabilidade acumulada.\ndf é o número de graus de liberdade da distribuição.\n\nPor padrão a funçõa retorna probabilidade acumulada do valor da estatística ser menor ou igual a q. Caso deseje a probabilidade de ser maior ou igual a q é necessário acrescentar o argumento lower.tail=FALSE\nSuponha que você tenha uma estatística qui-quadrado de 5.991 e 2 graus de liberdade e queira calcular a probabilidade acumulada P(x ≤ 5.991)\n\npchisq(q = 6, df = 2)\n\n[1] 0.9502129\n\n\nO gráfico abaixo visualiza o uso da função pchisq(q = 5.991, df = 2)\n\n\n\n\n\n\n\n15.5.4 qchisq()\nA função qchisq() é o oposto da pchisq(). É usada para calcular o quantil da distribuição qui-quadrado. Em outras palavras, ela encontra o valor q tal que a probabilidade acumulada até q seja igual a um dado valor de probabilidade p. Isso é útil em testes de hipóteses e intervalos de confiança onde se deseja encontrar os pontos críticos da distribuição qui-quadrado.\n\nqchisq(p =0.9502129, df = 2)\n\n[1] 5.999999"
  },
  {
    "objectID": "14-Distributions.html#distribuição-de-poisson",
    "href": "14-Distributions.html#distribuição-de-poisson",
    "title": "15  Distribuições de Probabilidade",
    "section": "15.6 Distribuição de Poisson",
    "text": "15.6 Distribuição de Poisson\nAs funções para distribuição de Poisson seguem o mesmo padrão das anteriores:\n\nrpois() cria conjunto randomizado de números numa distribuição de Poisson.\ndpois() calcula a função de densidade de probabilidade (PDF) da distribuição Poisson. O primeiro argumento é o ponto no eixo x do qual se pretende saber o valor da densidade de probabilidade, o segundo argumento é o parâmetro lambda.\nppois() calcula a função de distribuição acumulada (CDF) da distribuição de Poisson, ou seja, calcula a probabilidade de que uma variável aleatória com uma distribuição de Poisson seja menor ou igual a um determinado valor x.\nqpois() calcula o quantil de uma distribuição de Poisson, ou seja, retorna o valor x tal que a probabilidade acumulada P(X≤x)seja igual a uma probabilidade especificada p."
  },
  {
    "objectID": "14-Distributions.html#resumo",
    "href": "14-Distributions.html#resumo",
    "title": "15  Distribuições de Probabilidade",
    "section": "15.7 Resumo",
    "text": "15.7 Resumo\nO R possui essas funções de densidade, densidade cumulativa, quantil e numeros randomizados para diversas funções. O quadro abaixo resume esse capítulo.\n\n\n\n\n\n\n\n\n\n\nDistribuição\nPDF (d)\nCDF (p)\nQuantil (q)\nAleatório (r)\n\n\n\n\nNormal\ndnorm\npnorm\nqnorm\nrnorm\n\n\nBinomial\ndbinom\npbinom\nqbinom\nrbinom\n\n\nPoisson\ndpois\nppois\nqpois\nrpois\n\n\nQui-quadrado\ndchisq\npchisq\nqchisq\nrchisq\n\n\nt de Student\ndt\npt\nqt\nrt\n\n\nF\ndf\npf\nqf\nrf\n\n\nExponencial\ndexp\npexp\nqexp\nrexp\n\n\nGamma\ndgamma\npgamma\nqgamma\nrgamma\n\n\nBeta\ndbeta\npbeta\nqbeta\nrbeta\n\n\nGeométrica\ndgeom\npgeom\nqgeom\nrgeom\n\n\nHipergeométrica\ndhyper\nphyper\nqhyper\nrhyper\n\n\nBinomial Negativa\ndnbinom\npnbinom\nqnbinom\nrnbinom\n\n\nUniforme\ndunif\npunif\nqunif\nrunif\n\n\nWeibull\ndweibull\npweibull\nqweibull\nrweibull\n\n\nLog-normal\ndlnorm\nplnorm\nqlnorm\nrlnorm\n\n\nMultinomial\ndmultinom\n-\n-\nrmultinom\n\n\nCauchy\ndcauchy\npcauchy\nqcauchy\nrcauchy\n\n\nBeta-Binomial\ndbetabinom (MASS)\npbetabinom (MASS)\nqbetabinom (MASS)\nrbetabinom (MASS)\n\n\nNormal Inversa\ndinvgauss (statmod)\npinvgauss (statmod)\nqinvgauss (statmod)\nrinvgauss (statmod)\n\n\nPareto\ndpareto (VGAM)\nppareto (VGAM)\nqpareto (VGAM)\nrpareto (VGAM)\n\n\n\n\n\n\n\nGordon, Sue. 2006. The Normal Distribution. Sydney: Mathematics Learning Centre, University of Sydney.\n\n\nSilva, SC d, and WD Monteiro. 2009. “Levantamento Do Perfil Antropométrico Da População Brasileira Usuária Do Transporte Aéreo Nacional–Projeto Conhecer.” Journal Article. Publicação Técnica Do Acervo Da Anac.\n\n\nStahl, Saul. 2006. “The Evolution of the Normal Distribution.” Mathematics Magazine 79 (2): 96–113."
  },
  {
    "objectID": "15-Simulations.html#sequências-no-r",
    "href": "15-Simulations.html#sequências-no-r",
    "title": "16  Simulações",
    "section": "16.1 Sequências no R",
    "text": "16.1 Sequências no R\n\n16.1.1 Operador de Sequenciação\nÀs vezes precisamos criar uma sequência, e o modo mais fácil de criar uma sequencia numérica é usar a função c() juntamente com o operador :.\nIremos criar diversas sequências a armazenar o resultado em variáveis. Lembre-se que para mostrar o conteúdo das variável, basta digitar o nome da variável. Nas linhas de código a seguir faremos desse modo.\nCriando uma sequencia crescente de 1 em 1\n\n# cria uma sequencia crescente de 1 a 10\nx2 <- c(1:10)\nx2\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nCriando uma sequencia decrescente de 1 em 1\n\n# cria uma sequencia decrescente de 20 a 10\nx3 <- c(20:10)\nx3\n\n [1] 20 19 18 17 16 15 14 13 12 11 10\n\n\nCriando sequencia variadas\n\n# cria uma sequencia de 1 a 10\n# depois insere o número 20, \n# e depois cria uma nova sequencia de 30 a 40\nx4 <- c(1:10, 20, 30:40)\nx4\n\n [1]  1  2  3  4  5  6  7  8  9 10 20 30 31 32 33 34 35 36 37 38 39 40\n\n\nQuando precisamos de sequencia numérica com intervalos diferentes de 1, é preciso usar a função seq(), na qual podemos especificar o tamanho da diferença entre os números.\n\n\n16.1.2 A função seq()\nUsando seq() com argumentos explícitos\nA função seq() tem como argumentos o valor inicial da sequencia (from) , o valor final (to) e o tamanho do salto entre cada elemento da sequencia (by) .\n\n#cria uma sequencia de 1 a 10, aumentando 1 de cada vez, explicitando os argumentos\nseq(from = 1, to = 10, by = 1)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nUsando seq() com argumentos na ordem\nArgumentos podem ser também passados para a função apenas colocando-os na ordem correta. Toda função tem uma ordem de apresentação dos argumentos. Podemos explicitar isso como fizemos antes, ou apenas inserir na ordem correta como abaixo.\n\n#cria uma sequencia de 1 a 10, aumentando 1 de cada vez\nseq(1, 10, 1)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nUsando a função seq() estipulando um intervalo de 0.5\n\n# cria uma sequencia de 1 a 10 aumentando 0.5 de cada vez\nseq(1, 10, 0.5)\n\n [1]  1.0  1.5  2.0  2.5  3.0  3.5  4.0  4.5  5.0  5.5  6.0  6.5  7.0  7.5  8.0\n[16]  8.5  9.0  9.5 10.0\n\n\nUsando a função seq() com intervalo negativo\n\n# cria uma sequencia de 5 até 1, diminuindo 0.2 a cada vez\nseq(5, 1, -0.2)\n\n [1] 5.0 4.8 4.6 4.4 4.2 4.0 3.8 3.6 3.4 3.2 3.0 2.8 2.6 2.4 2.2 2.0 1.8 1.6 1.4\n[20] 1.2 1.0"
  },
  {
    "objectID": "15-Simulations.html#replicações-no-r",
    "href": "15-Simulations.html#replicações-no-r",
    "title": "16  Simulações",
    "section": "16.2 Replicações no R",
    "text": "16.2 Replicações no R\nNo R, a replicação é uma operação comum que envolve a criação de múltiplas cópias de elementos ou a execução de uma operação várias vezes. As funções rep() e replicate() são essenciais para essas tarefas, embora sirvam a propósitos diferentes.\n\n16.2.1 Diferenças Entre rep() e replicate()\n\nObjetivo: rep() é usado para replicar elementos de um vetor, enquanto replicate() é usado para executar uma expressão ou função várias vezes e coletar os resultados.\nTipo de Retorno: rep() retorna um vetor com elementos repetidos. replicate() retorna uma matriz ou lista com os resultados de cada execução.\nFlexibilidade: rep() é útil para a criação de vetores repetitivos. replicate() é mais adequado para simulações e execuções repetidas de código que geram resultados variáveis.\n\n\n\n16.2.2 A Função rep()\nA função rep() é usada para replicar elementos de vetores. Ela pode ser útil quando você precisa criar um vetor com elementos repetidos. Vamos ver alguns exemplos para entender melhor seu uso.\nExemplo 1: Replicando um Valor\n\n# Replicar o número 5, três vezes\nrep(5, times = 3)\n\n[1] 5 5 5\n\n\nExemplo 2: Replicando um Vetor de Valores\n\n# Replicar cada elemento do vetor c(1, 2, 3) duas vezes\nrep(c(1, 2, 3), each = 2)\n\n[1] 1 1 2 2 3 3\n\n\nExemplo 3: Replicando com Variação na Quantidade de Repetições\n\n# Replicar 1 duas vezes, 2 três vezes e 3 quatro vezes\nrep(c(1, 2, 3), times = c(2, 3, 4))\n\n[1] 1 1 2 2 2 3 3 3 3\n\n\nComo podemos ver, função rep() é bastante flexível, permitindo especificar quantas vezes cada elemento deve ser repetido (times) ou quantas vezes cada elemento do vetor deve ser repetido (each).\n\n\n16.2.3 A Função replicate()\nA função replicate() é usada para executar uma expressão ou função várias vezes e coletar os resultados. Isso é particularmente útil em simulações ou ao executar experimentos repetitivos.\nExemplo 1: Gerando Números Aleatórios\nO R tem diversas funções para gerar números aleatórios, como veremos logo adiante. Podemos usar replicate para criar diversos conjuntos diferentes de números aleatórios. Observe que a função replicate() retorna uma matriz, onde as colunas representam cada uma das repetições e as linhas representam os números sorteados em cada repetição.\n\n# Gerar 10 números aleatórios uniformemente distribuídos\n# Repetir esse processo 5 vezes com replicate\nreplicate(5, runif(10))\n\n            [,1]      [,2]       [,3]       [,4]       [,5]\n [1,] 0.21228265 0.3898527 0.47250740 0.66893374 0.11679406\n [2,] 0.81791667 0.2932496 0.81111416 0.55426047 0.91309153\n [3,] 0.60420456 0.1436612 0.71070608 0.73446399 0.69216421\n [4,] 0.53139076 0.9492934 0.02820865 0.45827503 0.08667835\n [5,] 0.37209148 0.8001112 0.39547869 0.82761985 0.07331102\n [6,] 0.90078042 0.9072131 0.67765159 0.79189772 0.69531865\n [7,] 0.11155626 0.4810397 0.83073469 0.08170767 0.43677271\n [8,] 0.52782209 0.1058414 0.40308648 0.76341006 0.64732959\n [9,] 0.07135281 0.4281111 0.35877118 0.26363395 0.71742911\n[10,] 0.82673397 0.9499041 0.28812038 0.34217073 0.34609796\n\n\n\n# replicando usando o pipe\nrunif(10) |>\n  replicate(n=5)\n\n           [,1]       [,2]       [,3]         [,4]      [,5]\n [1,] 0.4276656 0.05239424 0.26473307 0.8189127853 0.1175897\n [2,] 0.4514042 0.70997147 0.33645159 0.4295855190 0.8324378\n [3,] 0.7002073 0.56553790 0.86474613 0.4206835285 0.9065337\n [4,] 0.4801440 0.53026183 0.99346041 0.4181123921 0.9237536\n [5,] 0.6520919 0.76549550 0.46048373 0.8960186415 0.8406329\n [6,] 0.3284826 0.76361023 0.68066410 0.4568664816 0.7878139\n [7,] 0.2904079 0.88558643 0.29670625 0.7031281483 0.6662839\n [8,] 0.7572216 0.13903266 0.08955807 0.0003899853 0.9099544\n [9,] 0.8782428 0.76157075 0.41829749 0.3345950115 0.1778778\n[10,] 0.1630282 0.68533733 0.67547044 0.5825106851 0.4430018\n\n\nExemplo 2: Simulação de Lançamento moeda\nComo veremos no capítulo sobre simulação, a função sample() server para realizarmos amostragens. Podemos usar a função replicate() para simular várias repetições de amostragens.\nVamos criar um objeto simulando uma moeda e usar a função sample() para sortear um dos valores desse objeto (cara ou coroa). O argumento replace = TRUE é necessário, pois os valores possíveis podem ser repetido em cada sorteio.\n\n# cria o objeto moeda\nmoeda <- c(\"cara\",\"coroa\")\n\n# Simular o lançamento de uma moeda 3 vezes\nsample(moeda,2, replace = TRUE)\n\n[1] \"coroa\" \"coroa\"\n\n\nAgora que entendemos o funcionamento de sample(), podemos replicar esses dois lançamentos várias vezes com a função replicate().\n\n# replicando 5 vezes os dois lançamentos\nreplicate(n=5, sample(moeda, 2))\n\n     [,1]    [,2]    [,3]    [,4]    [,5]   \n[1,] \"cara\"  \"coroa\" \"cara\"  \"cara\"  \"coroa\"\n[2,] \"coroa\" \"cara\"  \"coroa\" \"coroa\" \"cara\""
  },
  {
    "objectID": "15-Simulations.html#números-aleatórios",
    "href": "15-Simulations.html#números-aleatórios",
    "title": "16  Simulações",
    "section": "16.3 Números Aleatórios",
    "text": "16.3 Números Aleatórios\nNúmeros aleatórios são valores gerados de tal forma que cada número tem a mesma probabilidade de ser escolhido. Eles desempenham um papel essencial em diversas áreas da ciência e tecnologia, permitindo a criação de simulações, modelagens estatísticas e testes que replicam a aleatoriedade do mundo real.\nNa ciência, a geração de números aleatórios é fundamental por várias razões. As simulações, por exemplo, permitem replicar fenômenos naturais ou processos clínicos, como a progressão de doenças ou a resposta a tratamentos, de maneira controlada. Na amostragem, a seleção aleatória de amostras de uma população garante que cada membro tenha a mesma chance de ser incluído, o que é crucial para a validade estatística dos estudos. Em ensaios clínicos, a randomização dos pacientes para diferentes grupos de tratamento minimiza o viés e assegura que os grupos sejam comparáveis, promovendo resultados mais confiáveis.\nA geração de números aleatórios também permite criar conjuntos numéricos que seguem diferentes distribuições estatísticas, como a distribuição uniforme, onde todos os valores dentro de um intervalo têm a mesma probabilidade de ocorrer; a distribuição normal, onde a maioria dos valores se concentra em torno da média, formando a conhecida curva em forma de sino; e a distribuição exponencial, usada para modelar o tempo entre eventos independentes que ocorrem a uma taxa constante.\nA história da geração de números aleatórios na computação é bastante interessante. No início, métodos mecânicos, como roletas e sorteios com cartas, eram usados para gerar números aleatórios. Com o advento dos computadores, a necessidade de métodos mais rápidos e eficientes levou ao desenvolvimento de algoritmos que usam uma fórmulas matemática para produzir uma sequência de números pseudoaleatórios. Embora esses números não sejam verdadeiramente aleatórios, eles são suficientemente aleatórios para a maioria das aplicações práticas.\nOs números pseudoaleatórios gerados por algoritmos, produzem sequências de números que parecem aleatórios, mas que na verdade seguem uma lógica predefinida. Esses algoritmos começam com um valor inicial chamado de “semente” (ou “seed” em inglês). Se a mesma semente for usada, a sequência de números gerada será sempre a mesma. Em inúmeras situações é importante definir o valor inicial do gerador de números pseudoaleatórios. Ao fixar essa semente, você garante que os resultados da geração de números aleatórios possam ser reproduzidos. Isso significa que, se você e outra pessoa executarem o mesmo código com a mesma semente, ambos obterão exatamente os mesmos números aleatórios.\nNa linguagem R a função set.seed() define o valor inicial do gerador de números pseudoaleatórios. Ao fixar essa semente, você garante que os resultados da geração de números aleatórios possam ser reproduzidos. Isso significa que, se você e outra pessoa executarem o mesmo código com a mesma semente, ambos obterão exatamente os mesmos números aleatórios.\nNo capítulo de Simulações mostramos que podemos cirar conjuntos de números aleatórios com diferentes distribuições, usando as funções runif() (distribuição uniforme), rnorm() (distribuição normal), rt() (distribuição t), rchisq() (distribuição Chi-quadrado) etc.\nVeremos a seguir como usar o R para realizar amostragens e como associar as funções de randomização com as funções de amostragem."
  },
  {
    "objectID": "15-Simulations.html#amostragens",
    "href": "15-Simulations.html#amostragens",
    "title": "16  Simulações",
    "section": "16.4 Amostragens",
    "text": "16.4 Amostragens\nO R possui uma função para simular amostras randomizadas: a função sample(). O primeiro argumento dessa função é a população (objeto que contenha os valores da população). O segundo argumento é o tamanho a amostra a ser retirada.\n\n# Selecionando, de forma aleatória, 5 números entre 1 e 10\nx <- 1:10\nsample(x, 5)\n\n[1]  6  9 10  2  8\n\n\nPara obtermos sempre os mesmos resultados precisamos definir a semente com set.seed().\n\nset.seed(5)\nx <- 1:10\nsample(x, 5)\n\n[1] 2 9 7 3 1\n\n\nPor padrão essa função realiza uma amostragem sem reposição, ou seja, uma vez retirada o elemento, esse mesmo elemento não pode ser retirado novamente. Por exemplo, se desejo simular um jogo de bingo, no qual há 100 bolinhas, não podemos retirar a mesma bolinha mais de uma vez. Esse é um exemplo de retirada sem reposição. O código abaixo simularmo uma sequencia aletória de retirada de 5 bolinhas de bingo num total de 100:\n\nx <- 1:100\nsample(x, 5)\n\n[1] 41 85 94 71 19\n\n\nPara simularmos situações nas quais é possível a repetição de um determinado elemento, precisamos alterar o parametro replace para replace=TRUE.\nPor exemplo, imagine que queremos simular a jogada de dois dados. Cada dado pode resultar em um valor de 1 a 6. Nesse caso, queremos sortear dois números de 1 a 6, mas é possível repetir o valor, pois os dados podem mostrar o mesmo valor.\n\nsample(1:6, 2, replace = TRUE)\n\n[1] 3 6\n\n\nA função replicate() nos permite repetir uma expressão várias vezes. Isso é útil para simular experimentos repetidamente. O resultado do código abaixo é uma matriz, onde as colunas representam cada uma das 10 repetições e as linhas representam os números sorteados em cada repetição.\n\n# Replicando 10 vezes a amostragem de 2 números entre 1 e 6\nx <- 1:6\nreplicate(n=10, sample(x, 2))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    2    4    5    1    3    5    2    1    6     5\n[2,]    5    2    3    4    2    2    3    2    4     3\n\n\nO código acima pode ser escrito de forma mais suscinta como abaixo, sem a criação de uma variável intermediária.\n\nreplicate(10, sample(1:6, 2))\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    6    1    2    4    4    3    5    6    3     3\n[2,]    2    2    4    6    5    4    3    5    6     2\n\n\nO código acima pode ser escrito de forma mais elegante com o uso do operador pipe:\n\nsample(1:6, 2) |>\n  replicate(n=10)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    4    2    6    5    1    1    5    3    4     4\n[2,]    1    4    4    2    4    4    2    1    3     3\n\n\nPodemos associar as funções de geração de números aleatórios para criar o conjunto de dados a ser usado na função sample() como a seguir:\n\n# cria um conjunto de números distribuidos de forma normal com média = 0 e desvio padrão = 1\nx <- rnorm(100) \n# Sorteia 5 desses números\nsample(x, 5)\n\n[1]  0.9000620  1.2780023  0.8389508 -1.7256622 -1.3614312\n\n\nOu usando o pipe:\n\nrnorm(100) |> sample(5)\n\n[1] -0.04019016  0.72640902  1.89762159  0.66753870  0.30438718\n\n\nFinalmente, a função sample não se limita a números. Podemos criar conjuntos de texto para serem sorteados. Por exemplos, nomes de pessoas ou cores. Podemos simular a jogada de uma moeda, com valores sendo nesse caso cara ou coroa.\n\nmoeda <- c(\"cara\", \"coroa\")\nsample(moeda, 1)\n\n[1] \"coroa\""
  },
  {
    "objectID": "15-Simulations.html#simulações-de-monte-carlo",
    "href": "15-Simulations.html#simulações-de-monte-carlo",
    "title": "16  Simulações",
    "section": "16.5 Simulações de Monte Carlo",
    "text": "16.5 Simulações de Monte Carlo\n\n16.5.1 Introdução\nA Simulação de Monte Carlo é uma técnica matemática e estatística que utiliza a geração de números aleatórios para realizar inúmeros experimentos virtuais no computador, explorando todas as formas possíveis que uma situação pode ocorrer. Isso ajuda a entender melhor as probabilidades de diferentes resultados.\nO procedimento dessa simulação geralmente envolve algumas etapas:\n\nDefinir o sistema ou processo que você quer estudar.\nGerar números aleatórios que seguem as regras do modelo.\nRepetir o processo muitas vezes para obter uma distribuição de resultados.\nEstudar os resultados gerados para fazer previsões ou tomar decisões.\n\nPor exemplo, Imagine que você está jogando roleta em um cassino e quer calcular a probabilidade de ganhar ao apostar no número 7. Em uma roleta europeia, há 37 casas numeradas de 0 a 36.\nPassos da Simulação de Monte Carlo:\n\nModelo do poblema: a roleta tem 37 casas (0 a 36) e você ganha se a bola cair no número 7.\nGerar resultados aleatórios: simular várias rodadas de roleta para ver quantas vezes a bola cai no número 7.\nRepetir várias vezes: repetir a simulação muitas vezes (por exemplo, 10.000 vezes) para obter uma distribuição dos resultados.\nAnalisar os resultados: calcular a proporção de vezes que você ganhou (bola caiu no número 7).\n\n\n# Definindo parâmetros do modelo\nnumero_de_rodadas <- 10000\nnumero_vencedor   <- 7\n\n# Simulando a roleta\nset.seed(123)  # Para reprodutibilidade\nresultados <- sample(0:36, numero_de_rodadas, replace = TRUE)\n\n# Contando quantas vezes saiu o número vencedor\nvitorias <- sum(resultados == numero_vencedor)\n\n# Calculando a proporção de vitórias\nproporcao_vitorias <- vitorias / numero_de_rodadas\n\n# Exibindo resultados\ncat(\"Proporção de vitórias ao apostar no número 7:\", proporcao_vitorias, \"\\n\")\n\nProporção de vitórias ao apostar no número 7: 0.0265 \n\n\nA simulação de Monte Carlo não é apenas útil para calcular probabilidades em jogos de azar, mas também é amplamente utilizada em matemática e ciência para estimar diversas outras condições. Uma aplicação comum é a estimativa da área abaixo de uma curva.\n\n\n16.5.2 Estimando Áreas com a Simulação de Monte Carlo\nVamos demonstrar como a Simulação de Monte Carlo pode ser usada para calcular a área abaixo da curva da função \\(y = x^2\\) entre os valores 4 e 6. A área abaixo da curva pode ser estimada como sendo a área do retangulo entre os pontos 4 e 6 multiplicada pela razão entre da área abaixo da curva a a área do quadrado. Entretanto, a área abaixo da curva é justamente o que queremos saber.\nA Simulação de Monte Carlo pode nos ajudar nesse problema, pois podemos fazer uma analogia da área numa região com a quantidade de pontos aleatórios que cabem nessa região. Assim, podemos estimar essa proporção entra as áreas através da razão entre a quantidade de pontos aleatórios que caem abaixo da curva pelo total de pontos dentro do retângulo.\n\\[\n\\frac{\\text{Área abaixo da curva}}{\\text{Área do retângulo}} = \\frac{\\text{pontos abaixo da curva}}{\\text{pontos totais no retangulo}}   \n\\]\nou seja,\n\\[\n{\\text{Área abaixo da curva}} = {\\text{Área do retângulo}} * {\\frac{\\text{pontos abaixo da curva}}{\\text{pontos totais}}}\n\\]\n\n\n\n\n\n\n\n\n\n\nPara estimar a área sob a curva usando a simulação de Monte Carlo, seguimos os seguintes passos:\n\nDefinir o modelo: No nosso caso, o mnodelo é a função \\(y = x^2\\) e os limites são x = 4 e x = 6.\nGerar Pontos Aleatórios: Geramos pontos aleatórios dentro do retângulo que envolve a região de interesse. Este retângulo vai de x = 3 a x = 4 e de y = 0 até o valor máximo de y neste caso, y = 16 porque \\(4^2 = 16\\)).\nContar Pontos Abaixo da Curva: Verificamos quantos pontos aleatórios caem abaixo da curva \\(y = x^2\\).\nCalcular a Área: A proporção de pontos abaixo da curva, multiplicada pela área do retângulo, nos dá a estimativa da área abaixo da curva.\n\nVamos implementar isso no R.\n\n# Definindo o modelo e os limites\nf <- function(x) x^2\nx_min <- 4\nx_max <- 6\ny_min <- 0\ny_max <- f(x_max)\n\n# Definindo o número de pontos aleatórios a serem gerados\nn_pontos <- 10000\n\n# Gerando pontos aleatórios\nset.seed(123)  # Para reprodutibilidade\nx <- runif(n_pontos, min = x_min, max = x_max)\ny <- runif(n_pontos, min = y_min, max = y_max)\n\n# Verificando quantos pontos estão abaixo da curva\n# variável lógica que será verdadeira se y for menor que x^2\nabaixo_da_curva     <- y <= f(x) \n\n# podemos somar os valores verdadeiros, pois no R  TRUE tem o valor = 1\npt_abaixo_da_curva <- sum(abaixo_da_curva)\n\n# Calculando a área\narea_retangulo <- (x_max - x_min) * (y_max - y_min)\narea_estimada  <- area_retangulo * (pt_abaixo_da_curva / n_pontos) \n\n# Exibindo o resultado\ncat(\"A área estimada abaixo da curva y = x^2 entre x = 4 e x = 6 é aproximadamente:\", area_estimada, \"\\n\")\n\nA área estimada abaixo da curva y = x^2 entre x = 4 e x = 6 é aproximadamente: 50.5368 \n\n\n\n\n16.5.3 Explicação do Código\n\nDefinindo os Limites de Integração e a Função\n\nDefinimos a função \\(f(x)=x^2\\).\nx_min e x_max são os limites inferiores e superiores do intervalo de integração (4 e 6, respectivamente).\ny_min é 0 e y_max é \\(f(xmax)=36\\).\n\nNúmero de Pontos Aleatórios a Serem Gerados\n\nn_pontos é definido como 10.000.\n\nGerando Pontos Aleatórios\n\nUsamos runif para gerar pontos aleatórios distribuídos uniformemente no intervalo x entre \\([4, 6]\\) e de y no intervalo \\([0, 36]\\).\n\nVerificação de Pontos Abaixo da Curva\n\nUsamos a condição y <= f(x) para verificar quantos pontos estão abaixo da curva \\(y=x^2\\).\n\nCálculo da Área\n\nCalculamos a área do retângulo como \\((xmax−xmin)×(ymax−ymin)\\)\nA área estimada é obtida multiplicando a proporção de pontos abaixo da curva pela área do retângulo.\n\nExibição do Resultado\n\nEsse código calculará a área abaixo da curva \\(y=x^2\\) entre \\(x=4\\) e \\(x=6\\) usando a simulação de Monte Carlo.\n\n\nVamos exemplificar também o uso da Simulação de Monte Carlo para calcular o valor de \\(\\pi\\), seguindo o exemplo do livro Programming for Analytics in R de John Paul Helveston https://p4a.jhelvy.com/monte-carlo-methods.\n\n\n\n\n\nSabemos que a área do círculo é calculada com \\(A=\\pi*r^2\\). Se desenharmos um quadrado contendo o círculo, a área desse quadrado será \\(A=(2r)^2\\) ou \\(A=4r^2\\).\n\nSe fizermos a razão da área do círculo pela área do quadrado obteremos:\n\\(R=\\frac{\\pi r^2}{4r^2}\\) que pode ser simplificada para \\(R=\\frac{\\pi}{4}\\).\nOu seja \\(\\pi=4R\\)\nEntão, para calcular \\(\\pi\\), basta multiplicar por 4 a razão entre a área do círculo e a do quadrado.\nA Simulação de Monte Carlo nos permite fazer um aproximação dessa razão. Podemos criar muitos pontos aleatórios no quadrado e depois simplesmente contar o número que estão dentro do círculo. A proporção desses pontos dentro com o total será a aproximação da razão da áreas.\nPrimeiro, vamos gerar um conjunto aleatório de pontos em um quadrado e depois determinar quais estão dentro do círculo.\nPara criar os pontos, usaremos um quadrado com comprimento lateral de 1 centrado em (x, y) = (0, 0), então nossos pontos precisam estar entre as coordenadas x = (-0,5, 0,5) e y = (- 0,5, 0,5):\n\ntrials <- 10000\npontos <- data.frame(x = runif(trials, -0.5, 0.5),\n                     y = runif(trials, -0.5, 0.5))\n\nPara determinar quais pontos estão dentro do círculo (que tem um raio de 0,5), basta calcular a distância de cada ponto até o centro, o que nada mais é que a diagonal de um triângulo, que pode ser calculada com o teorema de pitágoras. Se essa diagonal for menor que o raio, então o ponto está dentro do círculo. Para isso iremos criar uma variável lógica chamada pontosDentro, que terá o valor TRUE se o ponto estiver dentro do círculo.\n\nlibrary(dplyr)\npontos <- pontos |>\n          mutate(raio = sqrt(x^2 + y^2),\n                 pontosDentro = raio <= 0.5)\nhead(pontos)\n\n            x           y      raio pontosDentro\n1  0.49112339 -0.41210770 0.6411201        FALSE\n2 -0.19776935  0.27961148 0.3424840         TRUE\n3 -0.06624099 -0.21883268 0.2286386         TRUE\n4 -0.33947909  0.04969904 0.3430977         TRUE\n5  0.32302671 -0.30539315 0.4445348         TRUE\n6 -0.29190945 -0.16056017 0.3331527         TRUE\n\n\nO desenho abaixo mostra a simulação, colorindo de forma diferentes os pontos dentro e fora do círculo:\n\nlibrary(ggplot2)\nggplot(pontos) +\n    geom_point(aes(x = x, y = y, color = pontosDentro), size = 0.5) +\n    coord_fixed( ratio=1) +\n    theme_minimal()\n\n\n\n\nAgora basta calcular a proporção de pontos dentro do círculo.\n\ndentro <- sum(pontos$pontosDentro)\ntotal  <- nrow(pontos)\nR <- dentro/total\npiApprox <- 4 * R\npiApprox\n\n[1] 3.1524\n\n\nSe aumentarmos a quantidade de pontos o valor de \\(\\pi\\) fica bem mais próximo do verdadeiro.\n\ntrials <- 10000000\npontos <- data.frame(x = runif(trials, -0.5, 0.5),\n                     y = runif(trials, -0.5, 0.5)) |>\n          mutate(raio = sqrt(x^2 + y^2),\n                 pontosDentro = raio <= 0.5)\n\nR <- sum(pontos$pontosDentro) / nrow(pontos)\npiApprox <- 4 * R\npiApprox\n\n[1] 3.141812"
  },
  {
    "objectID": "15-Simulations.html#bootstrapping",
    "href": "15-Simulations.html#bootstrapping",
    "title": "16  Simulações",
    "section": "16.6 Bootstrapping",
    "text": "16.6 Bootstrapping\nO bootstrap é um método computacional para estimar a precisão de medidas estatísticas, baseado na reamostragem com reposição (replacement). Um dos principais uso do Boostrap é para calcular o intervalo de confiança para qualquer tipo de medida estatística (Dogan 2017).\nO método de bootstrap simples envolve pegar o conjunto de dados original, usando um computador, fazer uma amostragem com reposição para formar uma nova amostra (chamada de reamostra, amostra de bootstrap ou boostrap sample) que também é de tamanho N. A amostra de bootstrap é retirada de o original usando amostragem com substituição (por exemplo, podemos ‘reamostrar’ 5 vezes de [1,2,3,4,5] e obter [2,5,4,4,1]). Esse processo é repetido milhares de vezes. Em seguida, para cada uma dessas amostras de bootstrap, calculamos a estatística de interesse, chamada de “estimativa de bootstrap e seu intervalo de confiança.\nEntretanto, excetuando-se a média, é muito difícil conhecer a precisão de outras estimativas. O algoritmo de boostrap serve justamente para isso, para estimarmos a precisão de medidas estatísticas.\nPra fins de exemplo, vamos comparar o intervalo de confiança de uma média calculado calculado com o método boostrap e calculado com a fórmula tradicional \\(\\bar{x} \\pm 1.96\\times \\frac{\\sigma}{\\sqrt{n}}\\), onde \\(\\bar{x}\\) é a média, \\({\\sigma}\\) é o desvio padrão e \\({n}\\) é o tamanho da amostra.\nSuponha que estamos interessados na altura média das pessoas de uma cidade. Não podemos medir todas as pessoas da cidade, por isso, em vez disso, amostramos apenas uma pequena parte dela. Suponha que a amostra seja de tamanho N; isto é, medimos as alturas de N indivíduos. Dessa única amostra, apenas uma estimativa da média pode ser obtida. Entretanto, precisamos de alguma noção da variabilidade da média que calculamos. Apesar ser fácil aavaliar o erro padrão da média, esse exemplo serve para entendermos como funciona o boostrap.\nPara fins desse exemplo, vamos usar gerar de forma randomizada uma população de 100.000 pessoas, com distribuição normal, com média de altura de 175cm e desvio padrão de 20cm. E vamos retirar desse população uma amostra com 200 pessoas. Em seguida vamos retirar uma amostra dessa população e então calcular o intervalo de confiança da média da população e da amostra.\n\npop <- rnorm(n = 100000, mean = 175, sd = 20 )\nOriginalSample <- sample(pop, 200, replace = FALSE)\n\nUm teste t pode nos fornecer o intervalo de confiança da população e de nossa amostra:\n\nt.test(pop)\n\n\n    One Sample t-test\n\ndata:  pop\nt = 2756.7, df = 99999, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 174.9009 175.1498\nsample estimates:\nmean of x \n 175.0254 \n\nt.test(OriginalSample)\n\n\n    One Sample t-test\n\ndata:  OriginalSample\nt = 124.98, df = 199, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 171.3353 176.8286\nsample estimates:\nmean of x \n  174.082 \n\n\nAgora vamos calcular o intervalo de confiança da média da população e da amostra usando o método de bootstrap. Primeiro vamos criar 1000 amostras de bootstrap.\n\nbootSamples <- replicate(1000, sample(OriginalSample, size = 100, replace = TRUE))\n\nAgora vamos calcular a média de cada uma das amostras de bootstrap e então calcular o intervalo de confiança.\n\n# criando uma vetor \"means\" com as médias de cada uma das amostras do boostrap\nmeans <- apply(bootSamples, 2, mean)\n\n\nlibrary(ggplot2)\nggplot() +\n  geom_histogram(aes(x = means), bins = 14, fill = \"lightgreen\", col=\"darkgreen\") +\n  geom_histogram(aes(x = OriginalSample), bins = 14, fill = \"lightblue\", col=\"blue\") +\n  geom_vline(xintercept = mean(OriginalSample), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Distribuição das alturas da amostra original\\ne das médias das alturas das amostras de bootstrap\",\n       x = \"Média\",\n       y = \"Frequência\") +\n  theme_minimal()\n\n\n\n\n\npar(mfrow = c(1, 2))\nhist(means,breaks = 14, main = \"Distribuição das médias das amostras de bootstrap\", col=\"lightgreen\")\nhist(OriginalSample, breaks = 14, main = \"Distribuição da amostra original\", col=\"lightblue\")\n\n\n\n\n\n\n\n\nDogan, C Deha. 2017. “Applying Bootstrap Resampling to Compute Confidence Intervals for Various Statistics with r.” Eurasian Journal of Educational Research 17 (68): 1–18."
  },
  {
    "objectID": "16-Datasets.html#diabetes",
    "href": "16-Datasets.html#diabetes",
    "title": "17  Datasets",
    "section": "17.1 diabetes",
    "text": "17.1 diabetes\nO dataset com dados de diabetes foi obtido no site do departamento de bio estatística da universidade de Vanderbilt no link abaixo. Consistem em 19 variáveis de 403 indivíduos, selecionados de um total de 1046 entrevistados, em um estudo sobre a prevalência de obesidade, diabetes e outros fatores de risco cardiovascular na população afro-americana da região central da Virgínia.\n\n# Código para ler o dataset diabetes do site da Universidade de Vanderbilt\ndiabetes <- read.csv(file = \"https://hbiostat.org/data/repo/diabetes.csv\")\n\nhttps://hbiostat.org/data"
  },
  {
    "objectID": "16-Datasets.html#iris",
    "href": "16-Datasets.html#iris",
    "title": "17  Datasets",
    "section": "17.2 iris",
    "text": "17.2 iris\nO conjunto de dados “iris” do ggplot2 contém 150 observações de três espécies de íris (Setosa, Versicolor, Virginica), com medições de comprimento e largura das sépalas e pétalas, em centímetros. É amplamente utilizado para demonstrações de técnicas de análise de dados e aprendizado de máquina.\n\n# código para acessar o dataset iris do ggplot2\n# lembre-se que será primeiro necessário instalar o pacote ggplot2\nlibrary(ggplot2)\ndata(iris)"
  },
  {
    "objectID": "16-Datasets.html#mpg",
    "href": "16-Datasets.html#mpg",
    "title": "17  Datasets",
    "section": "17.3 mpg",
    "text": "17.3 mpg\nO conjunto de dados “mpg” do ggplot2 contém 234 observações de veículos, com informações detalhadas sobre consumo de combustível, características do motor e especificações do carro. As variáveis incluem fabricante, modelo, cilindrada, ano, número de cilindros, tipo de transmissão, tipo de tração, consumo na cidade e na estrada, tipo de combustível e classe do veículo. Este conjunto de dados é amplamente utilizado para análises e visualizações relacionadas ao desempenho de veículos em termos de eficiência de combustível.\n\n# código para acessar o dataset mpg do ggplot2\n# lembre-se que será primeiro necessário instalar o pacote ggplot2\nlibrary(ggplot2)\ndata(mpg)"
  },
  {
    "objectID": "16-Datasets.html#mtcars",
    "href": "16-Datasets.html#mtcars",
    "title": "17  Datasets",
    "section": "17.4 mtcars",
    "text": "17.4 mtcars\nO conjunto de dados “mtcars” do R base contém 32 observações de modelos de carros, com informações detalhadas sobre eficiência de combustível, características do motor, e especificações do veículo. As variáveis incluem milhas por galão, número de cilindros, deslocamento, potência, relação do eixo traseiro, peso, tempo para percorrer um quarto de milha, tipo de motor, tipo de transmissão, número de marchas e número de carburadores. Este conjunto de dados é amplamente utilizado para análises estatísticas e visualizações relacionadas ao desempenho e características dos veículos. Não é necessário carregar nenhum pacote para ter acesso a esse dataset que faz parte do R base.\n\n# código para acessar o dataset mtcars\ndata(mpg)"
  },
  {
    "objectID": "16-Datasets.html#arthritis",
    "href": "16-Datasets.html#arthritis",
    "title": "17  Datasets",
    "section": "17.5 Arthritis",
    "text": "17.5 Arthritis\nO conjunto de dados “Arthritis” do pacote vcd do R contém 84 observações de pacientes de um estudo clínico sobre o tratamento da artrite. As variáveis incluem a identificação do paciente, tipo de tratamento (Placebo ou Tratamento), sexo, idade e grau de melhora dos sintomas (Nenhuma, Alguma, Marcante). Este conjunto de dados é amplamente utilizado para analisar a eficácia de tratamentos de artrite e explorar como fatores como idade e sexo podem influenciar os resultados do tratamento.\n\n# código para acessar o dataset Arthritis\n# lembre-se que será primeiro necessário instalar o pacote vcd\nlibrary(vcd)\n\nLoading required package: grid\n\ndata(\"Arthritis\")"
  },
  {
    "objectID": "16-Datasets.html#airquality",
    "href": "16-Datasets.html#airquality",
    "title": "17  Datasets",
    "section": "17.6 airquality",
    "text": "17.6 airquality\nO conjunto de dados “airquality” em R contém 153 observações de medições diárias de qualidade do ar na cidade de Nova York, durante os meses de maio a setembro de 1973. As variáveis incluem concentração de ozônio, radiação solar, velocidade do vento, temperatura, mês e dia da medição. Este conjunto de dados é amplamente utilizado para análises ambientais e de séries temporais, apesar de conter alguns valores faltantes. Não é necessário carregar nenhum pacote para ter acesso a esse dataset que faz parte do R base.\n\n# código para acessar o dataset airquality\ndata(airquality)"
  },
  {
    "objectID": "16-Datasets.html#plantgrowth",
    "href": "16-Datasets.html#plantgrowth",
    "title": "17  Datasets",
    "section": "17.7 PlantGrowth",
    "text": "17.7 PlantGrowth\nO conjunto de dados “PlantGrowth” em R contém 30 observações de pesos de plantas submetidas a três diferentes tratamentos (controle, tratamento 1 e tratamento 2). Cada grupo possui 10 plantas. Este conjunto de dados é utilizado principalmente para realizar análises estatísticas, como ANOVA, para investigar o efeito dos tratamentos no crescimento das plantas. Não é necessário carregar nenhum pacote para ter acesso a esse dataset que faz parte do R base.\n\n# código para acessar o dataset PlantGrowth\ndata(PlantGrowth)"
  },
  {
    "objectID": "17-Conclusion.html",
    "href": "17-Conclusion.html",
    "title": "18  Conclusão",
    "section": "",
    "text": "Ao longo deste manual, exploramos a linguagem R e suas inúmeras aplicações na análise de dados, com um foco especial no contexto da saúde. A jornada começou com uma introdução à importância da estatística na medicina, destacando como a análise de dados é essencial para uma prática médica baseada em evidências. Desde os primeiros passos na instalação do R e do RStudio, guiamos o leitor através das funcionalidades básicas e avançadas dessa poderosa ferramenta.\nAprender a linguagem R pode inicialmente parecer uma tarefa intimidante, especialmente para estudantes de medicina que podem não ter uma formação prévia em ciência da computação. No entanto, como discutido nos capítulos iniciais, a R é uma linguagem acessível e intuitiva, criada especificamente para facilitar a análise de dados estatísticos e a produção de gráficos de alta qualidade. Com o suporte do RStudio, um ambiente de desenvolvimento integrado, o processo de programação em R se torna ainda mais eficiente e produtivo.\nExploramos os fundamentos da programação em R, incluindo a criação e manipulação de objetos, variáveis e vetores. Abordamos a importância de entender os diferentes tipos de dados e como esses dados podem ser manipulados para atender às necessidades específicas de uma análise. A transição para a manipulação de data frames e tibbles foi natural, permitindo ao leitor lidar com conjuntos de dados mais complexos de maneira organizada e eficaz.\nUm dos pontos altos deste manual foi a introdução ao tidyverse, um conjunto de pacotes desenvolvidos para tornar a análise de dados em R mais simples e intuitiva. Aprendemos a utilizar pacotes como dplyr para manipulação de dados, tidyr para arrumação de dados, ggplot2 para visualização de dados, entre outros. Esses pacotes não apenas ampliam as funcionalidades do R, mas também promovem uma sintaxe consistente e fácil de aprender, tornando o processo de análise de dados mais eficiente.\nA visualização de dados, uma parte crucial da análise, recebeu uma atenção especial com a introdução do ggplot2. Este pacote permite a criação de gráficos sofisticados e esteticamente agradáveis com apenas algumas linhas de código. Exploramos diversos tipos de gráficos, desde gráficos de barras e histogramas até scatter plots e boxplots, capacitando o leitor a apresentar seus dados de maneira clara e informativa.\nAlém disso, abordamos técnicas de análise estatística, desde análises descritivas até inferenciais. Aprendemos a aplicar testes estatísticos como o teste t de Student, ANOVA, e testes não paramétricos, fornecendo uma base sólida para a interpretação de resultados em pesquisas médicas. A compreensão desses conceitos é fundamental para a prática da medicina baseada em evidências, permitindo uma leitura crítica da literatura científica e uma melhor tomada de decisão clínica.\nA jornada pelo R não termina aqui. Este manual foi concebido como um ponto de partida, uma introdução aos conceitos e ferramentas básicas. O aprendizado contínuo e a prática são essenciais para dominar a linguagem R. Recomenda-se que os leitores continuem explorando os vastos recursos disponíveis, como livros, cursos online e comunidades de usuários. A participação em fóruns e grupos de discussão pode ser especialmente útil para a troca de conhecimentos e a resolução de dúvidas.\nAgradeço a todos os leitores por acompanharem este manual até o fim. Suas sugestões e críticas são sempre bem-vindas para que possamos melhorar continuamente este trabalho. Espero que este manual tenha proporcionado uma compreensão clara e prática da linguagem R, inspirando futuros profissionais de saúde a integrar a análise de dados em suas práticas diárias, contribuindo para uma medicina mais precisa e fundamentada em evidências."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Altman, Douglas G, and J Martin Bland. 1991. “Improving Doctors’\nUnderstanding of Statistics.” Journal Article. Journal of the\nRoyal Statistical Society: Series A (Statistics in Society) 154\n(2): 223–48.\n\n\nCarson, M. A., and N. Basiliko. 2016. “Approaches to r Education\nin Canadian Universities.” Journal Article. F1000Res 5:\n2802. https://doi.org/10.12688/f1000research.10232.1.\n\n\nClarke, M, DG Clayton, and LJ Donaldson. 1980. “Teaching\nEpidemiology and Statistics to Medical Students the Leicester\nExperience.” Journal Article. International Journal of\nEpidemiology 9 (2): 179–85.\n\n\nDogan, C Deha. 2017. “Applying Bootstrap Resampling to Compute\nConfidence Intervals for Various Statistics with r.” Eurasian\nJournal of Educational Research 17 (68): 1–18.\n\n\nGordon, Sue. 2006. The Normal Distribution. Sydney:\nMathematics Learning Centre, University of Sydney.\n\n\nHill, A Bradford. 1937. “I.—the Aim of the Statistical\nMethod.” Journal Article. The Lancet 229 (5914): 41–43.\n\n\n———. 1947. “Statistics in the Medical Curriculum?” Journal\nArticle. British Medical Journal 2 (4522): 366.\n\n\nHornik, Kurt. 2012a. “Are There Too Many r Packages?”\nJournal Article. Austrian Journal of Statistics 41 (1):\n59-66-59-66.\n\n\n———. 2012b. “The Comprehensive r Archive Network.” Journal\nArticle. Wiley Interdisciplinary Reviews: Computational\nStatistics 4 (4): 394–98. https://doi.org/doi:10.1002/wics.1212.\n\n\n———. 2017. “The r FAQ.” Web Page. https://CRAN.R-project.org/doc/FAQ/R-FAQ.html.\n\n\nHuber, Wolfgang, Vincent J. Carey, Robert Gentleman, Simon Anders, Marc\nCarlson, Benilton S. Carvalho, Hector Corrada Bravo, et al. 2015.\n“Orchestrating High-Throughput Genomic Analysis with\nBioconductor.” Journal Article. Nature Methods 12 (2):\n115–21. https://doi.org/10.1038/nmeth.3252.\n\n\nIhaka, R, and R Gentleman. 1996. “R: A Language for Data Analysis\nand Graphics. Journal of Computational and Graphical Statistics 5:\n299.” Journal Article. Doi: 10.2307/1390807.\n\n\nIhaka, Ross. 1998. “R: Past and Future History.” Journal\nArticle. Computing Science and Statistics 392396.\n\n\nIoannidis, John PA. 2005. “Why Most Published Research Findings\nAre False.” Journal Article. PLoS Medicine 2 (8): e124.\n\n\n———. 2016. “Why Most Clinical Research Is Not Useful.”\nJournal Article. PLoS Medicine 13 (6): e1002049.\n\n\nLwanga, S Kaggwa, Cho-Yook Tye, and O Ayeni. 1999. Teaching Health\nStatistics: Lesson and Seminar Outlines. Book. World Health\nOrganization.\n\n\nMassart, Desire, Johanna Verbeke, Xavier Capron, and Karin Schlesier.\n2005. “Visual Presentation of Data by Means of Box Plots.”\nJournal Article. Lc-Gc Europe 18: 2–5.\n\n\nMitlöhner, Johann, Sebastian Neumaier, Jürgen Umbrich, and Axel\nPolleres. 2016. “Characteristics of Open Data CSV Files.”\nIn 2016 2nd International Conference on Open and Big Data\n(OBD), 72–79. https://doi.org/10.1109/OBD.2016.18.\n\n\nPagano, Marcello, Kimberlee Gauvreau, and Heather Mattie. 2022.\nPrinciples of Biostatistics. Book. CRC Press.\n\n\nPiboonrungroj, Pairach. 2012. “R-Uni (a List of 100 Free r\nTutorials and Resources in University Webpages).” Web Page. https://pairach.com/2012/02/26/r-tutorials-from-universities-around-the-world/.\n\n\nRexer, Karl, Paul Gearan, and Heather Allen. 2015. “Rexer\nAnalytics’ 2015 Data Science Survey.” Data Science Survey Report.\nRexer Analytics.\n\n\nRobinson, David. 2017. “The Impressive Growth of r.” https://stackoverflow.blog/2017/10/10/impressive-growth-r/.\n\n\nSackett, D. L., and W. M. Rosenberg. 1995. “The Need for\nEvidence-Based Medicine.” Journal Article. JR Soc Med\n88: 620–24.\n\n\nSalsburg, David. 2001. The Lady Tasting Tea. How Statistics\nRevolutionized Science in the Twentieth Century. Book. 1º ed. New\nYork: Holt Paperbacks.\n\n\nShafranovich, Yakov. 2005. “Common Format and MIME Type for\nComma-Separated Values (CSV) Files.” https://www.rfc-editor.org/rfc/pdfrfc/rfc4180.txt.pdf.\n\n\nSilva, SC d, and WD Monteiro. 2009. “Levantamento Do Perfil\nAntropométrico Da População Brasileira Usuária Do Transporte Aéreo\nNacional–Projeto Conhecer.” Journal Article. Publicação\nTécnica Do Acervo Da Anac.\n\n\nSmith, D. 2008. “CRAN Now Has 10,000 r Packages. Here’s How to\nFind the Ones You Need.” Journal Article. Revolutions. Daily\nNews about Using Open Source R for Big Data Analysis, Predictive\nModeling, Data Science, and Visualization Since 2017.\n\n\nStahl, Saul. 2006. “The Evolution of the Normal\nDistribution.” Mathematics Magazine 79 (2): 96–113.\n\n\nStudent. 1908. “The Probable Error of a Mean.” Journal\nArticle. Biometrika 6 (1): 1–25. https://doi.org/10.2307/2331554.\n\n\nTippmann, S. 2015. “Programming Tools: Adventures with r.”\nJournal Article. Nature 517 (7532): 109–10. https://doi.org/10.1038/517109a.\n\n\nTukey, John Wilder et al. 1977. Exploratory Data Analysis. Vol.\n2. Springer.\n\n\nVance, Ashlee. 2009. “Data Analysts Captivated by r’s\nPower.” Journal Article. New York Times 6 (5.4).\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of\nStatistical Software 59 (10): 23."
  }
]